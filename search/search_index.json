{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Introducci\u00f3n a la nube","text":"<p>M\u00f3dulo optativo de Introducci\u00f3n al Cloud Computing de CFGS ASIR, DAM y DAW</p> <p>Iniciar ahora Ver en GitHub</p> <p>La computaci\u00f3n en la nube (cloud computing) ha transformado radicalmente la forma en que las empresas y usuarios acceden, almacenan y procesan la informaci\u00f3n. Este modelo tecnol\u00f3gico permite disponer de recursos inform\u00e1ticos bajo demanda a trav\u00e9s de Internet, sin necesidad de adquirir ni mantener infraestructuras f\u00edsicas propias. En el entorno profesional actual, donde la escalabilidad, la flexibilidad y la eficiencia son factores clave, conocer el funcionamiento y las posibilidades de la nube se ha convertido en una competencia esencial para cualquier t\u00e9cnico en inform\u00e1tica.</p> <p>Estos apuntes est\u00e1n dise\u00f1ados como una introducci\u00f3n pr\u00e1ctica y accesible al mundo de la computaci\u00f3n en la nube para la asignatura optativa de segundo curso de ciclos formativos de grado superior. A lo largo de los diferentes temas se abordar\u00e1n los fundamentos del modelo cloud, los principales tipos de servicios (IaaS, PaaS, SaaS), las plataformas m\u00e1s utilizadas (centr\u00e1ndonos en AWS), as\u00ed como aspectos b\u00e1sicos de seguridad, automatizaci\u00f3n y despliegue de aplicaciones. El objetivo es proporcionar una base s\u00f3lida que permita al estudiante comprender el paradigma cloud y dar sus primeros pasos en el uso de estas tecnolog\u00edas en contextos reales.</p>"},{"location":"pr01/pr01.html","title":"Proyecto 1. Infraestructura Segura de Servidores Internos y P\u00fablicos en AWS","text":""},{"location":"pr01/pr01.html#contexto","title":"Contexto","text":"<p>La empresa NovaWeb Solutions se dedica al desarrollo y despliegue de sitios web para clientes externos. Hasta ahora, su entorno de pruebas y publicaci\u00f3n se encontraba en servidores locales, pero ha decidido migrarlo completamente a la nube de AWS.</p> <p>Tu misi\u00f3n como ingeniero DevOps en la empresa es dise\u00f1ar y desplegar la infraestructura base que dar\u00e1 soporte a sus proyectos, asegurando conectividad, seguridad, y un aprovechamiento eficiente de los recursos.</p>"},{"location":"pr01/pr01.html#objetivos-del-proyecto","title":"Objetivos del proyecto","text":"<p>Implementar una infraestructura propia en AWS que contemple:</p> <ul> <li>Una red estructurada en varias subredes.</li> <li>Servidores Ubuntu distribuidos entre subredes p\u00fablicas y privadas.</li> <li>Un servidor web accesible desde Internet.</li> <li>Un sistema de almacenamiento compartido entre varios servidores.</li> <li>Un volumen adicional en alguno de los servidores para almacenamiento o copias.</li> <li>Gesti\u00f3n controlada del acceso a Internet en las instancias privadas.</li> </ul>"},{"location":"pr01/pr01.html#requisitos-funcionales","title":"Requisitos funcionales","text":""},{"location":"pr01/pr01.html#diseno-de-red","title":"Dise\u00f1o de red","text":"<ul> <li>Dise\u00f1a la estructura de red completa a partir de la VPC 172.16.0.0/16.</li> <li>Define cu\u00e1ntas subredes necesitas, qu\u00e9 tama\u00f1o debe tener cada una y su funci\u00f3n dentro de la infraestructura (p\u00fablicas, privadas, etc.).</li> <li>Establece las rutas necesarias para que cada servidor tenga la conectividad requerida seg\u00fan su prop\u00f3sito.</li> </ul>"},{"location":"pr01/pr01.html#servidores","title":"Servidores","text":"<ul> <li> <p>Despliega al menos tres instancias Ubuntu Server LTS, con roles diferenciados:</p> <ul> <li> <p>Servidor Web (p\u00fablico): alojar\u00e1 un sitio web accesible desde Internet mediante Apache u otro servidor similar.</p> <ul> <li>Este servidor debe ser accesible por HTTP/HTTPS y SSH.</li> <li>Su direcci\u00f3n IP p\u00fablica debe mantenerse fija a lo largo del tiempo (aunque la instancia se detenga y se inicie de nuevo).</li> <li>Deber\u00e1 servir el contenido que encontrar\u00e1s en el repositorio de GitHub que contiene una web de muestra:     <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> </ul> </li> <li> <p>Servidor Interno de Aplicaciones (privado): destinado a tareas de soporte y procesamiento interno.</p> <ul> <li>No debe tener acceso directo desde Internet.</li> </ul> </li> <li> <p>Servidor de Copias o Contenidos (privado): centralizar\u00e1 archivos y respaldos utilizados por otros servidores.</p> <ul> <li>Accesible \u00fanicamente desde la VPC.</li> </ul> </li> </ul> </li> <li> <p>En el servidor de Copias, crea y configura un dispositivo o volumen adicional para almacenamiento espec\u00edfico (datos, copias o logs).</p> </li> <li>Elige para cada servidor la familia de instancia m\u00e1s adecuada seg\u00fan su funci\u00f3n y justifica tu elecci\u00f3n en la memoria t\u00e9cnica.</li> </ul>"},{"location":"pr01/pr01.html#almacenamiento-compartido","title":"Almacenamiento compartido","text":"<ul> <li>Implementa un sistema de archivos compartido que permita que al menos dos servidores trabajen sobre el mismo conjunto de datos (por ejemplo, el contenido multimedia de la web).</li> </ul>"},{"location":"pr01/pr01.html#acceso-y-seguridad","title":"Acceso y seguridad","text":"<ul> <li>Define grupos de seguridad adaptados a los diferentes roles de los servidores, siguiendo el principio de m\u00ednimo privilegio.</li> <li> <p>Asegura que:</p> <ul> <li>El servidor web sea accesible \u00fanicamente por los puertos necesarios.</li> <li>Los servidores privados puedan comunicarse entre ellos y con el servidor web seg\u00fan sus necesidades.</li> <li>No exista acceso SSH directo desde Internet a los servidores privados.</li> <li>Durante el proceso de despliegue y configuraci\u00f3n, las instancias privadas deben poder acceder a Internet para instalar y actualizar paquetes.</li> <li>Con el fin de economizar costos,tras la puesta en marcha del entorno, el acceso a Internet desde las m\u00e1quinas internas deber\u00e1 quedar deshabilitado.</li> </ul> </li> </ul>"},{"location":"pr01/pr01.html#verificaciones","title":"Verificaciones","text":"<ul> <li>Desde tu equipo local, deber\u00e1s poder acceder al servidor web y visualizar correctamente el sitio servido por Apache.</li> <li>Los servidores deben ser accesibles por SSH seg\u00fan las reglas definidas.</li> <li>El sistema de archivos compartido debe estar operativo y accesible entre los servidores que lo utilicen.</li> </ul>"},{"location":"pr01/pr01.html#entregables","title":"Entregables","text":"<p>El proyecto debe incluir:</p> <ul> <li>Un diagrama de arquitectura donde se representen la VPC, las subredes, las rutas, las instancias desplegadas y los servicios que hayas necesitado.</li> <li> <p>Una memoria t\u00e9cnica que describa:</p> <ul> <li>La justificaci\u00f3n del dise\u00f1o de red y segmentaci\u00f3n elegidos.</li> <li>Los tipos de instancia seleccionados y su raz\u00f3n de elecci\u00f3n.</li> <li>La configuraci\u00f3n de seguridad y conectividad.</li> <li>La verificaci\u00f3n de la conexi\u00f3n a cada una de las instancias utilizando claves p\u00fablicas/privadas.</li> <li>El proceso de montaje del almacenamiento compartido y del volumen adicional.</li> <li>Las pruebas de verificaci\u00f3n realizadas.</li> </ul> </li> </ul> <p>Tip</p> <p>Para el diagrama de arquitectura utiliza https://app.diagrams.net/. Puedes utilizar como base el diagrama ejemplo.</p> <p>Importante</p> <p>El documento entregable deber\u00e1 seguir la estructura definida en el este documento.</p>"},{"location":"pr01/pr01.html#ayuda","title":"Ayuda","text":""},{"location":"pr01/pr01.html#instalacion-de-servidor-web","title":"Instalaci\u00f3n de servidor web","text":"<p>El servicio del servidor web se deber\u00e1 instalar en el momento de creaci\u00f3n de la instancia. </p> <p>Los comandos necesarios para instalar el servidor web:</p> <pre><code>sudo apt update\nsudo apt install apache2 -y\n</code></pre>"},{"location":"pr01/pr01.html#configuracion-del-servidor-web","title":"Configuraci\u00f3n del servidor web","text":"<p>Para que Apache sirva nuestra p\u00e1gina web, copia el contenido del repositorio clonado a <code>/var/www/html/</code></p>"},{"location":"pr01/pr01.html#reto-adicional-opcional","title":"Reto adicional (opcional)","text":"<ul> <li>Configura una tarea programada en el servidor de copias que sincronice peri\u00f3dicamente los datos del almacenamiento compartido con un directorio local.</li> </ul>"},{"location":"ud01/practica00.html","title":"Lanzamiento el laboratorio de AWS Academy","text":""},{"location":"ud01/practica00.html#acceso-a-aws-academy","title":"Acceso a AWS Academy","text":"<p>1.- En primer lugar nos validamos con nuestro usuario y contrase\u00f1a en la p\u00e1gina de AWS Academy</p> <p>AWS Academy</p> <p></p>"},{"location":"ud01/practica00.html#acceso-al-learner-lab","title":"Acceso al Learner Lab","text":"<p>2.- En el panel de control de los cursos disponibles seleccionamos el Learner Lab correspondiente.</p> <p></p> <p></p> <p>3.- En el apartado Contenidos pulsamos sobre la opci\u00f3n Lanzamiento del laboratorio.</p> <p></p> <p></p>"},{"location":"ud01/practica00.html#lanzamiento-del-laboratorio","title":"Lanzamiento del laboratorio","text":"<p>4.- Se abre una nueva ventana con el entorno virtual de AWS en el que se nos muestra el cr\u00e9dito en d\u00f3lares que nos queda para realizar pruebas en un entorno real.</p> <p>Pulsamos sobre el bot\u00f3n Start Lab.</p> <p></p> <p></p> <p>5.- Esperamos a que el icono situado a la derecha del texto AWS pase a verde, y pulsamos sobre el texto AWS. </p> <p></p> <p></p> <p>6.- Accedemos a la consola de AWS en un entorno real en la nube (con servicios restringidos).</p> <p></p>"},{"location":"ud01/practica01.html","title":"La Interfaz de L\u00ednea de Comandos","text":""},{"location":"ud01/practica01.html#instalando-aws-cli","title":"Instalando AWS CLI","text":"<p>AWS CLI, es el cliente de AWS mediante el cual podremos utilizar la terminal para poder trabajar con nuestro entorno en lugar de utilizar la herramienta gr\u00e1fica.</p> <p>En este apartado indicar\u00e9 la p\u00e1gina de la documentaci\u00f3n desde donde podremos ir siguiendo las instrucciones de instalaci\u00f3n:</p> <p>https://docs.aws.amazon.com/es_es/cli/latest/userguide/getting-started-install.html </p> <p>Desde aqu\u00ed podremos seleccionar el sistema operativo en el que trabajamos y poder seguir las instrucciones de instalaci\u00f3n.</p> <p></p> <p>Una vez finalizada la instalaci\u00f3n podremos comprobar la versi\u00f3n instalada mediante el comando <code>aws --version</code>.</p> <p></p>"},{"location":"ud01/practica01.html#el-laboratorio","title":"El laboratorio","text":"<p>Teniendo un laboratorio en marcha y el cliente instalado, el siguiente paso es conectarlos. Para ello hay que seguir los siguientes pasos:</p> <p>Ver credenciales del laboratorio, dentro de AWS Details opci\u00f3n Show</p> <p></p> <p>Haremos click en show:</p> <p></p> <p>Ahora utilizaremos el siguiente comando para enlazar la terminal con el lab.</p> <p><code>aws configure</code></p> <p>E iremos copiando y pegando la informaci\u00f3n que nos vaya pidiendo:</p> <p></p> <p>Una vez configurado comprobaremos si podemos recuperar la informaci\u00f3n del usuario:</p> <p><code>aws sts get-caller-identity</code></p> <p>En el caso de los labs vemos que no logra conectarse y devuelve un error. Para paliar este error accederemos a la carpeta personal del usuario y dentro de \u00e9sta hay una carpeta oculta .aws (creada cuando hemos hecho aws configure), y dentro de esta carpeta tenemos el archivo credentials, el cual tiene la informaci\u00f3n que hemos introducido antes. Ahora bien, para arreglarlo vaciaremos el contenido del archivo y copiaremos toda la informaci\u00f3n de AWS Details dentro del archivo:</p> <p></p> <p>seleccionamos todo el texto que aparece dentro del recuadro y lo copiamos en el archivo credentials</p> <p>Y una vez hecho comprobaremos si nos devuelve las credenciales:</p> <p></p> <p>Al ser un entorno preparado de laboratorio las credenciales devueltas son de un perfil general (Estudiante  de  prueba) pero si fueran credenciales reales devolver\u00eda el nombre correspondiente. Destacar que Arn significa Amazon Resource Name que es el identificador que genera AWS para identificar recursos/servicios.</p>"},{"location":"ud01/ud01.html","title":"Tema 1. Introducci\u00f3n a la Nube P\u00fablica","text":""},{"location":"ud01/ud01.html#introduccion-a-cloud-computing","title":"Introducci\u00f3n a Cloud Computing","text":"<p>El Cloud Computing o computaci\u00f3n en la nube es un modelo de prestaci\u00f3n de servicios inform\u00e1ticos que permite acceder a recursos como servidores, almacenamiento, bases de datos, redes, software y m\u00e1s, a trav\u00e9s de Internet y bajo demanda. En lugar de instalar y mantener infraestructura f\u00edsica localmente, las empresas y usuarios acceden a estos servicios desde centros de datos remotos gestionados por proveedores como Amazon Web Services (AWS), Microsoft Azure o Google Cloud.</p> <p>La computaci\u00f3n en la nube se distingue por la noci\u00f3n de que los recursos son virtuales y sin l\u00edmites y que los detalles de los sistemas f\u00edsicos en los que se ejecuta el software se abstraen al usuario. Cuando un usuario ejecuta una aplicaci\u00f3n en la nube desconoce por completo el hardware que est\u00e1 utilizando, la plataforma sobre la que corre, etc. Cuando almacenamos datos en Dropbox, o leemos el correo en Gmail o editamos una hoja de c\u00e1lculo en OneDrive desde un ordenador o una tableta, desconocemos los sistemas f\u00edsicos sobre los que trabajamos, ni la plataforma, ni la ubicaci\u00f3n de los servidores, ni nada por el estilo. Lo vemos de manera abstracta. Una nube.</p> <p>Este modelo se basa en el pago por uso, lo que permite a los usuasurio o las organizaciones consumir solo los recursos que necesitan en cada momento.</p>"},{"location":"ud01/ud01.html#que-ventajas-nos-proporciona-el-cloud-computing","title":"\u00bfQu\u00e9 ventajas nos proporciona el Cloud Computing?","text":"<p>Migrar nuestra estructura f\u00edsica hacia un modelo de computaci\u00f3n en la nube nos puede proporcionar una serie de ventajas con respecto al modelo tradicional (llamado on-premise):</p> <ol> <li>Escalabilidad: La nube permite aumentar o disminuir los recursos (como potencia de c\u00e1lculo, almacenamiento o capacidad de red) de forma sencilla y r\u00e1pida seg\u00fan las necesidades del momento. Esto es ideal para empresas con cargas de trabajo variables o en crecimiento.</li> <li>Elasticidad: La elasticidad va un paso m\u00e1s all\u00e1: permite que los sistemas se ajusten autom\u00e1ticamente a los cambios de demanda, a\u00f1adiendo o quitando recursos sin intervenci\u00f3n humana. Por ejemplo, una web que recibe muchas visitas en horas punta puede ampliar sus servidores autom\u00e1ticamente y luego reducirlos cuando baja la carga.</li> <li>Ahorro de costos: Al eliminar la necesidad de comprar, instalar y mantener hardware local, el cloud computing reduce significativamente los costos iniciales. Adem\u00e1s, el modelo de pago por uso evita pagar por recursos infrautilizados.</li> <li>Disponibilidad global: Los servicios en la nube est\u00e1n disponibles desde cualquier lugar con conexi\u00f3n a Internet, lo que facilita el trabajo remoto, el acceso desde distintas ubicaciones y el despliegue internacional de aplicaciones.</li> <li>Seguridad: Aunque suele haber dudas al respecto, los proveedores de nube invierten grandes recursos en proteger sus infraestructuras. Ofrecen herramientas avanzadas de cifrado, control de accesos, copias de seguridad y cumplimiento de normativas internacionales, que suelen ser m\u00e1s seguras que muchas soluciones locales mal gestionadas.</li> </ol>"},{"location":"ud01/ud01.html#inconvenientes-del-cloud-computing","title":"Inconvenientes del Cloud Computing","text":"<ol> <li>Dependencia de la conexi\u00f3n a Internet: Si no se dispone de una conexi\u00f3n estable y r\u00e1pida, el acceso a los servicios puede verse comprometido. </li> <li>Latencia:: Dependiendo de la ubicaci\u00f3n del servidor y la calidad de la conexi\u00f3n, puede haber retrasos en la respuesta (latencia), lo cual afecta el rendimiento de algunas aplicaciones.</li> <li>P\u00e9rdida de control sobre la infraestructura: Al estar alojados en servidores externos, los usuarios no tienen acceso f\u00edsico ni completo control sobre los sistemas, lo que puede ser una desventaja en algunos contextos empresariales.</li> <li>Costes a largo plazo: Aunque el coste inicial es bajo, si no se gestionan bien los recursos (por ejemplo, si se dejan servicios sobreescalados o encendidos sin necesidad), el gasto mensual puede aumentar significativamente.</li> <li>Problemas de compatibilidad o migraci\u00f3n: Migrar sistemas existentes a la nube puede ser complejo y requerir tiempo, adaptaci\u00f3n o incluso redise\u00f1o de ciertas aplicaciones.</li> <li>Preocupaciones legales y de privacidad: Algunas organizaciones deben cumplir normativas estrictas sobre la ubicaci\u00f3n de los datos (Leyes estatales y Europeas). Usar servicios en la nube ubicados en otros pa\u00edses puede suponer problemas legales si no se gestionan adecuadamente.</li> </ol>"},{"location":"ud01/ud01.html#modelos-de-servicio","title":"Modelos de Servicio","text":"<p>Los modelos de servicio del cloud computing describen el tipo de servicio que el proveedor est\u00e1 ofreciendo. Se construyen uno sobre otro y definen lo que un proveedor debe manejar y lo que es responsabilidad del cliente.</p> <p>Los tres principales modelos de servicio com\u00fanmente aceptados son:</p> <ul> <li> <p>Infraestructura como Servicio: IaaS ofrece m\u00e1quinas virtuales, almacenamiento virtual, infraestructura virtual, y otros activos de hardware como recursos que los usuarios pueden contratar. El proveedor de servicios de IaaS gestiona toda la infraestructura, mientras que el usuario es responsable de todos los dem\u00e1s aspectos de la implementaci\u00f3n (como el sistema operativo, las aplicaciones, y las interacciones del usuario con el sistema).</p> <p>Ejemplo IaaS: Las m\u00e1quinas virtuales de AWS (Amazon EC2) y de Azure (Microsoft Azure VMs).</p> </li> <li> <p>Plataforma como servicio: PaaS proporciona un entorno para desarrollar, probar y desplegar aplicaciones sin gestionar directamente el hardware ni los servicios necesarios. Ofrece las m\u00e1quinas virtuales, los sistemas operativos, los servicios, los marcos de desarrollo, etc. El usuario no se ha de encargar de gestionar la infraestructura de la nube, los sistemas operativos ni el software del servicio gestionado.</p> <p>Ejemplo PaaS: AWS RDS (Bases de Datos gestionadas de AWS), Lambda (funciones serverless de AWS), Azure App Service (despliegue de aplicaciones Web de Azure).</p> </li> <li> <p>Software como Servicio: Con SaaS el usuario accede a una aplicaci\u00f3n completa a trav\u00e9s de Internet. No se preocupa por la infraestructura ni por el mantenimiento. La aplicaci\u00f3n se proporciona al cliente a trav\u00e9s de una interfaz de cliente ligero (un navegador, por lo general), y la responsabilidad del cliente comienza y termina con la entrada y la gesti\u00f3n de sus datos y la interacci\u00f3n con el usuario. Todo, desde la aplicaci\u00f3n hasta la infraestructura, pasando por el almacenamiento de los datos es responsabilidad del proveedor.</p> <p>Ejemplo SaaS: Mircosoft 365, Google Docs, Trello, Genially, Canva, Spotify.</p> </li> </ul> <p></p> <p>Los tres modelos de servicio diferentes en su conjunto han llegado a ser conocido como el modelo SPI (Software, Plataforma e Infraestructura) de cloud computing. Pero podemos encontrar muchos otros modelos de servicio menos conocidos. Algunos ejemplos:</p> <ul> <li> <p>FaaS (Function as a Service): Se ejecutan funciones (trozos de c\u00f3digo) en respuesta a eventos. Es la base del serverless computing.</p> <p>Ejemplo: AWS Lambda, Azure Functions.</p> </li> <li> <p>BaaS (Backend as a Service): Proporciona servicios de backend listos para usar: autenticaci\u00f3n, bases de datos, notificaciones push, etc.</p> <p>Ejemplo: Firebase, AWS Amplify.</p> </li> <li> <p>STaaS (Almacenamiento como servicio): Permite a los usuarios almacenar datos (a nivel de bloque y a nivel de archivo)en la nube sin preocuparse por la infraestructura f\u00edsica. Es escalable, accesible desde cualquier lugar y se paga por el espacio utilizado.</p> <p>Ejemplo: Amazon S3, Azure Blob Storage y en cierto modo tambi\u00e9n DropBox.</p> </li> </ul> <p>Sin embargo, los servicios de SPI abarcan todas las otras posibilidades.</p> <p> </p>"},{"location":"ud01/ud01.html#introduccion-a-amazon-web-services","title":"Introducci\u00f3n a Amazon Web Services","text":""},{"location":"ud01/ud01.html#principales-proveedores-de-cloud-computing","title":"Principales proveedores de Cloud Computing","text":"<p>Existen muchos proveedores de soluciones de cloud computing, pero los 3 m\u00e1s importantes son:</p> <ul> <li>Amazon Web Services (AWS)</li> <li>Microsoft Azure</li> <li>Google Cloud Platform</li> </ul> <p>Estos 3 proveedores en su cartera de productos de cloud computing ofrecen todo tipo de soluciones que abarcan todas las posibilidades del modelo SPI: Redes, M\u00e1quinas Virtuales, Contenedores, Sistemas Gestores de Bases de Datos, Almacenamiento, Serverless, Alojamiento de Aplicaciones, Gesti\u00f3n de APIs, Seguridad e Identidad; IoT, IA y aprendizaje autom\u00e1tico; y muchos m\u00e1s servicios.</p> <p>Existe una gran variedad de servicios ofrecidos por todos los proveedores de Cloud, los cuales suelen tener equivalencias entre ellos. Algunas de las equivalencias m\u00e1s importantes son las que se muestran en la siguiente imagen.</p> <p></p>"},{"location":"ud01/ud01.html#amazon-web-services","title":"Amazon Web Services","text":"<p>Amazon.com comenz\u00f3 siendo una tienda online de libros que, con el paso del tiempo, fue creciendo y acab\u00f3 generaliz\u00e1ndose en el gigante actual de ventas por Internet. Este tremendo crecimiento necesitaba de infraestructuras web masivas (sobre todo los Black Friday), innovadoras y caras para la \u00e9poca, que ten\u00edan contratadas en empresas externas.</p> <p>A medida que iban creciendo, optaron por desarrollar de forma interna toda la infraestructura web necesaria a su medida y ahorrar en costes a largo plazo, con la idea a\u00f1adida de vender sus servicios a terceros.</p> <p>La idea fue todo un \u00e9xito, actualmente Amazon Web Services es la divisi\u00f3n que m\u00e1s beneficios da en el grupo Amazon. En 2024 tuvo unos 39.000 millones de d\u00f3lares de beneficio.</p> <p>Es y ha sido la plataforma de Cloud Computing pionera  desde 2006. La m\u00e1s avanzada y evolucionada frente al resto de competencia que debe seguir sus pasos.</p> <p>\u00bfQui\u00e9n usa Amazon Web Services? \u00bfC\u00f3mo es que nunca lo he o\u00eddo? Son preguntas frecuentes para este gigante silencioso. Basta con dar algunos apuntes para tener idea de su dimensi\u00f3n e importancia:</p> <ul> <li>Clientes conocidos que usan o comenzaron usando sus servicios al completo: Instagram, Pinterest, Netflix, Spotify, AirBnB, Tinder, Twitch, Linkedin, BBC, Vimeo, y por supuesto Amazon.com</li> <li>Los clientes que usan sus servicios parcialmente, como S3 CloudFront son incontables como Vodafone o Facebook, siendo paradigm\u00e1tico el uso de Apple, que tiene alojado all\u00ed parte del contenido de iCloud a nivel mundial.</li> </ul>"},{"location":"ud01/ud01.html#infraestructura-aws","title":"Infraestructura AWS","text":"<p>Las diferentes plataformas cloud ofrecen una infraestructura dividida en Regiones y Zonas de disponibilidad.</p> <p>A lo largo de todo el globo terr\u00e1queo se han construido enormes centros de datos que se conocen como Regiones. Estas regiones son zonas geogr\u00e1ficas, y dentro de cada una de ellas hay diferentes grupo de centros de datos l\u00f3gicos que se conocen como Zonas de Disponibilidad (AZ - Availability Zone) situadas en ubicaciones aisladas. Normalmente cada regi\u00f3n contiene una media de 3 zonas de disponibilidad.</p> <p>Cada zona de disponibilidad est\u00e1 aislada, pero las zonas de disponibilidad de una regi\u00f3n est\u00e1n conectadas mediante redes troncales privadas que proporciona un menor coste y una latencia de red entre regiones mejor que las conexiones p\u00fablicas de Internet.</p> <p>Por tanto, cada regi\u00f3n consta de varias zonas de disponibilidad aisladas y separadas f\u00edsicamente dentro de un \u00e1rea geogr\u00e1fica. Cada zona de disponibilidad tiene alimentaci\u00f3n, refrigeraci\u00f3n y seguridad f\u00edsica independientes y est\u00e1 conectada a trav\u00e9s de redes redundantes de latencia ultrabaja. Esto permite que los clientes trabajen con bases de datos y aplicaciones con un nivel de disponibilidad, tolerancia a errores y escalabilidad mayor que el que ofrecer\u00eda un centro de datos \u00fanico.</p> <p>Nota</p> <p>Dentro de AWS Academy siempre vamos a trabajar dentro de la regi\u00f3n <code>us-east-1</code>, correspondiente al Norte de Virginia (es la regi\u00f3n asignada tambi\u00e9n a la capa gratuita, y adem\u00e1s, es la m\u00e1s econ\u00f3mica).</p> <p>Una zona de disponibilidad se representa mediante un c\u00f3digo de regi\u00f3n seguido de un identificador de letra, por ejemplo, <code>us-east-1a</code>.</p> <p>Dentro de la regi\u00f3n us-east-1 ubicada en el Norte de Virginia, se encuentran 6 zonas de disponibilidad: us-east-1a, us-east-1b, us-east-1c, us-east-1d, us-east-1e, us-east-1f. En cambio, en us-east-2 s\u00f3lo tiene tres AZ: us-east-2a, us-east-2b y us-east-2c.</p> <p>La soluci\u00f3n ideal para garantizar una tolerancia a fallos es replicar los datos y la aplicaci\u00f3n en varias zonas de disponibilidad de una regi\u00f3n, y posteriormente, replicarlos a su vez entre diferentes regiones. La replicaci\u00f3n de datos entre regiones y zonas de disponibilidad es responsabilidad del cliente, mediante el dise\u00f1o de una arquitectura con un cl\u00faster que reparta las peticiones a partir de un balanceador de carga entre, al menos, dos AZ distintas. As\u00ed, si cae una AZ, la otra dar\u00e1 respuesta a todas las peticiones.</p> <p></p> <p>Atenci\u00f3n</p> <p>No todos los servicios de AWS est\u00e1n disponibles en todas las regiones.</p> <p>Para hacernos una idea de la infraestructura global de AWS hay que saber que la nube de AWS est\u00e1 dividida en 37 Regiones (entre ellas Espa\u00f1a) repartidas por todo el mundo. Estas 37 regiones incorporan unas 3 Zonas de Disponibilidad (AZ) de media cada una, teniendo 117 AZ en total.</p> <p>Cada Zona de Disponibilidad tiene entre 1 y 6 datacenters (DC), usualmente 4. Esto implica, por tanto, que la infraestructura de AWS est\u00e1 repartida entre 160 y 450 DC en todo el mundo (el n\u00famero exacto no se sabe por razones de seguridad). Si cada DC de cada una de las AZ tiene entre 50.000 y 80.000 servidores en rack, podemos multiplicar y hacernos una idea del enorme tama\u00f1o que tiene la infraestructura global de AWS.</p> <p>AWS dispone desde 2022 de una Regi\u00f3n ubicada en Espa\u00f1a (concretamente en Huesca) denominada <code>eu-south-2</code> que incorpora 3 AZs. Amazon ya ha anunciado su plan de expansi\u00f3n en esta regi\u00f3n que incrementar\u00e1 con 5 campus m\u00e1s destinados a Datacenters e instalaciones auxiliares.</p>"},{"location":"ud01/ud01.html#principales-servicios-de-aws","title":"Principales Servicios de AWS","text":"<p>Los principales servicios de AWS, clasificados por categor\u00eda ser\u00edan los siguientes:</p> <ul> <li> <p>C\u00f3mputo</p> <ul> <li> <p>Amazon EC2 (Elastic Compute Cloud)</p> <p>Proporciona m\u00e1quinas virtuales configurables. Ideal para ejecutar servidores, aplicaciones o entornos de desarrollo.</p> </li> <li> <p>AWS Lambda</p> <p>Servicio serverless que ejecuta funciones en respuesta a eventos. No requiere administrar servidores.</p> </li> <li> <p>Amazon ECS / EKS</p> <p>Para desplegar contenedores: ECS usa infraestructura AWS propia, EKS gestiona cl\u00fasteres de Kubernetes.</p> </li> </ul> </li> <li> <p>Almacenamiento</p> <ul> <li> <p>Amazon S3 (Simple Storage Service)</p> <p>Almacenamiento de objetos (archivos). Escalable, duradero y muy utilizado para copias de seguridad, sitios web est\u00e1ticos o repositorios de datos.</p> </li> <li> <p>Amazon EBS (Elastic Block Store)</p> <p>Discos virtuales para instancias EC2. Pensado para almacenamiento persistente de bloques.</p> </li> <li> <p>Amazon Glacier</p> <p>Almacenamiento de archivos a largo plazo con acceso diferido, ideal para archivos que se consultan muy poco.</p> </li> </ul> </li> <li> <p>Bases de datos</p> <ul> <li> <p>Amazon RDS (Relational Database Service)</p> <p>Gestiona bases de datos relacionales (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server).</p> </li> <li> <p>Amazon DynamoDB</p> <p>Base de datos NoSQL totalmente gestionada. Ideal para aplicaciones de alto rendimiento y baja latencia.</p> </li> <li> <p>Amazon Aurora</p> <p>Motor de base de datos relacional compatible con MySQL/PostgreSQL, optimizado para la nube.</p> </li> </ul> </li> <li> <p>Redes y entrega de contenido</p> <ul> <li> <p>Amazon VPC (Virtual Private Cloud)</p> <p>Permite crear redes virtuales privadas dentro de AWS, con control sobre IPs, subredes, firewalls, etc.</p> </li> <li> <p>Elastic Load Balancing (ELB)</p> <p>Distribuye el tr\u00e1fico entre m\u00faltiples instancias EC2 para mejorar rendimiento y disponibilidad.</p> </li> <li> <p>Amazon CloudFront</p> <p>Red de entrega de contenido (CDN) para distribuir sitios web, v\u00eddeos u otros contenidos con baja latencia.</p> </li> </ul> </li> <li> <p>Desarrollo y herramientas de DevOps</p> <ul> <li> <p>AWS Elastic Beanstalk</p> <p>Despliegue autom\u00e1tico de aplicaciones web (Java, Python, PHP, Node.js, .NET, Ruby, Go, etc.) sin necesidad de configurar servidores, balanceadores de carga, ni escalado. (PaaS)</p> </li> <li> <p>AWS CodePipeline</p> <p>Automatiza el flujo de integraci\u00f3n y despliegue continuo (CI/CD).</p> </li> <li> <p>AWS CodeBuild / CodeDeploy</p> <p>Servicios para compilar y desplegar c\u00f3digo de forma autom\u00e1tica.</p> </li> <li> <p>AWS CloudFormation</p> <p>Permite definir la infraestructura (redes, m\u00e1quinas, servicios gestionados,...) como c\u00f3digo (IaC) usando plantillas en JSON o YAML.</p> </li> </ul> </li> <li> <p>Seguridad, identidad y cumplimiento</p> <ul> <li> <p>AWS IAM (Identity and Access Management)</p> <p>Control de acceso granular a recursos AWS: usuarios, roles, pol\u00edticas y permisos.</p> </li> <li> <p>AWS KMS (Key Management Service)</p> <p>Gesti\u00f3n de claves criptogr\u00e1ficas para cifrar datos de forma segura.</p> </li> </ul> </li> <li> <p>Monitorizaci\u00f3n y gesti\u00f3n</p> <ul> <li> <p>Amazon CloudWatch</p> <p>Monitorea m\u00e9tricas, logs y alarmas de recursos en tiempo real.</p> </li> <li> <p>AWS CloudTrail</p> <p>Registro de auditor\u00eda de todas las llamadas a la API de AWS. \u00datil para trazabilidad y seguridad.</p> </li> </ul> </li> <li> <p>Inteligencia Artificial y Machine Learning</p> <ul> <li> <p>Amazon SageMaker</p> <p>Plataforma para crear, entrenar y desplegar modelos de aprendizaje autom\u00e1tico a escala.</p> </li> <li> <p>Amazon Rekognition</p> <p>Analiza im\u00e1genes y v\u00eddeos para detectar objetos, rostros y texto.</p> </li> <li> <p>Amazon Polly</p> <p>Convierte texto en voz natural (TTS).</p> </li> </ul> </li> </ul>"},{"location":"ud01/ud01.html#migrando-hacia-el-marco-de-adopcion-de-la-nube-de-aws-caf-de-aws","title":"Migrando hacia el marco de adopci\u00f3n de la nube de AWS (CAF de AWS)","text":"<p>Para ayudar a las organizaciones a planificar y ejecutar con \u00e9xito la adopci\u00f3n de servicios en la nube existe un marco metodol\u00f3gico llamado Cloud Adoption Framework (CAF) de AWS. Migrar hacia este marco implica transformar procesos, cultura y tecnolog\u00eda para alinear los objetivos empresariales con las capacidades de la nube.</p> <p>Adoptar este marco no es simplemente un cambio t\u00e9cnico, sino una transformaci\u00f3n organizativa progresiva que incluye:</p> <ol> <li> <p>Evaluaci\u00f3n y diagn\u00f3stico</p> <p>Identificar el nivel de madurez digital actual.</p> <p>Analizar cargas de trabajo y procesos que pueden migrarse o redise\u00f1arse.</p> </li> <li> <p>Dise\u00f1o del plan de adopci\u00f3n</p> <p>Crear una hoja de ruta para la migraci\u00f3n, identificando prioridades y dependencias.</p> <p>Definir una arquitectura de destino basada en buenas pr\u00e1cticas de AWS.</p> </li> <li> <p>Preparaci\u00f3n del personal</p> <p>Capacitaci\u00f3n t\u00e9cnica en herramientas y servicios cloud.</p> <p>Formaci\u00f3n en nuevas metodolog\u00edas (DevOps, IaC, seguridad en la nube).</p> </li> <li> <p>Migraci\u00f3n y modernizaci\u00f3n</p> <p>Mover aplicaciones y datos de forma controlada (lift &amp; shift, refactorizaci\u00f3n, etc.).</p> <p>Aprovechar servicios nativos de AWS para optimizar coste, rendimiento y resiliencia.</p> </li> <li> <p>Gobierno y control continuo</p> <p>Establecer pol\u00edticas de uso, presupuestos, auditor\u00edas y automatizaci\u00f3n de la seguridad.</p> </li> </ol> <p>Ejemplo pr\u00e1ctico</p> <p>Una empresa que ofrece servicios web quiere modernizar su infraestructura. Aplicando el CAF:</p> <ul> <li>Eval\u00faa qu\u00e9 aplicaciones pueden migrarse.</li> <li>Forma a su equipo t\u00e9cnico en AWS.</li> <li>Define una arquitectura escalable basada en contenedores.</li> <li>Automatiza pol\u00edticas de seguridad y monitorizaci\u00f3n.</li> <li>Mejora el time-to-market de sus desarrollos y reduce el gasto en hardware.</li> </ul>"},{"location":"ud02/practica1.html","title":"Creaci\u00f3n de una M\u00e1quina Virtual (pr\u00e1ctica guiada)","text":""},{"location":"ud02/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear en la nube una m\u00e1quina virtual de Windows Server 2025 y nos conectaremos a ella por RDP. Conoceremos los recursos de AWS asociados a la creaci\u00f3n de esa m\u00e1quina virtual:</p> <ul> <li>La instancia EC2 (la propia m\u00e1quina virtual).</li> <li>El volumen EBS asociado (el disco duro de la m\u00e1quina virtual).</li> <li>La red (VPC) y la subred virtual a la que est\u00e1 conectada la m\u00e1quina.</li> <li>Un Internet Gateway (puerta de enlace) para salir a Internet desde la red virtual.</li> <li>Una direcci\u00f3n IP P\u00fablica para conectarnos desde el exterior.</li> <li>Un grupo de seguridad (firewall) para controlar los accesos.</li> </ul>"},{"location":"ud02/practica1.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud02/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud02/practica1.html#acceso-a-ec2","title":"Acceso a EC2","text":"<p>1.- Vamos a crear directamente una m\u00e1quina en la red virtual (VPC) creada por defecto. Para ello accedemos directamente al servicio de m\u00e1quinas virtuales de AWS llamado EC2 (Amazon Elastic Compute Cloud).</p> <ul> <li>Buscamos el servicio EC2 en la consola.</li> <li>Accedemos y pulsamos sobre Lanzar la Instancia.</li> </ul> <p>Nota</p> <p>Tenemos una red creada de manera predeterminada con una direcci\u00f3n de red 172.31.0.0/16, la cual tiene 6 subredes ubicadas en 6 zonas de disponibilidad distintas de la regi\u00f3n en la que se lanza el laboratorio (Norte de Virginia: us-east-1). Vamos a crear la m\u00e1quina en esta red por defecto.</p> <p></p>"},{"location":"ud02/practica1.html#lanzamiento-de-la-instancia","title":"Lanzamiento de la instancia","text":"<p>2.- Para lanzar la instancia EC2 es necesario asignarle una serie de par\u00e1metros obligatorios y configurar otros opcionales.</p> <ul> <li>El nombre del equipo ser\u00e1 W2025</li> <li>Seleccionamos una imagen (AMI) de Microsoft Windows Server 2025 Base.</li> <li>En el tama\u00f1o de la m\u00e1quina seleccionamos un tipo de instancia t3.medium (2 CPUS y 4 GiB de RAM)</li> <li>En el par de claves podemos elegir entre crear un nuevo par de claves o utilizar las ya creadas de nuestro laboratorio (vockey). Seleccionamos las ya creadas vockey.</li> <li>En la configuraci\u00f3n de red pulsamos en Editar:<ul> <li>Dejamos la VPC (la red virtual) predeterminada.</li> <li>Seleccionamos una subred (por ejemplo la asociada a la zona de disponibilidad 2 cuyo nombre es us-east-1b y su direcci\u00f3n de red es 172.31.16.0/20)</li> <li>Habilitamos la asignaci\u00f3n de una IP P\u00fablica para conectarnos desde Internet a esta m\u00e1quina.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-remoto y le ponemos una descripci\u00f3n (acceso remoto a W2025)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 3389 (RDP) desde cualquier lugar de Internet (0.0.0.0/0)</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 30GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p></p>"},{"location":"ud02/practica1.html#comprobacion-de-los-recursos-creados","title":"Comprobaci\u00f3n de los recursos creados","text":"<p>Tras unos minutos se nos crea la instancia, y con ella los siguientes recursos que podemos comprobar.</p> <p>3.- Accede al panel principal de EC2.</p> <p></p> <p>Comprueba pinchando sobre el enlace correspondiente que se ha creado:</p> <ul> <li>Una instancia (m\u00e1quina).</li> <li>Un volumen EBS (disco duro).</li> <li>2 Grupos de seguridad (el que ven\u00eda por defecto y el que hemos creado llamado acceso-remoto).</li> </ul> <p></p> <p>4.- Accede en la consola al panel de VPC.</p> <p></p> <p>Comprueba que nos aparece una VPC que ya ven\u00eda creada por defecto. Accede a ella y ver\u00e1s las subredes y recursos asociados:</p> <ul> <li>6 Subredes en 6 AZs</li> <li>1 Tabla de enrutamiento utilizada por todas las subredes.</li> <li>1 Conexi\u00f3n de red a Internet: Internet Gateway</li> </ul> <p></p> <p></p>"},{"location":"ud02/practica1.html#acceso-por-rdp","title":"Acceso por RDP","text":"<p>Vamos a iniciar una sesi\u00f3n de escritorio remoto en la m\u00e1quina creada. Al crear la m\u00e1quina no nos ha solicitado nombre de usuario y contrase\u00f1a. Por seguridad, nos crea una contrase\u00f1a compleja que solamente podemos ver utilizando el par de claves p\u00fablica y privada que hemos seleccionado al crear la m\u00e1quina.</p> <p>El primer paso para poder ver la contrase\u00f1a es descargarnos el fichero de la clave o copiar el contenido. </p> <p>5.- Accede a la consola de lanzamiento del laboratorio y en Detalles pulsa sobre una de las opciones de descarga o visualizaci\u00f3n de la clave privada. Descarga, por ejemplo, el fichero PEM.</p> <p></p> <p>6.- En la consola de AWS accede al panel de la instancia EC2 que acabamos de lanzar y pulsa sobre Conectar. En la pesta\u00f1a de Cliente RDP descarga el archivo RDP y pulsa sobre Obtener Contrase\u00f1a. Para descifrarla te pide la clave privada que acabas de descargar.</p> <p>7.- Una vez descifrada la contrase\u00f1a, ya podemos abrir el fichero RDP descargado e introducir el usuario (Administrator) y la contrase\u00f1a para iniciar sesi\u00f3n.</p> <p>Captura la pantalla</p> <p>Haz una captura de pantalla en la que se vea la conexi\u00f3n por RDP a la m\u00e1quina Windows Server 2025 como parte de las pr\u00e1cticas a entregar.</p>"},{"location":"ud02/practica1.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>8.- Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Terminamos la instancia. En el panel de EC2, con la instancia seleccionada, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> <li>Por \u00faltimo, eliminamos el grupo de seguridad acceso-remoto.</li> </ul> <p>Recuerda finalizar el laboratorio cuando acabes con las pr\u00e1cticas.</p>"},{"location":"ud02/practica2.html","title":"Pr\u00e1cticas entregables","text":""},{"location":"ud02/practica2.html#practica-1","title":"Pr\u00e1ctica 1","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-virtual-practica-guiada","title":"Creaci\u00f3n de una M\u00e1quina Virtual (pr\u00e1ctica guiada)","text":"<p>Reproduce la pr\u00e1ctica guiada y haz una captura de pantalla en la que se vea la conexi\u00f3n por RDP a la m\u00e1quina Windows Server 2025 creada.</p>"},{"location":"ud02/practica2.html#practica-2","title":"Pr\u00e1ctica 2","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux","title":"Creaci\u00f3n de una M\u00e1quina Linux","text":"<p>Necesitamos una m\u00e1quina que act\u00fae como servidor de Bases de Datos y para ello vamos a crear una instancia EC2.</p> <p>Queremos que el tama\u00f1o de la m\u00e1quina se adapte a esa funci\u00f3n de servidor de Base de Datos. Decide t\u00fa qu\u00e9 familia de instancias utilizar.</p> <p>Como sistema operativo utilizaremos Ubuntu, y deseamos que al crearse la m\u00e1quina se instale autom\u00e1ticamente el paquete del gestor de base de datos mysql.</p> <p>No vamos a utilizar el par de claves del laboratorio, sino crear un par de claves nuevo para conectarnos por ssh. El usuario de conexi\u00f3n ser\u00e1 el que nos cree por defecto.</p> <p>Tip</p> <p>Para instalar mysql hay que actualizar los repositios de Linux y a continuaci\u00f3n instalar el paquete con el comando <code>apt install mysql-server -y</code></p> <p>Tip</p> <p>Recuerda cambiar los permisos del fichero de la clave privada y a\u00f1adirlo con el par\u00e1metro <code>-i</code> dentro del comando <code>ssh</code></p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el tama\u00f1o de la instancia, los datos de usuario y el par de claves utilizado y la conexi\u00f3n por ssh a la m\u00e1quina Linux.</p>"},{"location":"ud02/practica2.html#practica-3","title":"Pr\u00e1ctica 3","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux-desde-la-cli","title":"Creaci\u00f3n de una M\u00e1quina Linux desde la CLI","text":"<p>Ahora que ya hemos practicado con el entorno gr\u00e1fico, vamos a comenzar a utilizar la terminal. Para ello, tal y como se explic\u00f3 en el Tema 1, debemos configurar las credenciales en el archivo <code>credentials</code> para poder estar conectados con el lab.</p> <p>En esta pr\u00e1ctica vamos a hacer un script (en Windows o Linux) para crear una m\u00e1quina virtual con los valores por defecto mediante el comando <code>aws ec2 run-instances</code> .</p> <p>Nota</p> <p>Necesitamos especificar algunos par\u00e1metros m\u00ednimos, entre ellos el identificador de la AMI a utilizar. Existen herramientas y comandos para conocer las IDs de las AMIs, pero nosoros accederemos a la consola gr\u00e1fica y, al intentar crear una instancia, veremos la ID de la AMI que nos interesa para poder introducirla en el comando.</p> <p>Recuerda que como usuario de aws academy debes utilizar la regi\u00f3n us-east-1 que te permite crear los recursos que se piden en este curso.</p> <p>Crearemos un fichero de script con el siguiente comando:</p> WindowsLinux <pre><code>aws ec2 run-instances `\n--image-id ami-0b09ffb6d8b58ca91 `\n--count 1 `     \n--instance-type m1.small `     \n--key-name vockey `     \n--region us-east-1\n</code></pre> <pre><code>aws ec2 run-instances \\\n--image-id ami-0b09ffb6d8b58ca91 \\\n--count 1 \\\n--instance-type m1.small \\\n--key-name vockey \\\n--region us-east-1    \n</code></pre> <p>Una vez guardado, damos permiso de ejecuci\u00f3n (en Linux) y lo ejecutamos anteponiendo <code>./</code> al nombre del script (en Windows y Linux).</p> <p>Al ejecutarlo, el comando nos devuelve una cadena json con informaci\u00f3n relativa a la instancia creada, pero no nos aparece ni la IP P\u00fablica ni el nombre DNS P\u00fablico asignados.</p> <p>Para poder ver dicha informaci\u00f3n y as\u00ed poder conectarnos mediante ssh, ejecutamos el comando <code>aws ec2 describe-instances</code> y filtramos la informaci\u00f3n de salida para que nos aparezca la palabra <code>PublicIpAddress</code>. En este caso no vamos a conectarnos por SSH pues en el script ser\u00eda necesario abrir el puerto 22 en el grupo de seguridad. Lo veremos en el siguiente tema.</p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el comando de creaci\u00f3n de la instancia.</p>"},{"location":"ud02/practica2.html#practica-4","title":"Pr\u00e1ctica 4","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux-desde-la-cli_1","title":"Creaci\u00f3n de una M\u00e1quina Linux desde la CLI","text":"<p>Modifica el script de la pr\u00e1ctica anterior para lanzar una nueva instancia cuyo tam\u00f1o sea <code>t2.micro</code>, la AMI sea una basada en Debian y el par de claves sea el creado en la pr\u00e1ctica 2.</p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el script y la ejecuci\u00f3n del mismo.</p>"},{"location":"ud02/practica2.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Termina todas la instancias. En el panel de EC2, con las instancias seleccionadas, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> </ul> <p>Recuerda finalizar el laboratorio cuando acabes con las pr\u00e1cticas.</p>"},{"location":"ud02/ud02.html","title":"Tema 2. Capa Inform\u00e1tica","text":""},{"location":"ud02/ud02.html#que-es-una-capa-informatica","title":"\u00bfQu\u00e9 es una Capa Inform\u00e1tica?","text":"<p>La capa inform\u00e1tica (o de c\u00f3mputo) de AWS es el nivel de la nube encargado de proporcionar recursos de procesamiento (CPU, memoria y red) que permiten ejecutar aplicaciones, sistemas operativos y servicios. Esta capa ofrece distintos modelos de uso, desde m\u00e1quinas virtuales hasta entornos sin servidor.</p> <p>Es decir, son los servicios que sustituyen o complementan a los servidores f\u00edsicos o m\u00e1quinas virtuales tradicionales en un centro de datos.</p>"},{"location":"ud02/ud02.html#que-otros-componentes-interactuan-con-la-capa-informatica","title":"\u00bfQu\u00e9 otros componentes interact\u00faan con la capa inform\u00e1tica?","text":"<ul> <li>Capa de almacenamiento (S3, EBS, EFS): Proporciona d\u00f3nde guardar los datos que las aplicaciones procesan.</li> <li>Capa de red (VPC, Route 53, ELB): Permite la comunicaci\u00f3n entre instancias, usuarios y servicios de AWS.</li> <li>Capa de bases de datos (RDS, DynamoDB, Aurora): Proporciona sistemas gestionados para almacenar, consultar y organizar datos.</li> <li>Capa de seguridad e identidad (IAM, Security Groups, NACLs): Garantiza que solo los usuarios o servicios autorizados accedan a los recursos de c\u00f3mputo.</li> <li>Capa de monitorizaci\u00f3n y gesti\u00f3n (CloudWatch, CloudTrail): Supervisa el estado y el rendimiento de los recursos inform\u00e1ticos.</li> </ul>"},{"location":"ud02/ud02.html#servicios-de-computo-en-aws","title":"Servicios de c\u00f3mputo en AWS.","text":"<p>Cuando hablamos de capa inform\u00e1tica en AWS pensamos r\u00e1pidamente en la posibilidad de crear m\u00e1quinas virtuales en la nube. Este popular servicio es el conocido como EC2, pero no es el \u00fanico servicio que ofrece AWS relacionado con la capa de c\u00f3mputo.</p> <p>AWS ofrece varias opciones de inform\u00e1tica para satisfacer diferentes necesidades. Las opciones clave de inform\u00e1tica de tiempo de ejecuci\u00f3n se pueden agrupar en cuatro categor\u00edas de modelos inform\u00e1ticos en la nube: </p> <ul> <li>M\u00e1quinas virtuales (VM)</li> <li>Contenedores</li> <li>Plataforma como servicio (PaaS)</li> <li>Sin servidor (Serverless)</li> </ul> <p></p> <p>En este tema nos vamos a centrar en el servicio EC2.</p>"},{"location":"ud02/ud02.html#amazon-ec2","title":"Amazon EC2","text":"<p>Amazon Elastic Compute Cloud (Amazon EC2) proporciona m\u00e1quinas virtuales en las que podemos alojar el mismo tipo de aplicaciones que podr\u00edamos ejecutar en un servidor en nuestras oficinas (servidores web, de aplicaciones, de correo, de bases de datos, multimedia, ...), ofreciendo capacidad de c\u00f3mputo segura y de tama\u00f1o ajustable en la nube.</p> <p>Amazon EC2 proporciona m\u00e1quinas virtuales y se puede considerar una forma de infraestructura como servicio (IaaS). Podemos elegir el sistema operativo, as\u00ed como el tama\u00f1o y las capacidades de los recursos de los servidores que lancemos, pero los servicios de IaaS nos obligan a estar a cargo de muchas de las responsabilidades de la administraci\u00f3n del servidor tales como actualizaciones del sistema operativo, copias de seguridad, instalaci\u00f3n y actualizaci\u00f3n de aplicaciones y servicios, etc.</p> <p>La computaci\u00f3n el\u00e1stica (Elastic Compute) se refiere a la capacidad para aumentar o reducir f\u00e1cilmente la cantidad de servidores que ejecutan una aplicaci\u00f3n de manera autom\u00e1tica, as\u00ed como para aumentar o reducir la capacidad de procesamiento (CPU), memoria RAM o almacenamiento de los servidores existentes.</p> <p>Cuando hablemos de una m\u00e1quina virtual lanzada en Amazon EC2 nos referiremos a ella como una instancia EC2.</p>"},{"location":"ud02/ud02.html#parametros-de-configuracion-de-una-instancia-ec2","title":"Par\u00e1metros de configuraci\u00f3n de una instancia EC2","text":"<p>Cuando creemos una instancia EC2 deberemos especificarle algunos par\u00e1metros necesarios para su configuraci\u00f3n y su seguridad. Algunos de ellos los vamos a ver en este tema y otros los iremos desarrollando en temas siguientes.</p> <p>Entre estos par\u00e1metros necesarios habr\u00e1 que indicarle a la consola que la instancia debe tener un tama\u00f1o de procesador y memoria, un sistema de almacenamiento o disco duro virtual, con un sistema operativo basado en una imagen de m\u00e1quina que se crear\u00e1 con unos datos de usuario; adem\u00e1s deber\u00e1 estar conectada en una red privada virtual de AWS y necesitaremos un par de claves p\u00fablica/privada para conectarnos a la m\u00e1quina.</p> <p></p>"},{"location":"ud02/ud02.html#amis","title":"AMIs","text":"<p>Una AMI (Amazon Machine Image) es una plantilla preconfigurada que contiene la informaci\u00f3n necesaria para crear una m\u00e1quina virtual (instancia) en Amazon EC2.</p> <p>Podr\u00eda decirse que es como una \u201cfoto\u201d de un servidor que sirve de modelo para lanzar nuevas instancias en AWS. A partir de esa imagen se pueden crear tantas m\u00e1quinas virtuales como se necesiten, todas con la misma configuraci\u00f3n inicial.</p> <p>Una AMI incluye:</p> <ul> <li>El sistema operativo (Linux, Windows, etc.).</li> <li>Opcionalmente, aplicaciones o configuraciones adicionales.</li> <li>Permisos de acceso (qui\u00e9n puede usarla).</li> <li>Informaci\u00f3n sobre el tipo de almacenamiento que utilizar\u00e1.</li> </ul> <p>Podemos encontrarnos varios tipos de AMI:</p> <ul> <li>De AWS: proporcionadas y mantenidas por Amazon (ej. Amazon Linux, Ubuntu, Windows Server).</li> <li>De la comunidad: compartidas por otros usuarios.</li> <li>Privadas/personalizadas: creadas por la propia organizaci\u00f3n o usuario con sus programas y configuraciones.</li> <li>Del Marketplace: publicadas por proveedores de software (ej. im\u00e1genes con Oracle, SAP, etc.).</li> </ul>"},{"location":"ud02/ud02.html#tipo-de-instancias","title":"Tipo de instancias","text":"<p>Un tipo de instancia EC2 define una configuraci\u00f3n de caracter\u00edsticas de rendimiento de CPU, memoria, almacenamiento y red que proporcionan un nivel determinado de rendimiento inform\u00e1tico. Ser\u00e1 lo equivalente a decir el tama\u00f1o de la instancia ajustando los tama\u00f1os de dichas caracter\u00edsticas de la m\u00e1quina virtual.</p> <p>La nomenclatura del tipo de instancia nos determina la familia, la generaci\u00f3n y el tama\u00f1o.</p> <p></p> <p>Para el tipo de instancia <code>m5d.xlarge</code> la letra m indica el nombre de la familia, al cual le sigue un n\u00famero, en este caso el 5. </p> <p>Este n\u00famero indica la generaci\u00f3n de ese tipo de familia. Por lo tanto, una instancia m5 es la quinta generaci\u00f3n de la familia m. En general, los tipos de instancias que son de una generaci\u00f3n m\u00e1s alta son m\u00e1s potentes y ofrecen un mejor relaci\u00f3n calidad-precio.</p> <p>La parte siguiente del nombre corresponde a la capacidad de la instancia. Cuando se comparan las capacidades, es importante tener en cuenta la parte del coeficiente de la categor\u00eda de capacidad. \u00a0 Por ejemplo, una instancia <code>m5.2xlarge</code> tiene el doble de vCPU y memoria que una instancia <code>m5.xlarge</code> que tiene, a su vez, el doble de vCPU y memoria que una instancia <code>m5.large</code>. \u00a0</p> <p>Nota</p> <p>Adem\u00e1s de tener en cuenta las necesidades de CPU, RAM y almacenamiento de las cargas de trabajo, tambi\u00e9n es importante tener en cuenta los requisitos del ancho de banda de la red, que tambi\u00e9n est\u00e1 vinculada al tama\u00f1o de la instancia de EC2. Si ejecutamos trabajos que hacen un uso intensivo de la red, es posible que debamos aumentar las especificaciones de las instancias para satisfacer nuestras necesidades.</p> <p>Cada tipo de instancia proporciona un nivel de rendimiento de red documentado. Por ejemplo, una instancia <code>a1.medium</code> brinda hasta 10\u00a0Gb/s, pero una instancia <code>p3dn.24xlarge</code> proporciona hasta 100\u00a0Gb/s.</p> <p>Las familias de las instancias se agrupan seg\u00fan su prop\u00f3sito y caracter\u00edsticas de hardware como se resume la siguiente tabla:</p> Familia Optimizado para Ejemplos t, m Uso general Web, apps ligeras, desarrollo, pruebas c CPU intensiva An\u00e1lisis, servicios web, juegos multijugador, codificaci\u00f3n de v\u00eddeos r, x RAM intensiva Bases de datos, cach\u00e9 en memoria, an\u00e1lisis de Big Data i, d Disco Duro r\u00e1pido Bases de datos NoSQL, Big Data, Almacenamiento de Datos p, g, f Computaci\u00f3n acelerada HPC, Machine Learning e IA, gr\u00e1ficos"},{"location":"ud02/ud02.html#par-de-claves","title":"Par de Claves","text":"<p>Amazon EC2 utiliza la criptograf\u00eda de clave p\u00fablica para cifrar y descifrar la informaci\u00f3n de inicio de sesi\u00f3n. La tecnolog\u00eda utiliza una clave p\u00fablica para cifrar un dato y luego el destinatario usa la clave privada para descifrar los datos. El conjunto de clave p\u00fablica y clave privada se denomina par de claves. </p> <p>Esta criptograf\u00eda de clave p\u00fablica nos permite acceder de forma segura a nuestras instancias mediante una clave privada en lugar de una contrase\u00f1a, de hecho EC2 deshabilita en las m\u00e1quinas Linux el acceso por contrase\u00f1a mediante SSH, oblig\u00e1ndonos a conectarnos mediante este par de claves.</p> <p>Cuando lanzamos una instancia es neccesario especificar un par de claves. Podemos especificar un par de claves existente o uno nuevo que se cree durante el lanzamiento. Si creamos un nuevo par de claves, debemos descargarlo y guardarlo en un lugar seguro. Esta oportunidad es la \u00fanica posibilidad de guardar el archivo de clave privada.\u00a0La clave p\u00fablica la almacena AWS dentro de la instancia, mientras que la clave privada la almacenamos nosotros.</p> <p>Atenci\u00f3n</p> <p>Si perdemos las claves, tendremos que destruir la instancia y volver a crearla.</p> <p>Para conectarnos a una instancia de Windows, utilizaremos la clave privada a fin de obtener la contrase\u00f1a de administrador y, a continuaci\u00f3n, iniciar sesi\u00f3n en el escritorio de Windows de la instancia de EC2 mediante el Protocolo de escritorio remoto (RDP). Para establecer una conexi\u00f3n SSH desde una m\u00e1quina Windows a una instancia de EC2, podemos utilizar una herramienta como PuTTY, que requerir\u00e1 la misma clave privada.</p> <p>Con las instancias de Linux, en el momento de arranque, se coloca el contenido de la clave p\u00fablica en la instancia. Se crea una entrada en <code>~/.ssh/authorized_keys</code>. Para iniciar sesi\u00f3n en nuestra instancia de Linux (por ejemplo, mediante SSH), debemos proporcionar la clave privada cuando establezcamos la conexi\u00f3n.\u00a0El siguiente ejemplo muestra c\u00f3mo hacer una conexi\u00f3n por ssh a la m\u00e1quina remota ubicada en 3.83.80.53 utilizando la clave privada descargada en el fichero <code>labuser.pem</code>:</p> <pre><code>ssh -i labsuser.pem ec2-user@3.83.80.52\n</code></pre> <p>Claves en AWS Academy</p> <p>Nuestro usuario del laboratorio tiene creado por defecto un par de claves que se conocen como <code>vockey</code>. Esta claves se pueden descargar desde la opci\u00f3n AWS Details del laboratorio de Learner Lab. Para poder conectarnos es necesario adem\u00e1s dar permisos para que s\u00f3lo nuestro usuario pueda utilizar la clave: <code>chmod 400 labuser.pem</code></p> <p>Usuarios Linux por defecto</p> <p>Al crear una instancia basada en una AMI de Linux se crean unos usuarios por defecto. En el caso de una AMI Ubuntu el usuario es <code>ubuntu</code> y para las AMIs de Amazon Linux el usuario es <code>ec2-user</code>.</p>"},{"location":"ud02/ud02.html#configuracion-de-la-red","title":"Configuraci\u00f3n de la red","text":"<p>Un paso necesario para la creaci\u00f3n de una instrancia EC2 es especificar la ubicaci\u00f3n de red en la que se implementar\u00e1, teniendo en cuenta la regi\u00f3n donde nos encontramos antes de lanzar la instancia. Hay que elegire la VPC (la red) y la subred dentro de la misma, ya sea de las que tenemos creadas o pudiendo crear los recursos en este paso.</p> <p>Adem\u00e1s, cuando se lanza una instancia en una VPC predeterminada, AWS le asigna una direcci\u00f3n IP p\u00fablica de forma predeterminada. En caso contrario, si la VPC no es la predeterminada, AWS no asignar\u00e1 una direcci\u00f3n IP p\u00fablica, a no ser que lo indiquemos de forma expl\u00edcita.</p> <p>A la creaci\u00f3n y configuraci\u00f3n de la red le dedicaremos un tema entero.</p>"},{"location":"ud02/ud02.html#almacenamiento","title":"Almacenamiento","text":"<p>Al lanzar la instancia EC2 configuraremos las opciones de almacenamiento. Se puede definir el tama\u00f1o del volumen ra\u00edz en el que est\u00e1 instalado el sistema operativo invitado, o incluso a\u00f1adir vol\u00famenes de almacenamiento adicionales.</p> <p>Algunas AMI est\u00e1n configuradas para lanzar m\u00e1s de un volumen de almacenamiento de forma predeterminada y, de esa manera, proporcionar almacenamiento independiente del volumen ra\u00edz. Para cada volumen que tenga la instancia, podemos indicar el tama\u00f1o de los discos, los tipos de volumen, si el almacenamiento se conservar\u00e1 en el caso de terminaci\u00f3n de la instancia y si se debe utilizar el cifrado.</p> <ul> <li>Configurar el volumen ra\u00edz.<ul> <li>D\u00f3nde est\u00e1 instalado el sistema operativo invitado.</li> </ul> </li> <li>Adjuntar vol\u00famenes de almacenamiento adicionales (opcional).<ul> <li>Es posible que la AMI ya incluya m\u00e1s de un volumen.</li> </ul> </li> <li>Para cada volumen, especificaremos lo siguiente:<ul> <li>Tama\u00f1o del disco (en GB).</li> <li>El tipo de volumen<ul> <li>Hay disponibles diferentes tipos de unidades de estado s\u00f3lido (SSD) y unidades de disco duro (HDD).</li> </ul> </li> <li>Si el volumen se eliminar\u00e1 al finalizar la instancia.</li> <li>Si se debe utilizar el cifrado.</li> </ul> </li> </ul> <p>Al almacenamiento tambi\u00e9n le dedicaremos un tema entero.</p>"},{"location":"ud02/ud02.html#datos-de-usuario","title":"Datos de usuario","text":"<p>Al crear las instancias de EC2, tenemos la opci\u00f3n de pasar datos de usuario a la instancia. Los datos de usuario pueden automatizar la finalizaci\u00f3n de las instalaciones y configuraciones en el lanzamiento de la instancia. Por ejemplo, un script de datos de usuario podr\u00eda aplicar parches y actualizar el sistema operativo de la instancia, buscar e instalar claves de licencia de software, o instalar software adicional. </p> <p></p> <p>En el script de datos de usuario de ejemplo, ver\u00e1 un script de shell Linux Bash de tres l\u00edneas sencillo. La primera l\u00ednea indica que el script debe ser ejecutado por el shell de Bash. La segunda l\u00ednea invoca la utilidad <code>apt update</code> para actualizar los repositorios de una distribuci\u00f3n Ubuntu, por ejemplo. La tercera l\u00ednea del script indica que se debe instalar la utilidad Wget para descargar archivos de la Web.</p> <p>En una instancia de Windows, el script de datos de usuario debe escribirse en un formato compatible con una ventana del s\u00edmbolo del sistema (comandos por lotes) o con Windows PowerShell.</p> <p>Nota</p> <p>El script s\u00f3lo se ejecuta la primera vez que se inicia la instancia.</p> <p>Cuando se lanza una instancia se crean una serie de metadatos a los que se puede acceder desde la misma instancia mediante la url <code>http://169.254.169.254/latest/meta-data/\u200b</code> y que a su vez podemos acceder desde el script de datos de usuario.</p> <p></p>"},{"location":"ud02/ud02.html#costos-de-las-instancias-ec2","title":"Costos de las instancias EC2","text":"<p>No todas las m\u00e1quinas EC2 cuestan lo mismo. Evidentemente las m\u00e1s grandes cuestan m\u00e1s, pero adem\u00e1s existen una serie de factores que influir\u00e1n en el costo de nuestra m\u00e1quina EC2:</p> <ul> <li>Tipo de instancia (m\u00e1s CPU/memoria \u21d2 m\u00e1s caro).</li> <li>Regi\u00f3n en la que se lanza (cada regi\u00f3n tiene precios distintos).</li> <li>Tiempo de uso (horas/minutos encendida).</li> <li>Almacenamiento asociado (EBS, snapshots).</li> <li>Tr\u00e1fico de red (salida de datos hacia Internet suele ser de pago).</li> </ul> <p>El costo habitual de las m\u00e1quinas EC2 viene determinado por el uso que hagamos de ellas. Mientras la m\u00e1quina est\u00e1 apagada no se nos factura el costo asociado a la computaci\u00f3n (pero ojo, s\u00ed otros costos como almacenamiento). Este pago por uso se conoce como pago bajo demanda. Normalmente cuando iniciemos una instancia usaremos este tipo de pago (el cr\u00e9dito concedido por AWS Academy es en esa modalidad), pero conviene conocer el resto de formas que ofrecen diferentes facturaciones:</p> <ul> <li>Pago por uso (On-Demand): se paga por hora o por segundo de uso, sin compromiso. Es la modalidad de pago por defecto.</li> <li>Instancias reservadas: precio m\u00e1s bajo a cambio de un compromiso de 1 o 3 a\u00f1os.</li> <li>Instancias spot: muy baratas, pero pueden ser interrumpidas por AWS si necesita los recursos.</li> <li>Savings Plans: descuentos a cambio de comprometerse a un nivel de gasto mensual.</li> </ul>"},{"location":"ud02/ud02.html#precauciones-a-tener-en-cuenta","title":"Precauciones a tener en cuenta","text":"<ul> <li>Apagar las instancias cuando no se usan: aunque est\u00e9n inactivas, si est\u00e1n \u201crunning\u201d generan costos.</li> <li>Revisar el almacenamiento EBS: incluso si se apaga la instancia, los discos EBS asociados siguen cobrando.</li> <li>Controlar el tama\u00f1o de las instancias: usar solo la potencia que realmente se necesita.</li> <li>Monitorizar el tr\u00e1fico de red: grandes transferencias de datos a Internet incrementan la factura.</li> <li>Usar la capa gratuita (Free Tier): ofrece 750 horas/mes de una instancia t2.micro o t3.micro durante 12 meses, pero solo en determinadas condiciones.</li> <li>Configurar alarmas en AWS Budgets o CloudWatch: para evitar gastos inesperados.</li> </ul> <p>Atenci\u00f3n</p> <p>EC2 es flexible pero puede ser caro si no se controla. Lo importante es elegir el modelo de facturaci\u00f3n adecuado y vigilar los recursos que siguen generando gasto aunque no se usen. El costo de EC2 depende del tipo de instancia, el tiempo de uso, el almacenamiento y la red. Para evitar sorpresas en la factura, hay que apagar instancias cuando no se usan, vigilar discos y transferencias, y aprovechar la capa gratuita.</p>"},{"location":"ud03/redpractica00.html","title":"Pr\u00e1ctica 0. Creaci\u00f3n de una VPC de forma autom\u00e1tica","text":"<p>Una VPC es una red virtual aislada desde un punto de vista l\u00f3gico, a la que asignamos un direccionamiento de red, y que podemos subdividir en subredes, como se hace en una infraestructura tradicional. La diferencia es que en este caso todo lo definimos por software, ya sea desde la consola de AWS, desde la terminal con comandos de CLI, o utlizando alg\u00fan lenguaje de programaci\u00f3n soportado por el SDK de AWS.</p> <p>AWS tiene regiones en diferentes paises, y cada regi\u00f3n tiene varias zonas de disponibilidad que est\u00e1n separadas f\u00edsicamente unas de otras (unos 100 km como mucho). Cada zona de disponibilidad a su vez tiene varios datacenters.</p> <p>Una VPC se define a nivel de regi\u00f3n, y puede abarcar una o m\u00e1s zonas de disponibilidad. As\u00ed, podemos crear subredes en varias de estas zonas y desplegar nuestros recursos de manera que sean altamente disponibles.</p> <p>En el esquema siguiente se muestra una VPC dentro de una regi\u00f3n con tres zonas de disponibilidad. En cada una de ellas hay definida una subred, en las que se pueden lanzar instancias EC2 de manera que podamos tener un servicio replicado (o diferentes servicios) en diferentes zonas geogr\u00e1ficas:</p> <p></p> <p>Existen diferentes formas para crear una VPC y sus elementos. Vamos a comenzar por la manera m\u00e1s sencilla, creando de manera autom\u00e1tica los elementos que componen una VPC.</p>"},{"location":"ud03/redpractica00.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a realizar la creaci\u00f3n simult\u00e1nea de los elementos de red desde la consola de AWS. Aprenderemos a:</p> <ul> <li>Crear una VPC y asignar un bloque de CIDR IPv4 a la red.</li> <li>Crear subredes dentro de esa VPC y asignarles un bloque de direcciones CIDR IPv4.</li> <li>Ubicar cada subred dentro de una zona de disponibilidad (AZ).</li> </ul> <p>Una vez que creemos la VPC, crearemos 2 instancias EC2 en dicha VPC y accediendo por SSH a ellas comprobaremos las direcciones IP privadas que se le han asignado dentro del bloque de direcciones de la subred.</p>"},{"location":"ud03/redpractica00.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":"<p>Vamos a crear una VPC que contendr\u00e1 una \u00fanica subred en una Zona de Disponibilidad. La subred ser\u00e1 p\u00fablica, lo que significa que sus elementos ser\u00e1n accesibles desde Internet con la correspondiente apertura de puertos (grupos de seguridad).</p> <ul> <li>La direcci\u00f3n de la Red ser\u00e1 <code>192.168.0.0/16</code></li> <li>La direcci\u00f3n de la subred p\u00fablica ser\u00e1 <code>192.168.5.0/24</code></li> </ul>"},{"location":"ud03/redpractica00.html#creacion-simultanea-de-los-elementos-de-red-desde-la-consola-de-aws","title":"Creaci\u00f3n simult\u00e1nea de los elementos de red desde la consola de AWS","text":"<p>Ahora que ya hemos comprobado que podemos utilizar instancias dentro del espacio de Amazon, el siguiente paso es crear un \u2019trozo\u2019 de nube y ser conscientes del direccionamiento que podemos emplear dentro del espacio que AWS nos da. Podemos acceder al servicio VPC busc\u00e1ndolo en la barra superior de la consola de AWS, una vez hemos arrancado el Learner Lab y accedido a la consola:</p> <p></p> <p></p> <p>Lo primero ser\u00e1 utilizar la creaci\u00f3n de subredes en el mismo momento que se crea una VPC (opci\u00f3n VPC y m\u00e1s). Seleccionaremos el servicio VPC, con  direccionamiento <code>192.168.0.0/16</code>, y dentro de la VPC crearemos una \u00fanica subred p\u00fablica con direccionamiento <code>192.168.5.0/24</code>:</p> <p> </p> <p>En este caso estamos utilizando una \u00fanica zona de disponibilidad con una subred p\u00fablica, concretamente la zona con nombre <code>us-east-1a</code> en la regi\u00f3n del Norte de Virginia (<code>us-east-1</code>):</p> <p>En este punto no vamos a seleccionar Gateways NAT ni puntos de enlace de la VPC, que son conceptos que veremos m\u00e1s adelante.</p> <p></p> <p>Una vez pulsemos sobre el bot\u00f3n de Crear VPC, podremos ir viendo los elementos que se van creando, en funci\u00f3n de las opciones que se elijan:</p> <p></p> <p>Una vez creada la VPC, es interesante seleccionar la pesta\u00f1a de Mapa de recursos que nos permite comprobar de una manera visual los elementos creados y c\u00f3mo se relacionan entre ellos:</p> <p></p> <p>En el men\u00fa lateral izquierdo del Panel de VPC, tenemos diferentes opciones para trabajar con los diferentes  elementos que pueden estar presentes en una VPC. Podemos mostrar informaci\u00f3n sobre los elementos creados:</p> <p>La VPC  :</p> <p></p> <p>La subred :</p> <p></p> <p>Es importante fijarnos en el identificador que se genera para cada recurso, porque muchas veces creamos elementos y les perdemos la trazabilidad. Adem\u00e1s, para utilizar la CLI (Command Line Interface), necesitaremos el identificador de cada servicio. </p>"},{"location":"ud03/redpractica00.html#creacion-de-una-instancia-ec2-en-la-subred-creada","title":"Creaci\u00f3n de una instancia EC2 en la subred creada","text":"<p>Crea una instancia EC2 de Ubuntu con un grupo de seguridad por defecto, de manera que se despliegue en la subred que acabamos de crear, y selecciona la opci\u00f3n de Asignar autom\u00e1ticamente la IP p\u00fablica. Para ello, en el momento de lanzar la instancia, edita la configuraci\u00f3n de red y seleccionar la VPC y la subred reci\u00e9n creadas:</p> <p></p> <p></p>"},{"location":"ud03/redpractica00.html#creacion-de-una-segunda-instancia-ec2-en-la-subred-creada","title":"Creaci\u00f3n de una segunda instancia EC2 en la subred creada","text":"<p>Crea una segunda m\u00e1quina EC2 Ubuntu, asign\u00e1ndole el grupo de seguridad que se ha creado al lanzar la EC2 anterior, despleg\u00e1ndola tambi\u00e9n en la misma subred.</p> <p>Con todo esto la arquitectura finalmente creada es la que se muestra a continuaci\u00f3n:</p> <p></p> <p>Accede por ssh a las instancias y comprueba sus direcciones ip privadas.</p> <p>Captura las pantallas</p> <p>Entrega captura de pantalla resultado de ejecutar el comando <code>ip a</code> una vez est\u00e1s conectado por ssh en cada una de las instancias.</p>"},{"location":"ud03/redpractica01.html","title":"Pr\u00e1ctica 1. Creaci\u00f3n de una VPC de forma manual","text":""},{"location":"ud03/redpractica01.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a realizar la creaci\u00f3n independiente de los elementos de red desde la consola de AWS, el resultado ser\u00e1 el mismo que en la pr\u00e1ctica anterior pero se trata de que entiendas qu\u00e9 papel juegan cada uno de los siguientes conceptos en la VPC:</p> <ul> <li>Red</li> <li>Subred</li> <li>Zona de disponibilidad</li> <li>Direcci\u00f3n IP P\u00fablica</li> <li>Nombre de host DNS</li> <li>Gateway de internet IGW</li> <li>Tabla de enrutamiento</li> </ul>"},{"location":"ud03/redpractica01.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":"<p>Vamos a crear una VPC y todos sus elementos necesarios paso a paso. La VPC tendr\u00e1 las siguientes direcciones:</p> <ul> <li>Red: 192.168.0.0/16</li> <li>Subred: 192.168.0.0/24</li> </ul> <p>Captura las pantallas</p> <p>Esta tarea la documentar\u00e1s paso a paso. Para comprobar que ha funcionado correctamente, al final entregar\u00e1s tambi\u00e9n una captura del resultado de acceder por ssh a las instancia y comprobar su direcci\u00f3n privada.</p>"},{"location":"ud03/redpractica01.html#creacion-independiente-de-los-elementos-de-red-desde-la-consola-de-aws","title":"Creaci\u00f3n independiente de los elementos de red desde la consola de AWS","text":"<p>En la pr\u00e1ctica anterior hemos creado una VPC completa (utilizando la ayuda para la configuraci\u00f3n que nos ofrece AWS) porque ya conoc\u00edamos de antemano todos los elementos que necesit\u00e1bamos. Pero puede darse el caso de que tengamos que crear los  elementos por separado. De eso trata esta alternativa, por tanto, seleccionaremos la opci\u00f3n Solo la VPC al crearla.</p>"},{"location":"ud03/redpractica01.html#creacion-de-la-vpc","title":"Creaci\u00f3n de la VPC","text":"<p>Lo primero es crear una VPC con su direccionamiento (por ejemplo, <code>192.168.0.0/16</code>) seleccionando la opci\u00f3n Solo la VPC:</p> <p></p> <p></p>"},{"location":"ud03/redpractica01.html#creacion-de-las-subredes","title":"Creaci\u00f3n de las subredes","text":"<p>A continuaci\u00f3n, una vez creada la VPC, desde la opci\u00f3n de Subredes, crearemos la subred asoci\u00e1ndola a la VPC que acabamos de crear y d\u00e1ndole un nombre y un rango de direcciones IPv4, que debe estar dentro del rango de la VPC. Por ejemplo, podemos asignar el rango 192.168.0.0/24:</p> <p></p> <p></p> <p>En este caso no hemos asignado una zona de disponibilidad en concreto, con lo que la subred se puede crear en cualquiera de las seis zonas de disponibilidad que hay en la regi\u00f3n del Norte de Virginia (us-east-1).</p> <p></p>"},{"location":"ud03/redpractica01.html#comprobacion-de-funcionamiento-con-una-ec2","title":"Comprobaci\u00f3n de funcionamiento con una EC2","text":"<p>Vamos a lanzar una instancia EC2 y comprobar si funciona la arquitectura que acabamos de hacer. Para ello, al crear la instancia, seleccionaremos la VPC y subred que hemos creado. </p> <p></p> <p></p> <p>Es importante habilitar la asignaci\u00f3n de una IP p\u00fablica.</p> <p>Nota</p> <p>AWS solo asigna autom\u00e1ticamente direcciones IP p\u00fablicas en la VPC por defecto, pero no en las creadas por nosotros.</p> <p></p> <p></p> <p>Una vez creado, nos daremos cuenta de que S\u00cd que se asigna una IP p\u00fablica pero NO un nombre de host DNS. El problema reside en que en la VPC no hemos habilitado esta resoluci\u00f3n.</p> <p></p>"},{"location":"ud03/redpractica01.html#nombre-de-host-dns","title":"Nombre de host DNS","text":"<p>Para habilitar el nombre de host DNS, accedemos al men\u00fa de VPC y seleccionaremos la VPC creada:</p> <p></p> <p></p> <p>Y editaremos la configuraci\u00f3n para habilitar la opci\u00f3n nombres de host DNS.</p> <p></p> <p></p> <p>Ahora cuando volvamos a comprobar las propiedades de la EC2 creada, podremos ver que ya le ha asignado un nombre de host DNS a trav\u00e9s del cual podremos acceder por ssh (tambi\u00e9n lo podr\u00edamos hacer utilizando la ip p\u00fablica).</p> <p>Cuando intentemos acceder por ssh, nos daremos cuenta de que NO es posible hacerlo, ya que a nuestra VPC le falta un elemento/servicio que permita a todo lo que haya dentro poder configurarse para poder conectarse con el exterior y viceversa. </p>"},{"location":"ud03/redpractica01.html#internet-gateway","title":"Internet Gateway","text":"<p>El elemento que nos falta es el gateway de Internet (Internet Gateway o puerta de enlace de Internet - IGW). Podemos  crear  este  elemento dede la opci\u00f3n Puerta  de  enlace  de  Internet que encontraremos en el men\u00fa lateral izquierdo del panel del servicio VPC:</p> <p></p> <p></p> <p></p> <p>Si visualizamos el listado de los IGWs que hay creados, veremos que el estado del nuevo IGW aparece como detached, as\u00ed que tendremos que asign\u00e1rselo a la VPC deseada. En las acciones del IGW, le daremos a conectar a VPC:</p> <p></p> <p></p> <p></p> <p>\u00a1Pero seguimos sin poder conectarnos!</p> <p>Falta configurar un elemento encargado de gestionar el tr\u00e1fico dentro de la VPC: la tabla de enrutamiento.  </p>"},{"location":"ud03/redpractica01.html#tablas-de-enrutamiento","title":"Tablas de enrutamiento","text":"<p>Al  crear  una  VPC,  se  crea  un  tabla  de  enrutamiento  por defecto, y tenemos que asociarle la subred creada para poder crear rutas para esa subred, desde la opci\u00f3n correspondiente del panel de VPC (puedes localizar la subred entre las distintas que puedan haber observando la VPC a la que pertenece):</p> <p></p> <p></p> <p>Asociaremos la subred expl\u00edcitamente, aunque si no lo hacemos, la subred se asocia con la tabla de enrutamiento por defecto de la VPC.</p> <p></p> <p>Podemos volver a comprobar si nos podemos conectar a la instancia EC2, y seguimos SIN CONEXI\u00d3N. </p> <p>Lo \u00fanico que nos falta es modificar las rutas de la tabla de enrutamiento asociada a la subred. Si nos fijamos en las rutas que hay (seleccionando la subred, pesta\u00f1a \u2018Tabla de enrutamiento\u2019), s\u00f3lo se est\u00e1 enrutando la red de la VPC en local, es  decir  las subredes que tenga a su alcance (192.168.0.0/16). </p> <p>Hay que a\u00f1adir una ruta e indicar  que  todo lo que vaya a <code>0.0.0.0</code> (todo el tr\u00e1fico) salga por el Internet Gateway que hemos creado y asociado a nuestra VPC. Para ello seleccionamos la tabla de enrutamiento, editamos las rutas, y seleccionamos la opci\u00f3n Agregar ruta:</p> <p></p> <p>Una vez a\u00f1adida, comprobamos que aparece la nueva ruta en la lista de rutas de la tabla de enrutamiento:</p> <p></p> <p>Una vez hecho esto, ahora s\u00ed que podremos conectarnos por ssh a cualquier instancia EC2 lanzada en la subred que hemos creado (siempre que la EC2 tenga asignada una direcci\u00f3n IP p\u00fablica, y de que el grupo de seguridad asociado, concepto del que hablaremos m\u00e1s adelante, permita tr\u00e1fico entrante al puerto de ssh).</p> <p>Captura la pantalla</p> <p>Accede por ssh a la instancia EC2 y comprueba con el comando <code>ip a</code> su direcci\u00f3n privada. Captura la pantalla.</p>"},{"location":"ud03/redpractica02.html","title":"Pr\u00e1ctica 2. Creaci\u00f3n de una VPC con 2 subredes","text":""},{"location":"ud03/redpractica02.html#objetivo-de-la-practica","title":"Objetivo de la Pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a implementar un esquema en el que tendremos una red virtual con dos subredes (subred-publica y subred-privada). </p> <p>En cada una de esas subreeds crearemos una m\u00e1quina virtual Ubuntu:</p> <ul> <li>La primera ser\u00e1 accesible desde el exterior de la red (desde Internet) y para ello crearemos un grupo de seguridad en el que habilitaremos el puerto 22 (ssh) y el 80 (http) para que puedan entrar desde cualquier direcci\u00f3n. Adem\u00e1s necesitaremos una IP P\u00fablica y un Internet Gateway que dar\u00e1 salida al exterior a todos los elementos de la subred.</li> <li>La segunda m\u00e1quina estar\u00e1 en la subred-privada y configuraremos su grupo de seguridad para que sea accesible \u00fanicamente desde la subred-p\u00fablica, sin acceso desde el exterior. Para que esta m\u00e1quina tenga acceso a Internet (por ejemplo para poder hacer actualizaciones) pero no sea accesible desde Internet, necesitaremos un NAT-Gateway que se ubicar\u00e1 en la subred-p\u00fablica</li> </ul>"},{"location":"ud03/redpractica02.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud03/redpractica02.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud03/redpractica02.html#creacion-de-la-nueva-vpc","title":"Creaci\u00f3n de la nueva VPC","text":"<p>1.- Procedemos a crear la nueva VPC:</p> <ul> <li>Le decimos que queremos crear la VPC y m\u00e1s.</li> <li>Asignamos un nombre a la VPC, por ejemplo practica02</li> <li>Como direcci\u00f3n de red (Bloque de CIDR IPv4) dejamos la 10.0.0.0/16</li> <li>Seleccionamos una \u00fanica zona de disponibilidad (AZ).</li> <li>Le decimos que nos cree una subred p\u00fablica y otra privada.</li> <li>Personalizamos los bloques de direcciones de modo que las subredes tengan las siguientes direcciones:<ul> <li>Subred p\u00fablica: 10.0.1.0/24</li> <li>Subred privada: 10.0.2.0/24</li> </ul> </li> <li>Como deseamos que la subred privada tenga salida a Internet, creamos un Gateway NAT en 1 AZ (ojo, esto nos incrementar\u00e1 el coste considerablemente).</li> <li>No vamos a conectar ning\u00fan bucket de S3, por tanto no seleccionamos ning\u00fan Gateway de S3 en el apartado de Puntos de enlace de la VPC.</li> </ul> <p></p> <p></p> <p></p>"},{"location":"ud03/redpractica02.html#comprobacion-de-los-recursos-creados","title":"Comprobaci\u00f3n de los recursos creados","text":"<p>2.- Comprobamos los recursos creados:</p> <ul> <li>La VPC (practica02-vpc).</li> <li>Las 2 subredes (practica02-subnet-public1 y practica02-subnet-private1).</li> <li>El Internet Gateway (practica02-igw).</li> <li>Las 2 tablas de enrutamiento (una por cada subred: practica02-rtb-public y practica02-rtb-private).</li> <li>Una tabla de enrutamiento por defecto.</li> <li>Un Grupo de Seguridad por defecto.</li> <li>El NAT Gateway (practica02-nat-public1) ubicado en la subred p\u00fablica para dar salida a Internet en la subred privada.</li> <li>Una IP El\u00e1stica asociada al NAT Gateway (practica02-eip).</li> </ul> <p></p>"},{"location":"ud03/redpractica02.html#tablas-de-enrutamiento","title":"Tablas de enrutamiento","text":"<p>Al crearse la VPC se han creado 3 tablas de enrutamiento: una por defecto y dos asociadas a las 2 subredes que hemos creado. Las 2 tablas asociadas a las nuevas subredes son las siguientes:</p> <p>Tabla de entutamiento de la subred privada</p> <p>Uso T\u00edpico</p> <p>Subred privada que aloja recursos como:</p> <ul> <li>Bases de datos, servidores de aplicaciones o backend.</li> <li>Instancias que requieren acceso saliente a Internet (actualizaciones, APIs externas), pero que no deben recibir tr\u00e1fico entrante directamente desde Internet.</li> </ul> Destino Objetivo 10.0.0.0 /16 local 0.0.0.0 /16 nat-gateway <p>Interpretaci\u00f3n:</p> <ul> <li>10.0.0.0/16 -&gt; local:         Permite que todos los recursos dentro de la VPC con direcci\u00f3n en el rango 10.0.0.0/16 se comuniquen entre s\u00ed sin salir de la red privada.</li> <li>0.0.0.0/0 -&gt; NAT-Gateway:         Redirige el tr\u00e1fico saliente destinado a Internet al NAT Gateway que se encuentra en la subred p\u00fablica.         El NAT Gateway permite que las instancias en la subred privada se comuniquen con Internet sin ser directamente accesibles desde \u00e9l.</li> </ul> <p></p> <p>Tabla de entutamiento de la subred p\u00fablica</p> <p>Uso T\u00edpico</p> <p>Subred p\u00fablica que aloja recursos como:</p> <ul> <li>Servidores web o aplicaciones que necesitan acceso desde Internet.</li> <li>Instancias EC2 con direcciones IP p\u00fablicas.</li> </ul> Destino Objetivo 10.0.0.0 /16 local 0.0.0.0 /16 Internet-gateway <p>Interpretaci\u00f3n:</p> <ul> <li>10.0.0.0/16 -&gt; local:         Igual que en la tabla privada, permite la comunicaci\u00f3n entre recursos dentro de la VPC sin salir de la red.</li> <li>0.0.0.0/0 -&gt; Internet-Gateway:         Define que todo el tr\u00e1fico destinado a Internet (es decir, fuera del rango 10.0.0.0/16) sea redirigido al Internet Gateway.         Este es el componente clave que convierte esta subred en una subred p\u00fablica.</li> </ul> <p></p>"},{"location":"ud03/redpractica02.html#creacion-de-una-instancia-ec2-en-la-subred-publica","title":"Creaci\u00f3n de una instancia EC2 en la subred p\u00fablica","text":"<p>Vamos a crear una m\u00e1quina Ubuntu en la subred p\u00fablica a la cual nos podremos conectar desde Internet.</p> <p>3.- Accedemos al panel de EC2 y lanzamos una instancia.</p> <ul> <li>La nombramos ub01</li> <li>La imagen ser\u00e1 una AMI de Ubuntu 24.04 LTS.</li> <li>En tipo de instancia seleccionamos una t2.micro (1 CPU y 1GB de RAM) incluida en la capa gratuita.</li> <li>Seleccionamos el par de claves vockey proporcionadas por el laboratorio.</li> <li>Editamos la configuraci\u00f3n de red.<ul> <li>Incluimos la m\u00e1quina en la subred p\u00fablica creada.</li> <li>Habilitamos la asignaci\u00f3n de una IP P\u00fablica.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-publico y le ponemos una descripci\u00f3n (acceso ssh a subred publica)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 22 (SSH) desde cualquier lugar de Internet (0.0.0.0/0)</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 8GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p>Nota</p> <p>Hay que tener en cuenta que la direcci\u00f3n IP asignada ser\u00e1 din\u00e1mica, por lo que si dese\u00e1ramos que nuestra m\u00e1quina fuera, por ejemplo, un servidor web, habr\u00eda que asociarle una IP el\u00e1stica, que equivale a asignarle una IP p\u00fablica est\u00e1tica.</p> <p></p>"},{"location":"ud03/redpractica02.html#conexion-mediante-ssh","title":"Conexi\u00f3n mediante SSH","text":"<p>Al crear la instancia no nos ha preguntado por ning\u00fan usuario ni contrase\u00f1a en el sistema operativo. AWS crea unos usuarios por defecto que var\u00edan dependiendo del tipo de AMI seleccionada. Se pueden consultar aqu\u00ed.</p> <p>Para conectarnos a la m\u00e1quina mediante ssh lo debemos hacer con un par de claves. En nuestro caso le hemos indicado que utilizar\u00edamos las del laboratorio (vockey), por tanto el primer es descargarnos el fichero de la clave.</p> <p>4.- Accedemos a la consola de lanzamiento del laboratorio y en Detalles pulsamos sobre la descarga del fichero PEM.</p> <p></p> <p>5.- Una vez descargado el fichero de clave debemos cambiar los permisos de dicho archivo:</p> <ul> <li>En Linux: <code>chmod 400 labuser.pem</code></li> <li>En Windows: Dejamos \u00fanicamente los permisos para nuestro usuario, eliminando los accesos del resto de usuarios.</li> </ul> <p>6.- Lanzamos el ssh indicando el fichero de la clave privada descargada y sustituyendo por la url correspondiente:</p> <pre><code>ssh -i \"labuser.pem\" ubuntu@ec2-204-236-197-47.compute-1.amazonaws.com\n</code></pre> <p></p>"},{"location":"ud03/redpractica02.html#instalacion-de-un-servidor-web","title":"Instalaci\u00f3n de un servidor web","text":"<p>Una vez dentro de la m\u00e1quina vamos a instalar un servidor web.</p> <p>7.- Ejecutamos:</p> <pre><code>sudo apt update\nsudo apt install apache2 -y\n</code></pre> <p></p>"},{"location":"ud03/redpractica02.html#acceso-a-la-pagina-web","title":"Acceso a la p\u00e1gina web","text":"<p>8.- Una vez instalado el servidor Apache, accedemos desde el navegador de nuestra m\u00e1quina local a la direcci\u00f3n IP P\u00fablica de  nuestra m\u00e1quina AWS.</p> <p>A pesar de tener instalado y corriendo el servidor web, el navegador no es capaz de resolver la direcci\u00f3n puesto que en el firewall de la instancia (grupo de seguridad acceso-publico) s\u00f3lo hemos permitido conexiones desde el puerto 22.</p> <p>Vamos a permitir conexiones tambi\u00e9n del puerto 80 (http) a\u00f1adiendo una nueva regla de entrada en el grupo de seguridad acceso-publico.</p> <p> 9.- En la consola de AWS, dentro del panel de VPC, accedemos al grupo de seguridad acceso-publico para editar sus propiedades:</p> <ul> <li>En las Reglas de entrada a\u00f1adimos una del tipo HTTP (Puerto TCP 80) para permitir accesos desde cualquier direcci\u00f3n (0.0.0.0/0).</li> </ul> <p> 10.- Guardamos las reglas y ya podemos acceder desde el navegador a la p\u00e1gina por defecto del servidor Apache instalado en nuestra m\u00e1quina.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre el acceso desde el navegador a la p\u00e1gina por defecto servida por el servidor Apache de la m\u00e1quina EC2. Que se vea claramente la url con la IP p\u00fablica de la m\u00e1quina.</p> <p></p>"},{"location":"ud03/redpractica02.html#creacion-de-una-instancia-ec2-en-la-subred-privada","title":"Creaci\u00f3n de una instancia EC2 en la subred privada","text":"<p>Vamos a crear una m\u00e1quina Ubuntu en la subred privada a la cual NO nos podremos conectar desde Internet.</p> <p>11.- Accedemos al panel de EC2 y lanzamos una instancia.</p> <ul> <li>La nombramos ub02</li> <li>La imagen ser\u00e1 una AMI de Ubuntu 24.04 LTS.</li> <li>En tipo de instancia seleccionamos una t2.micro (1 CPU y 1GB de RAM) incluida en la capa gratuita.</li> <li>Seleccionamos el par de claves vockey proporcionadas por el laboratorio.</li> <li>Editamos la configuraci\u00f3n de red.<ul> <li>Incluimos la m\u00e1quina en la subred privada creada.</li> <li>NO habilitamos la asignaci\u00f3n de una IP P\u00fablica.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-privado y le ponemos una descripci\u00f3n (acceso ssh a subred privada)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 22 (SSH) desde tipo de origen Personalizado, y como origen seleccionamos el grupo de seguridad acceso-publico</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 8GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p>Nota</p> <p>En el grupo de seguridad asociado a esta instancia hemos dicho que s\u00f3lo se pueden admitir conexiones por ssh provenientes del grupo de seguridad acceso-publico, de modo que para poder conectarnos a la m\u00e1quina ub02 \u00fanicamente podremos hacerlo desde la m\u00e1quina ubu01.</p> <p></p>"},{"location":"ud03/redpractica02.html#conexion-mediante-ssh_1","title":"Conexi\u00f3n mediante SSH","text":"<p>La m\u00e1quina ubu02 no tiene direcci\u00f3n p\u00fablica, y adem\u00e1s, aunque la tuviera, el grupo de seguridad solamente admite conexiones desde la subred p\u00fablica, y no desde Internet. Por todo ello, si deseamos conectarnos a esta m\u00e1quina, el \u00fanico modo es hacerlo desde la m\u00e1quina ub01. Para ello necesitamos 2 requisitos:</p> <ul> <li>Averiguar la IP de la m\u00e1quina (Sabemos que al estar en la subred privada estar\u00e1 en el rango de direcciones 10.0.2.0/24)</li> <li>Pasar la clave privada (<code>labuser.pem</code>) que descargamos en nuestra m\u00e1quina local a la m\u00e1quina ub01, pues nos har\u00e1 falta para conectarnos a ub02.</li> </ul> <p>12.- Comenzamos accediendo desde el panel de EC2 a los detalles de la instancia ub02 y copiamos la direcci\u00f3n IP privada.</p> <p>13.- En segundo lugar, desde nuestra m\u00e1quina host (y con la conexi\u00f3n ssh cerrada) copiamos el archivo <code>labuser.pem</code> a la m\u00e1quina ubu01 mediante el comando <code>scp</code>:</p> <pre><code>scp -i labsuser.pem labsuser.pem ubuntu@ec2-18-212-203-120.compute-1.amazonaws.com:/home/ubuntu/clave_privada\n</code></pre> <p>14.- Iniciamos sesi\u00f3n en ub01:</p> <pre><code>ssh -i \"labuser.pem\" ubuntu@ec2-204-236-197-47.compute-1.amazonaws.com\n</code></pre> <p>15.- Comprobamos con un ls que se ha copiado el fichero y cambiamos los permisos:</p> <p><pre><code>ls -l\nchmod 400 clave_privada\n</code></pre> 16.- Nos conectamos con esa clave a la m\u00e1quina ub02 mediante la IP privada que anotamos:</p> <pre><code>ssh -i clave_privada ubuntu@10.0.2.112\n</code></pre> <p>17.- Comprobamos que tenemos conexi\u00f3n de salida a Internet gracias al NAT Gateway:</p> <pre><code>sudo apt update\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el comando <code>apt update</code> y que se vea la direcci\u00f3n IP interna (aparece en el prompt de comandos).</p> <p></p>"},{"location":"ud03/redpractica02.html#eliminacion-del-nat-gateaway","title":"Eliminaci\u00f3n del NAT Gateaway","text":"<p>18.- Accedemos a la consola de VPC y en Gateways NAT eliminamos el gateway (practica02-nat-public1) que creamos al crear la VPC.</p> <p>19.- Intenta en ubu02 acceder a Internet, por ejemplo actualizando los repositorios:</p> <pre><code>sudo apt update\n</code></pre> <p>Ya hemos perdido la conexi\u00f3n a Internet.</p> <p></p>"},{"location":"ud03/redpractica02.html#eliminacion-de-recursos","title":"Eliminaci\u00f3n de recursos","text":"<p>20.- Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Comenzamos liberando la IP el\u00e1stica que se asoci\u00f3 al NAT Gateway. Accedemos a la consola de EC2 y en IP El\u00e1sticas seleccionamos la opci\u00f3n Publicar direcci\u00f3n IP el\u00e1stica. (Publicar = hacer p\u00fablica = disponible).</li> <li>Terminamos las instancias. En el panel de EC2, con la instancia seleccionada, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> <li>Por \u00faltimo, esperamos unos minutos a que se acaben de terminar la instancias y eliminamos los grupos de seguridad acceso-publico y acceso-privado, comenzando por este \u00faltimo.</li> </ul> <p>Recuerda finalizar el laboratorio.</p>"},{"location":"ud03/redpractica03.html","title":"Redpractica03","text":""},{"location":"ud03/redpractica03.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta tarea aprenderemos a crear subredes privadas y a configurar diferentes recursos de red de manera que se pueda acceder a Internet desde una instancia desplegada en una subred privada. Tambi\u00e9n trataremos diferentes aspectos de seguridad para controlar el tr\u00e1fico de red, tanto a nivel de instancias como a nivel  de  subred.  En  concreto, utilizaremos  los  siguientes  servicios  y  recursos  relacionados  con  la  parte  de  redes de AWS:</p> <ol> <li>VPC</li> <li>Subredes p\u00fablicas y privadas</li> <li>Tablas de enrutamiento y rutas</li> <li>Gateway de Internet</li> <li>Gateway NAT</li> <li>Grupos de seguridad</li> <li>ACL de red</li> </ol> <p>El escenario propuesto que vamos a desarrollar consistir\u00e1 en una VPC con una subred p\u00fablica y una subred privada, la cual s\u00f3lo tendr\u00e1 acceso al exterior pasando primero por la subred p\u00fablica, y se lanzar\u00e1 una instancia EC2 en cada subred. Para que la instancia desplegada en la subred privada tenga acceso a Internet, se utilizar\u00e1 un Gateway NAT, que  es  un  recurso  de  red  que  podemos  desplegar  en  una  subred  p\u00fablica  que  tenga conexi\u00f3n a un Gateway de Internet, de manera que permita la salida a Internet desde los recursos desplegados en subredes privadas, sin m\u00e1s que redirigir de manera apropiada el tr\u00e1fico de red mediante rutas.</p> <p>Los rangos utilizados para la VPC y subredes de la pr\u00e1ctica guiada que tienes a continuaci\u00f3n son:</p> <ul> <li>Direccionamiento VPC: 172.16.0.0/16</li> <li>Direccionamiento subred p\u00fablica: 172.16.0.0/20</li> <li>Direccionamiento subred privada: 172.16.64.0/20</li> </ul> <p></p> <p>Aunque es posible desplegar todos los recursos de red al crear la VPC, vamos a crear \u00fanicamente la VPC, la subred p\u00fablica, el Gateway de Internet y las tablas de rutas por defecto. Para ello se utilizar\u00e1 la consola gr\u00e1fica de AWS. Despu\u00e9s, a\u00f1adiremos uno a uno los recursos de la parte privada.</p> <p>El objetivo inicial entonces en cuanto a la parte de red, es tener una VPC, una subred p\u00fablica, un Gateway de Internet (IGW) y una tabla de enrutamiento, que vamos creando desde la opci\u00f3n de creaci\u00f3n de VPC como ya se vio</p>"},{"location":"ud03/redpractica03.html#que-tienes-que-hacer-en-esta-tarea","title":"Qu\u00e9 tienes que hacer en esta tarea","text":"<ul> <li>La tarea consiste en realizar un despliegue de una t\u00edpica arquitectura de dos capas, donde en la parte p\u00fablica tendremos un servidor web, y en la privada un servidor de base de datos:</li> <li>Crea  una  VPC  con  dos  subredes,  una  p\u00fablica  y  otra  privada, puedes poner el mismo direccionamiento de red que tienes en esta tarea guiada o puedes escoger otro. Para que desde la subred privada se pueda acceder al exterior deber\u00e1s utilizar un NAT Gateway.</li> <li>En la subred p\u00fablica, lanza una instancia EC2 e instala un servidor web Apache, que ser\u00e1 accesible desde cualquier equipo externo a la VPC por el puerto 80, utilizando tanto su nombre DNS como su direcci\u00f3n IP p\u00fablica.</li> <li>En la subred privada, lanza otra instancia EC2 e instala un servicio de MySQL. Para acceder a esta instancia, tendr\u00e1s que acceder primero a la instancia p\u00fablica (utiliza para ello el agente ssh).</li> <li>Los grupos de seguridad asociados a las instancias deben permitir s\u00f3lo el tr\u00e1fico de entrada  necesario, utilizando una regla encadenada en el caso del grupo de seguridad asociado a la instancia de base de datos,  de  manera  que  s\u00f3lo  acepte  tr\u00e1fico  entrante  del protocolo adecuado desde la instancia del servidor web.</li> <li>Con\u00e9ctate con ssh a la instancia de la subred p\u00fablica, y realiza una prueba de conexi\u00f3n al servidor de base de datos, utilizando para ello la aplicaci\u00f3n cliente mysql (que tendr\u00e1s que instalar previamente).</li> </ul> <p>Para entregar</p> <ul> <li>Adjunta   a  la  tarea   un   documento  pdf   con   las   siguientes  capturas:  mapa  de  la  VPC, configuraci\u00f3n  de  las reglas de entrada  de los grupos de seguridad de las dos instancias, conexi\u00f3n al servidor Apache desde un navegador, y conexi\u00f3n al servicio de base de datos desde la instancia del servidor web.</li> </ul> <p>Nota: No es necesario utilizar ACLs de red en esta tarea, el tr\u00e1fico de red se controlar\u00e1 \u00fanicamente con los grupos de seguridad asociados a las instancias, y por el hecho de que el servidor de base de datos residir\u00e1 en una subred privada.</p>"},{"location":"ud03/redpractica03.html#veamos-ahora-el-ejemplo-de-como-hacer-esto","title":"Veamos ahora el ejemplo de c\u00f3mo hacer esto","text":""},{"location":"ud03/redpractica03.html#vpc-con-su-direccionamiento","title":"VPC con su direccionamiento:","text":"<p>Y ahora el direccionamiento de la subred p\u00fablica (la subred privada la crearemos m\u00e1s adelante):</p> <p></p> <p></p> <p>Partiendo de aqu\u00ed, el siguiente objetivo es crear otra subred (que ser\u00e1 la subred privada), utilizando la opci\u00f3n Subredes del Panel de VPC:</p> <p></p> <p>Subred privada (hay que elegir la VPC que acabamos de crear):</p> <p></p> <p>Como se puede comprobar, realmente en ning\u00fan momento estamos indicando que la subred sea privada. Simplemente creamos subredes, y ser\u00e1n las tablas de enrutamiento las que decidan si la subred es p\u00fablica o privada, dependiendo de si \u00e9sta puede alcanzar o no un elemento de red que permita la comunicaci\u00f3n con el exterior.</p> <p>A continuaci\u00f3n, lanzaremos una instancia EC2 en la subred p\u00fablica y otra en la subred privada. Las instancias pueden ser por ejemplo Amazon Linux o Ubuntu, tama\u00f1o t3.micro, con creaci\u00f3n de grupo de seguridad por defecto y clave privada \u2018vockey\u2019. En las opciones para lanzar las instancias, hay que editar la configuraci\u00f3n de red y seleccionar la VPC y subred  en  la  queremos  lanzarla.  Tambi\u00e9n  seleccionaremos  la  opci\u00f3n  para  asignar autom\u00e1ticamente una IP p\u00fablica.</p> <p>En la imagen siguiente se muestra la configuraci\u00f3n para el caso de la instancia EC2 p\u00fablica, para la privada habr\u00eda que cambiar s\u00f3lo la subred:</p> <p></p> <p>Si  intentamos  conectarnos  por  ssh  a  la  instancia  desplegada  en  la  subred  privada utilizando su direcci\u00f3n ip p\u00fablica, comprobaremos que no es posible el acceso. La subred privada no est\u00e1 asociada de ninguna manera con la subred con el Internet Gateway para poder enrutar el tr\u00e1fico al exterior.</p> <p>Si comprobamos la tabla de enrutamiento asociada a la VPC (desde el panel de VPC, opci\u00f3n Tablas de enrutamiento), podremos ver en la pesta\u00f1a de asociaciones de subred, que \u00fanicamente tenemos la subred p\u00fablica asociada a la tabla de enrutamiento:</p> <p></p> <p>La subred privada aparece en la pesta\u00f1a \u201cSubredes sin asociaciones expl\u00edcitas\u201d, lo que quiere decir que est\u00e1 preparada para ser a\u00f1adida a la tabla de enrutamiento, pero a\u00fan no lo hemos hecho.</p> <p>B\u00e1sicamente lo que pretendemos es hacer que la subred privada salga al exterior a trav\u00e9s de la subred p\u00fablica. Para ello, cada subred tiene su propia tabla de enrutamiento, y en el caso de la subred p\u00fablica existe una ruta hacia el Gateway de Internet para poder salir al exterior:</p> <p></p> <p>En este punto podr\u00edamos conectarnos por ssh a la instancia de la red p\u00fablica y hacer ping a www.google.es y deber\u00eda funcionar:</p> <p></p> <p>Tambi\u00e9n podemos conectarnos por ssh desde la instancia en la subred p\u00fablica a la instancia de la subred privada y probar el mismo comando ping, que obviamente no funcionar\u00e1 todav\u00eda. En el siguiente punto veremos c\u00f3mo hacer esta conexi\u00f3n ssh a la instancia EC2 de la subred privada, \u2018saltando\u2019 desde la instancia p\u00fablica.</p>"},{"location":"ud03/redpractica03.html#conexion-ssh-a-las-instancias-publica-y-privada","title":"Conexi\u00f3n SSH a las instancias p\u00fablica y privada","text":"<p>A continuaci\u00f3n, veremos c\u00f3mo hacer la conexi\u00f3n ssh a las instancias EC2 utilizando la misma clave privada,  sin  necesidad  de  copiar  la  clave  privada  (labsuser.pem)  a  la instancia  p\u00fablica  (tambi\u00e9n  se  podr\u00eda  hacer usando diferentes credenciales de acceso, pero aprovecharemos que las dos instancias se han creado con la misma clave \u2018vockey\u2019). Para ello utilizaremos el reenv\u00edo de agente SSH, que permitir\u00e1 conectarnos desde un host basti\u00f3n en una subred p\u00fablica a la instancia privada.</p> <p>Seguiremos los pasos indicados  para  equipos  Linux.  En sistemas Windows,  se puede utilizar el programa PuTTY (puedes consultar este  art\u00edculo  donde se detalla c\u00f3mo realizar la conexi\u00f3n a una EC2 con Linux desde un host basti\u00f3n).  En primer lugar, comprobamos que las claves privadas tienen los permisos adecuados. Luego, desde el terminal ejecutaremos los siguientes comandos:</p> <p>Ejecutamos ssh-agent en segundo plano:</p> <p><code>eval $(ssh-agent)</code></p> <p>Cargamos en memoria la clave privada de la instancia:</p> <p><code>ssh-add labsuser.pem</code></p> <p>Podemos ver las claves a\u00f1adidas al agente ssh mediante el comando:</p> <p><code>ssh-add -l</code></p> <p>Nos conectamos en primer lugar a la instancia de la subred p\u00fablica. Con la opci\u00f3n -A, las claves se mantienen en memoria, y no es necesario utilizar la opci\u00f3n -i para indicar la clave (utiliza el nombre de usuario</p> <p>adecuado seg\u00fan la AMI de la instancia):</p> <p><code>ssh -A ec2-user@direcci\u00f3n-ip-p\u00fablica</code></p> <p>Una vez conectados a la instancia p\u00fablica, desde ella nos conectamos a la instancia de la subred privada utilizando su direcci\u00f3n IP privada:</p> <p><code>ssh ec2-user@direccion-ip-privada</code></p> <p>Una vez hemos logrado tener acceso a la instancia de la subred privada, si intentamos hacer  por  ejemplo un  ping  a www.google.es,  comprobaremos que  no  funciona. Hasta ahora lo que hemos logrado hacer es llegar hasta la instancia, pero, \u00bfy si la instancia necesita actualizarse o tener acceso a Internet por cualquier motivo? Para esta casu\u00edstica podemos  utilizar  el  servicio  NAT  Gateway ,  que  es  un  servicio  que  permite  que  las instancias de una subred privada puedan conectarse a servicios fuera de la VPC, pero los servicios externos no pueden iniciar una conexi\u00f3n con esas instancias.</p>"},{"location":"ud03/redpractica03.html#creacion-de-un-nat-gateway-y-modificacion-de-la-tabla-de-rutas-de-la-subred-privada","title":"Creaci\u00f3n de un NAT Gateway y modificaci\u00f3n de la tabla de rutas de la subred privada","text":"<p>Lo primero que haremos ser\u00e1 crear un NAT Gateway desde la opci\u00f3n correspondiente del panel de VPC:</p> <p></p> <p>Aqu\u00ed aparece por primera vez el concepto de ip el\u00e1stica. Una ip el\u00e1stica es una direcci\u00f3n ip p\u00fablica est\u00e1tica, que vamos a poder reutilizar en otros servicios.  Es decir, si hubiera un servicio que necesitase de una direcci\u00f3n ip p\u00fablica, o bien podemos utilizar las que AWS asigna por defecto de forma din\u00e1mica, o si ya necesitamos una direcci\u00f3n est\u00e1tica que no cambie (para un servidor web, por ejemplo) se podr\u00eda reutilizar la ip el\u00e1stica creada. Por supuesto,  reservar  direcciones  ip  de  esta  forma  conlleva  un  gasto  asociado, independientemente de que est\u00e9n o no asignadas a recursos. En las cuentas de AWS se pueden utilizar hasta 5 direcciones el\u00e1sticas por regi\u00f3n, aunque se puede solicitar el aumento de este l\u00edmite.</p> <p>El servicio NAT Gateway necesita tener asignado una direcci\u00f3n ip el\u00e1stica, por eso hay que pinchar en la opci\u00f3n de asignar ip el\u00e1stica. La creaci\u00f3n de este elemento de red lleva un rato, y habr\u00e1 que esperar a que est\u00e9 en estado \u201cavailable\u201d. En este caso el NAT Gateway lo vamos a crear en la subred p\u00fablica (ya veremos m\u00e1s adelante el motivo).</p> <p></p> <p>Cabe destacar que el servicio NAT Gateway, al tener una ip el\u00e1stica asociada, supondr\u00e1 un coste adicional incluso cuando apaguemos el laboratorio. Lo mismo pasa con otros servicios  de  AWS  (cuando  paramos el laboratorio, las instancias EC2 se detienen y dejamos de pagar por el uso de CPU, pero seguimos pagando por el almacenamiento asignado a su disco de sistema).</p> <p>A continuaci\u00f3n, vamos a configurar la subred privada para que tenga conexi\u00f3n al exterior. Para ello, primero  vamos  a  crear  una  tabla  de  enrutamiento que  podemos  llamar  \u2018rt- privada\u2019, y despu\u00e9s le asociaremos la subred:</p> <p></p> <p>Cuando se cree la tabla de enrutamiento, le asociaremos la subred privada desde la pesta\u00f1a \u201cAsociaciones de subredes\u201d, haciendo clic en \u201cEditar asociaciones de subredes\u201d:</p> <p></p> <p>Despu\u00e9s, accediendo desde la pesta\u00f1a \u2018Rutas\u2019 de la tabla de enrutamiento, a\u00f1adiremos una ruta para redirigir el tr\u00e1fico que vaya a Internet hacia el NAT Gateway que hemos creado, y \u00e9ste ya se encargar\u00e1 de dar salida hacia Internet:</p> <p></p> <p></p> <p>Ahora podremos hacer dos comprobaciones:</p> <ul> <li>Seguimos sin poder conectarnos por ssh directamente a la ip p\u00fablica de la instancia privada desde una m\u00e1quina local:</li> </ul> <p></p> <p></p> <ul> <li>Si hacemos ping desde la EC2 de la subred privada al exterior, S\u00cd que obtendremos respuesta:</li> </ul> <p></p>"},{"location":"ud03/redpractica03.html#nacl-network-access-control-list","title":"NACL (Network Access Control List)","text":"<p>Una NACL es un componente de seguridad que act\u00faa como un firewall, permitiendo o denegando el tr\u00e1fico entrante o saliente a nivel de subred dentro de una VPC. Hasta ahora hemos estado trabajando con los grupos de seguridad, que son b\u00e1sicamente son firewalls  con  estado  que  podemos  asignar  a  diferentes  recursos en AWS, como una instancia EC2. Con los grupos de seguridad, cuando se establece una conexi\u00f3n entrante, se puede devolver una respuesta sin que sea necesario habilitar una regla de salida que lo permita expl\u00edcitamente. Sin embargo, AWS ofrece otro nivel de seguridad, que son las NACL o ACL de red.</p> <p>A diferencia de las reglas asociadas a un grupo de seguridad, las reglas de NACL son sin estado. Por ejemplo, si queremos que una instancia responda a un ping, a\u00f1adimos en su grupo de seguridad asociado una regla que permita el tr\u00e1fico entrante ICMP. Cuando se realiza el ping, la entrada se permite e impl\u00edcitamente se permite la salida por cualquier puerto, ya que es una conexi\u00f3n establecida. Sin embargo, en el caso de las NACL, este permiso impl\u00edcito NO es dado, hay que configurar tanto las reglas de entrada como las de salida.</p>"},{"location":"ud03/redpractica03.html#escenario-de-prueba","title":"Escenario de prueba","text":"<p>Vamos a comprobar que los grupos de seguridad son capaces de guardar el estado y las ACLs de red no. Para ello, montaremos en una VPC una subred p\u00fablica y lanzaremos una instancia EC2 en dicha subred. Permitiremos la entrada del ping mediante una NACL definida en la subred pero NO la salida, para comprobar que el ping NO sale, y luego m\u00e1s tarde lo permitiremos.</p> <p>Antes de continuar, es recomendable eliminar todo lo que hemos hecho anteriormente para no confundirnos y tener los siguientes conceptos claros. Si no queremos eliminar los recursos individualmente, se puede realizar un reset del laboratorio para eliminar todos los recursos, pero dejar\u00e1 \u00e9ste inaccesible durante un rato.</p> <p>El escenario de prueba es b\u00e1sico, con una VPC con una sola subred p\u00fablica que enrutar\u00e1 el tr\u00e1fico externo mediante un Gateway de Internet:</p> <p></p>"},{"location":"ud03/redpractica03.html#creacion-de-la-vpc-e-instancia-ec2","title":"Creaci\u00f3n de la VPC e instancia EC2","text":"<p>Lo primero es crear la VPC junto con la subred. Nos podemos guiar con las siguientes capturas:</p> <p></p> <p>Una vez creada la infraestructura de red, pasaremos a lanzar la instancia dentro de la subred en la VPC reci\u00e9n creada:</p> <p></p> <p>Una vez la instancia est\u00e9 en ejecuci\u00f3n, podemos probar que podemos acceder por ssh, y a continuaci\u00f3n salir y probar a hacer un ping desde nuestra m\u00e1quina local a la instancia:</p> <p></p> <p>A continuaci\u00f3n, modificaremos el grupo de seguridad asociado a la instancia para permitir tr\u00e1fico ICMP entrante desde cualquier sitio, y comprobar que el ping funciona. Una vez hecha esta comprobaci\u00f3n, a\u00f1adiremos una capa adicional de seguridad a nivel de subred con reglas ACL.</p> <p>Hay  que  tener  en  cuenta  que  en  los  grupos  de  seguridad,  por  defecto  todo  el  tr\u00e1fico entrante se deniega, y se permite todo el de salida. Por lo tanto, daremos permiso al protocolo ICMP en una regla de entrada y salida del ping y luego denegaremos la salida del ping y ver como ya no responde.</p> <p>El  grupo de  seguridad  asociado  a  la  instancia  EC2  configurado para  permitir el  ping tendr\u00eda un aspecto como el siguiente:</p> <p></p> <p>Observamos en las reglas de salida que todo el tr\u00e1fico est\u00e1 permitido:</p> <p></p> <p>En este punto, podemos probar de nuevo el ping de la m\u00e1quina local a la EC2, y veremos que funciona.</p> <p>Para comprobar que los grupos de seguridad \u2018recuerdan\u2019 las peticiones entrantes, vamos a eliminar la regla que permite toda la salida de todo el tr\u00e1fico. Para ello, editamos las reglas de salida del grupo de seguridad:</p> <p></p> <p>Una vez eliminada la regla, comprobamos que no hay reglas de salida:</p> <p></p> <p>Si volvemos a probar el ping, comprobaremos que sigue funcionando incluso, despu\u00e9s de eliminar la regla de tr\u00e1fico de salida. Las ACL de red nos van a permitir tener un mayor control sobre el tr\u00e1fico entrante y saliente a una subred, a cambio de una mayor sobrecarga en las tareas de administraci\u00f3n.</p>"},{"location":"ud03/redpractica03.html#creacion-de-una-acl-de-red-nacl","title":"Creaci\u00f3n de una ACL de red (NACL)","text":"<p>En el momento de la creaci\u00f3n de la VPC, la subred, y la tabla de rutas correspondiente, tambi\u00e9n se ha creado una ACL de red predeterminada asociada a nuestra subred, aunque es posible crear m\u00e1s ACLs desde el panel de VPC, opci\u00f3n ACL de red. Podemos observar la ACL de red por defecto asociada a nuestra subred:</p> <p></p> <p></p> <p>Cada subred de una VPC debe estar asociada a una ACL de red. Si no asociamos una subred de forma expl\u00edcita a una ACL de red, la subred se asociar\u00e1 de manera autom\u00e1tica a la ACL de red predeterminada, que por defecto permite todo el tr\u00e1fico  de  entrada y salida de la subred. Se puede crear una ACL de red personalizada y asociarla a una subred para permitir o denegar el tr\u00e1fico entrante o saliente espec\u00edfico a nivel de subred. Adem\u00e1s, es posible asociar una ACL de red con varias subredes, pero una subred s\u00f3lo puede asociarse a una ACL de red a la vez. Al asociar una ACL de red a una subred, se quita la asociaci\u00f3n anterior.</p> <p>A continuaci\u00f3n crearemos el NACL en la VPC con la que estamos trabajando y le asociaremos la subred, lo que eliminar\u00e1 la asociaci\u00f3n con la NACL predeterminada:</p> <p></p> <p>Y comprobamos que tiene asociada la subred p\u00fablica desde la pesta\u00f1a \u201cAsociaciones de subredes\u201d:</p> <p></p> <p>Si observamos las reglas de entrada y salida de la NACL reci\u00e9n creada, comprobaremos que por defecto se deniega todo el tr\u00e1fico de entrada y salida a la subred:</p> <p></p> <p>Podemos a\u00f1adir y eliminar reglas de entrada y salida. Las reglas se eval\u00faan comenzando por la regla de n\u00famero m\u00e1s bajo. En cuanto una regla coincide con el tr\u00e1fico, esta se aplica  independientemente  de  cualquier  regla  con  un  n\u00famero  mayor  que  pueda contradecirla.</p> <p>Desde el men\u00fa ACL de red, vamos a modificar las reglas de entrada y salida y realizar las siguientes pruebas:</p> <ul> <li>A\u00f1adir regla de entrada ICMP. Desde la regla NACL, en la pesta\u00f1a Reglas de Entrada, Editamos las reglas de entrada:</li> </ul> <p></p> <p>A\u00f1adimos una nueva regla de entrada, con n\u00famero 100 (se recomiendan incrementos de 10 o 100), permitiendo el tr\u00e1fico ICMP desde cualquier origen:</p> <p></p> <p>Y ahora ya nos aparece la nueva regla:</p> <p></p> <p>Como  hemos  comentado  anteriormente,  las  reglas  se  eval\u00faan  con  una  prioridad ascendente, y en cuanto se satisface, ya no se comprueban las de menor prioridad.</p> <p>Comprobamos que el ping NO funciona:</p> <p></p> <ul> <li>Ahora a\u00f1adiremos la regla de salida ICMP en la correspondiente regla de salida NACL, para despu\u00e9s comprobar que el ping SI funciona:</li> </ul> <p></p> <p></p>"},{"location":"ud03/redpractica03.html#reglas-encadenadas-en-grupos-de-seguridad","title":"Reglas encadenadas en grupos de seguridad","text":"<p>Las reglas que regulan el tr\u00e1fico de red en los grupos de seguridad se pueden encadenar, de manera que podemos restringir el tr\u00e1fico permiti\u00e9ndolo \u00fanicamente cuando proviene de un grupo de seguridad determinado.</p> <p>Para probar este concepto, lo que vamos a hacer es crear un nuevo grupo de seguridad (con el nombre \u2018gs-encadenado\u2019, por ejemplo) y a\u00f1adir una nueva regla de entrada que permitir\u00e1 el tr\u00e1fico ICMP, asign\u00e1ndole como origen el grupo de seguridad que tiene asociado la instancia que tenemos lanzada:</p> <p></p> <p>A continuaci\u00f3n, lanzamos una nueva instancia EC2 en la misma subred que la primera, y le  asignamos el nuevo grupo de seguridad \u2018encadenado\u2019, en lugar de crear un nuevo grupo de seguridad:</p> <p>Y cuando queramos por ejemplo hacer un ping desde la m\u00e1quina local, veremos que no lo permite:</p> <p></p> <p>Sin embargo, si nos conectamos a la primera instancia por ssh y hacemos un ping a la direcci\u00f3n IP privada de la segunda instancia, comprobaremos que s\u00ed hay respuesta al ping:</p> <p></p> <p>En definitiva, combinando reglas encadenadas de grupos de seguridad y NACLs, es posible controlar de manera exhaustiva todo el tr\u00e1fico que entra y sale en nuestra VPC y los recursos desplegados en ella.</p>"},{"location":"ud03/redpractica04.html","title":"Pr\u00e1ctica 3. Creaci\u00f3n de VPC con CLI","text":""},{"location":"ud03/redpractica04.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear la misma VPC que en ejercicios anteriores pero utilizando CLI. Se adjunta un script de ejemplo en el cual se realizan las acciones:</p> <ul> <li>Creaci\u00f3n de una VPC.</li> <li>Habilitar DNS en la VPC.</li> <li>Creaci\u00f3n de una subred.</li> <li>Creaci\u00f3n de un grupo de seguridad y apertura de un puerto.</li> <li>Creaci\u00f3n de una instancia EC2.</li> <li>Creaci\u00f3n Internet Gateway y guardado de ID.</li> <li>Se adjunta el IGW a la VPC.</li> <li>Se crear tablas de rutas y se guardan sus ID.</li> <li>Se agregan una ruta para salida a internet.</li> <li>Se asocia la tabla de rutas a la subred.</li> </ul>"},{"location":"ud03/redpractica04.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":"<p>Tienes que descargar el siguiente script:</p> LinuxWindows <p>script Creaci\u00f3n VPC para Linux</p> <p>script Creaci\u00f3n VPC para Windows</p>"},{"location":"ud03/redpractica04.html#parte-1-modificacion-del-script-de-creacion-de-la-vpc-y-la-ec2","title":"Parte 1. Modificaci\u00f3n del script de creaci\u00f3n de la VPC y la EC2","text":"<p>La pr\u00e1ctica consiste en modificar el script para que la VPC la cree con la direcci\u00f3n <code>192.168.0.0/16</code> y la subred que hay dentro de ella la cree con la direcci\u00f3n <code>192.168.3.0/24</code>.</p> <p>Atenci\u00f3n</p> <p>F\u00edjate que la instancia EC2 del script de ejemplo se crea con una IP fija dentro de la subred.</p> <p>Ejecuta el script. Para poder ejecutarlo tendr\u00e1s que autenticarte primero con la informaci\u00f3n de la sesi\u00f3n actual de tu laboratorio. Comprueba que se crean los elementos indicados anteriormente.</p>"},{"location":"ud03/redpractica04.html#parte-2-creacion-de-una-subred-y-otra-maquina-ec2","title":"Parte 2. Creaci\u00f3n de una subred y otra m\u00e1quina EC2","text":"<p>Esta parte se hace desde la consola gr\u00e1fica de AWS</p> <p>Debes crear una instancia EC2 en otra subred de nombre \u201csubred-tunombre\u201d y hacer un ping de una m\u00e1quina a otra.</p> <p>Para comprobar el ping, primero deber\u00e1s conectarte por ssh a la primera m\u00e1quina y hacer un ping a la segunda m\u00e1quina de manera local (el ping funciona).</p> <p>Deber\u00e1s modificar el grupo de seguridad creado y permitir el protocolo ICMP. Normalmente las instancias tienen grupos de seguridad diferentes, pero en este caso como la configuraci\u00f3n es muy sencilla, en la nueva m\u00e1quina EC2 puedes reutilizar el grupo de seguridad y permitir el ping.</p> <p>Atenci\u00f3n</p> <p>F\u00edjate que cuando cambias de sesi\u00f3n el token del cli tambi\u00e9n te cambia, es decir, debes cambiar las credentials tal como hiciste en la pr\u00e1ctica  La interfaz de Linea de comandos . </p> <p>Captura las pantallas</p> <p>Resultado de la ejcuci\u00f3n del script</p> <p>Mapa de recursos de la vpc creada</p> <p>Direcciones ip privadas de las instancias</p> <p>Ping de una instancia a la otra</p>"},{"location":"ud03/vpc.html","title":"Creaci\u00f3n de un entorno de red","text":""},{"location":"ud03/vpc.html#es-necesaria-una-arquitectura-de-red-en-la-nube-de-aws","title":"\u00bfEs necesaria una arquitectura de red en la nube de AWS?","text":"<p>La necesidad de una arquitectura de red en AWS no es una cuesti\u00f3n secundaria, sino una decisi\u00f3n estrat\u00e9gica fundamental. Esta arquitectura impacta directamente en el rendimiento, la seguridad y la capacidad de crecimiento de cualquier soluci\u00f3n tecnol\u00f3gica desplegada en la nube. Los siguientes pilares justifican claramente su implementaci\u00f3n</p>"},{"location":"ud03/vpc.html#escalabilidad","title":"Escalabilidad","text":"<p>Una arquitectura de red bien dise\u00f1ada en AWS permite escalar los recursos de forma autom\u00e1tica y seg\u00fan la demanda, sin comprometer la continuidad operativa.</p> <p>Servicios como Amazon VPC, Auto Scaling, Elastic Load Balancing y Route 53 permiten distribuir el tr\u00e1fico de manera eficiente y agregar ecursos de computaci\u00f3n sin redise\u00f1ar toda la infraestructura. Elementos como Elastic IPs, subredes en m\u00faltiples zonas de disponibilidad y recursos el\u00e1sticos garantizan disponibilidad incluso ante aumentos s\u00fabitos de tr\u00e1fico.</p> <p>Adem\u00e1s, esta arquitectura permite escalar horizontalmente (a\u00f1adiendo m\u00e1s instancias) o verticalmente (potenciando las existentes) sin nterrumpir los servicios en producci\u00f3n.</p>"},{"location":"ud03/vpc.html#seguridad","title":"Seguridad","text":"<p>AWS permite implementar una estrategia de seguridad multicapa, desde el nivel de red hasta el de la aplicaci\u00f3n. A trav\u00e9s de VPCs configurables, subredes segmentadas, grupos de seguridad y listas de control de acceso (NACLs), es posible definir reglas precisas para controlar el tr\u00e1fico. Adem\u00e1s posee servicios que protegen frente a amenazas externas y ataques DDoS.</p> <p>La infraestructura puede reforzarse mediante conexiones cifradas (VPN, Direct Connect), lo que asegura la confidencialidad de la nformaci\u00f3n en tr\u00e1nsito.</p>"},{"location":"ud03/vpc.html#conectividad","title":"Conectividad","text":"<p>La arquitectura de red en AWS facilita la integraci\u00f3n fluida entre distintos recursos, ya sea en la nube o en entornos h\u00edbridos.</p> <p>Soluciones como VPC Peering, Transit Gateway y PrivateLink permiten conectar instancias, bases de datos, contenedores y otros servicios sin fricci\u00f3n. Tambi\u00e9n es posible establecer conectividad h\u00edbrida mediante t\u00faneles VPN cifrados o AWS Direct Connect.</p> <p>Por otro lado, servicios como AWS Global Accelerator optimizan la velocidad de acceso para usuarios distribuidos geogr\u00e1ficamente, mejorando la experiencia del cliente final.</p> <p>Dise\u00f1ar una arquitectura de red s\u00f3lida en AWS no es una opci\u00f3n, sino un requisito. Esta arquitectura constituye el cimiento que permite que las soluciones cloud sean escalables, seguras y conectadas. De su planificaci\u00f3n depende en gran medida la disponibilidad del servicio, la protecci\u00f3n de los datos y la agilidad de la organizaci\u00f3n para adaptarse a nuevos desaf\u00edos.</p>"},{"location":"ud03/vpc.html#los-servicios-que-ofrece-aws-para-gestionar-las-redes-son","title":"Los servicios que ofrece AWS para gestionar las redes son:","text":"<p>Amazon Virtual Private Cloud (Amazon VPC): permite aprovisionar secciones aisladas de forma l\u00f3gica de la nube de AWS.</p> <p>Elastic Load Balancing: distribuye autom\u00e1ticamente el tr\u00e1fico entrante de las aplicaciones en varios destinos, tales como instancias de Amazon EC2, contenedores, direcciones IP y funciones Lambda.</p> <p>Amazon CloudFront: servicio r\u00e1pido de red de entrega de contenido (CDN) que suministra datos, videos, aplicaciones y APIs de manera segura a clientes de  todo el mundo, con baja latencia y altas velocidades de transferencia.</p> <p>AWS Transit Gateway: servicio que permite a los clientes conectar sus nubes privadas virtuales de Amazon (VPC) y sus redes en las instalaciones ( on-premise ) a un \u00fanico gateway .</p> <p>Amazon Route 53: servicio web de DNS escalable y en la nube dise\u00f1ado para direccionar a los usuarios finales a las aplicaciones de Internet de    una forma confiable.</p> <p>AWS Global Accelerator: utiliza las ubicaciones de borde para encontrar la ruta \u00f3ptima a la regi\u00f3n donde reside nuestra aplicaci\u00f3n (haciendo uso tanto de protocolos HTTP como TCP/UDP).</p> <p>AWS Direct Connect: ofrece una manera de establecer una conexi\u00f3n de red privada dedicada desde un centro de datos u oficina a AWS, lo que puede reducir los costes de red y aumentar el rendimiento del ancho de  banda.</p> <p>AWS VPN: proporciona un t\u00fanel privado seguro desde una red o dispositivo a la red global de AWS.</p> <p>Haciendo usos de esos servicios se puede mostrar una soluci\u00f3n sencilla:</p> <p></p>"},{"location":"ud03/vpc.html#redes-en-aws","title":"Redes en AWS","text":"<p>Suponemos que los conceptos de red, subred y direcci\u00f3n IP y el modelo de la OSI est\u00e1n claros.</p> <p>Dentro de AWS se utiliza el m\u00e9todo CIDR para describir redes, por ejemplo,\u00a0<code>192.0.2.0/24</code>\u00a0(los primeros 24 bits son est\u00e1ticos, y los \u00faltimos 8 flexibles). </p> <p>Nota</p> <p>Cabe destacar que AWS reserva las primeras cuatro direcciones IP y la \u00faltima direcci\u00f3n IP de cada subred para fines de redes internas. </p> <p>Por ejemplo, una subred <code>/28</code> tendr\u00eda 16 direcciones IP disponibles. De ah\u00ed hay que restar las 5 IP reservadas por AWS, obteniendo 11 direcciones IP para nuestro uso dentro de la subred.</p> <p>Muchos de los conceptos de redes f\u00edsicas son v\u00e1lidos para las redes  cloud, con la ventaja que en la nube nos ahorraremos gran parte de la complejidad.</p>"},{"location":"ud03/vpc.html#amazon-vpc","title":"Amazon VPC","text":"<p>AWS utiliza las VPC (AmazonVirtual Private Cloud ) como redes privadas virtuales donde est\u00e1n conectados todos los recursos con los que trabajamos, de manera que el acceso queda aislado de otros usuarios. Dicho de otro modo, Amazon VPC permite lanzar recursos de AWS en la red virtual que definamos. Esta red virtual se asemeja en gran medida a una red tradicional que ejecutar\u00edamos en nuestro propio centro de datos, con los beneficios de utilizar la infraestructura escalable de AWS, pudiendo crear una VPC que abarque varias AZ.</p> <p>Al definir la red virtual podemos seleccionar nuestro propio intervalo de direcciones IP, crear subredes y configurar las tablas de enrutamiento y gateways de red. Tambi\u00e9n podemos colocar el\u00a0backend\u00a0(servidores de aplicaciones o de bases de datos) en una subred privada sin acceso a Internet p\u00fablico. Finalmente, podemos a\u00f1adir varias capas de seguridad, como grupos de seguridad y listas de control de acceso a la red (ACL de red), para ayudar a controlar el acceso a las instancias de EC2 en cada subred.</p> <p>Sin entrar en mayor detalle, vamos a repasar algunos de los componentes m\u00e1s importantes:</p>"},{"location":"ud03/vpc.html#gateway-de-internet-igw","title":"Gateway de Internet\u00a0(IGW)","text":"<p>Un\u00a0gateway de Internet\u00a0(Internet Gateway, IGW) es un componente de la VPC que permite la comunicaci\u00f3n entre instancias de la VPC e Internet. </p> <p>Un caso espec\u00edfico es un Gateway NAT(o Nat Gateway), que se utiliza para proporcionar conectividad a Internet a instancias EC2 en las subredes privadas.</p> <p>Despu\u00e9s de crear una VPC, podemos agregar subredes. Cada\u00a0subred\u00a0est\u00e1 ubicada por completo dentro de una zona de disponibilidad y no puede abarcar otras zonas. </p> <p>Si el tr\u00e1fico de una subred se direcciona a un Internet Gateway, la subred recibe el nombre de subred   p\u00fablica. Si una subred no dispone de una ruta al\u00a0Internet Gateway, recibe el nombre de subred privada.</p> <p>Para que las subredes privadas puedan conectarse a Internet dirigiendo el tr\u00e1fico al\u00a0NAT Gateway hemos de configurar las tablas enrutamiento.</p>"},{"location":"ud03/vpc.html#tabla-de-enrutamiento","title":"Tabla de enrutamiento","text":"<p>Una\u00a0tabla de enrutamientocontiene un conjunto de reglas, llamadas rutas, que se utilizan para   determinar el destino del tr\u00e1fico de red. Cada subred de una VPC debe estar asociada a una tabla de enrutamiento, que es la que controla el direccionamiento de la subred. Las reglas de las tablas de enrutamiento se colocan de m\u00e1s a menos restrictivas. Tienen una ruta local integrada, la cual no se puede eliminar. Las rutas adicionales se agregan a la tabla.</p>"},{"location":"ud03/vpc.html#grupo-de-seguridad","title":"Grupo de seguridad","text":"<p>Las VPC utilizan un grupo de seguridad que act\u00faa como un\u00a0firewall\u00a0virtual.</p> <p>Cuando se lanza una instancia, se asocia uno o varios grupos de seguridad a ella. Los grupos de seguridad tienen reglas que controlan el tr\u00e1fico de entrada y de salida de las instancias, las  cuales podemos modificar. </p> <p>Atenci\u00f3n</p> <p>Los grupos de seguridad predeterminados deniegan todo el tr\u00e1fico de entrada y permiten todo el tr\u00e1fico de salida.</p> <p>A continuaci\u00f3n veremos algunas pr\u00e1cticas de creaci\u00f3n de VPC que nos ayudar\u00e1n a entender y afianzar estos conceptos.</p>"},{"location":"ud04/practica1.html","title":"Pr\u00e1ctica 1. Creaci\u00f3n de un bucket en Amazon S3","text":"<p>Creaci\u00f3n y gesti\u00f3n de un bucket en Amazon S3: subida de objetos, control de permisos y versiones.</p> <p></p>"},{"location":"ud04/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento de Amazon S3 como servicio de almacenamiento de objetos.</li> <li>Aprender a crear y configurar un bucket en una regi\u00f3n determinada.</li> <li>Subir archivos y gestionar su acceso mediante ACLs.</li> <li>Acceder a un objeto p\u00fablico a trav\u00e9s de su URL en el navegador.</li> <li>Activar el control de versiones y comprobar c\u00f3mo mantiene distintas versiones de un mismo archivo.</li> </ul>"},{"location":"ud04/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud04/practica1.html#creacion-del-bucket","title":"Creaci\u00f3n del bucket","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio S3.</p> <ul> <li>Pulsa en \u201cCrear bucket\u201d.</li> <li> <p>Especifica:</p> <ul> <li>Tipo de bucket: Uso general.</li> <li>Nombre del bucket: debe ser \u00fanico en todo el mundo (por ejemplo: <code>practica-s3-nombrealumno</code>).</li> </ul> </li> <li> <p>Deja todos los dem\u00e1s campos por defecto.</p> </li> <li>Crea el bucket pulsando \u201cCrear bucket\u201d.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#subida-de-objetos","title":"Subida de objetos","text":"<p>2.- Entra en el bucket reci\u00e9n creado para a\u00f1adir contenidos:</p> <ul> <li>Pulsa \u201cCargar\u201d \u2192 \u201cA\u00f1adir archivos\u201d y selecciona 2 o 3 im\u00e1genes en formato jpg de tu equipo. Por ejemplo <code>foto1.jpg</code> y <code>foto2.jpg</code></li> <li>Haz clic en \u201cCargar\u201d para subirlas.</li> <li>Prueba a cargar tambi\u00e9n una carpeta con archivos dentro.</li> <li>Comprueba que aparecen en la lista de objetos.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#acceso-mediante-url","title":"Acceso mediante URL","text":"<p>3.- Vamos a acceder a uno de los objetos reci\u00e9n subidos, por ejemplo <code>foto1.jpg</code>, desde un navegador especificicando su url:</p> <ul> <li>Ve a la pesta\u00f1a \u201cPropiedades\u201d del objeto <code>foto1.jpg</code></li> <li>Copia la URL del objeto (por ejemplo:    <code>https://practica-s3-nombrealumno.s3.us-east-1.amazonaws.com/foto1.jpg</code>)</li> </ul> <p></p> <ul> <li>Abre un navegador web y pega la URL.</li> <li>Comprueba que la imagen no se muestra correctamente al no disponer de permisos.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#desbloquear-el-acceso-publico","title":"Desbloquear el acceso p\u00fablico","text":"<p>4.- Vamos ahora a desbloquear la restricci\u00f3n de acceso p\u00fablico al bucket. Lo podr\u00edamos haber hecho en el momento de creaci\u00f3n. Para ello, en la pantalla del bucket accedemos a la pesta\u00f1a Permisos y editamos la opci\u00f3n de Bloquear acceso p\u00fablico.</p> <p></p> <p>Desmarcamos todas las opciones. Nos pide que confirmemos.</p> <p></p> <p>Atenci\u00f3n</p> <p>En entornos reales no se deben dejar objetos p\u00fablicos.</p> <p>Si accedemos de nuevo desde un navegador a la url del objeto veremos que continuamos sin poder acceder al objeto, a pesar de haber hecho p\u00fablico el bucket. A\u00fan nos falta un paso m\u00e1s.</p>"},{"location":"ud04/practica1.html#cambio-de-permisos-mediante-acl","title":"Cambio de permisos mediante ACL","text":"<p>5.- Las pol\u00edticas de acceso a los objetos se pueden controlar de varias maneras (ACLs, Pol\u00edticas, Roles). Vamos a hacerlo por una opci\u00f3n m\u00e1s sencilla pero que AWS no recomienda: mediante ACLs (listas de control de acceso). Para ello el primer paso ser\u00e1 habilitar las ACLs que por defecto aparecen deshabilitadas. Este paso tambi\u00e9n podr\u00edamos haberlo hecho al crear el bucket.</p> <ul> <li>Vuelve a seleccionar el bucket en S3.</li> <li>En la pesta\u00f1a \u201cPermisos\u201d, busca la secci\u00f3n \u201cPropiedades de los objetos\u201d.</li> <li>Pulsa en \u201cEditar\u201d y habilita las ACLs.</li> </ul> <p></p> <p>6.- Una vez habilitadas las ACL, vamoa a hacer p\u00fablico el objeto en particular:</p> <ul> <li>Seleccionam el objeto <code>foto1.jpg</code> </li> <li>En el men\u00fa Acciones selecciona Hacer p\u00fablico mediante ACL.</li> <li>Comprueba que ya puedes acceder desde el navegador a la url p\u00fablica del objeto.</li> </ul> <p></p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el acceso desde el navegador a la imagen. Debe verse la url del objeto y la fotograf\u00eda mostrada dentro del navegador.</p>"},{"location":"ud04/practica1.html#activar-el-control-de-versiones","title":"Activar el control de versiones","text":"<p>Amazon S3 incorpora una funcionalidad que permite mantener m\u00faltiples versiones de un objeto en el mismo bucket, protegiendo contra eliminaciones o modificaciones no deseadas. Cuando se habilita, S3 conserva una versi\u00f3n anterior del objeto cada vez que se modifica o elimina. Esto permite recuperar y restaurar f\u00e1cilmente versiones anteriores de un objeto en cualquier momento</p> <ul> <li>Regresa a la vista principal del bucket.</li> <li>En la pesta\u00f1a \u201cPropiedades\u201d, busca la secci\u00f3n \u201cControl de versiones\u201d.</li> <li>Pulsa \u201cEditar\u201d \u2192 activa el control de versiones \u2192 Guardar cambios.</li> </ul>"},{"location":"ud04/practica1.html#probar-el-control-de-versiones","title":"Probar el control de versiones","text":"<ul> <li>Sube de nuevo una imagen con el mismo nombre que una ya existente (por ejemplo <code>foto1.jpg</code>).</li> <li>S3 no reemplazar\u00e1 la imagen anterior, sino que guardar\u00e1 una nueva versi\u00f3n.</li> <li>Ve al objeto y selecciona la pesta\u00f1a \u201cVersiones\u201d para ver las distintas versiones almacenadas.</li> <li>Prueba a descargar o restaurar la versi\u00f3n anterior.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestren las distintas versiones del archivo.</p>"},{"location":"ud04/practica2.html","title":"Pr\u00e1ctica 2. Publicaci\u00f3n de una web est\u00e1tica en S3","text":"<p>Publicaci\u00f3n de un sitio web est\u00e1tico en Amazon S3 con control de acceso mediante pol\u00edticas de bucket.</p>"},{"location":"ud04/practica2.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del alojamiento web est\u00e1tico en Amazon S3.</li> <li>Aprender a crear un bucket, subir un sitio web y habilitar su acceso p\u00fablico mediante una pol\u00edtica de bucket.</li> <li>Configurar S3 para que sirva p\u00e1ginas web (HTML, CSS, im\u00e1genes, etc.) directamente.</li> <li>Comprobar el acceso al sitio web a trav\u00e9s de una URL p\u00fablica de S3.</li> </ul>"},{"location":"ud04/practica2.html#preparacion-del-material","title":"Preparaci\u00f3n del material","text":"<p>1.- En primer lugar vamos a descargar desde GitHub un repositorio con una web de muestra. Lo haremos en un fichero <code>.zip</code> el cual habr\u00e1 que descomprimir:</p> <ul> <li>Accede al repositorio de GitHub que contiene una web de muestra:    <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> <li>Descarga el repositorio en formato ZIP pulsando en Code \u2192 Download ZIP.</li> <li>Descomprime el archivo ZIP en tu equipo local. Deber\u00edas tener una carpeta con archivos como <code>index.html</code>, <code>assets/</code>, etc.</li> </ul>"},{"location":"ud04/practica2.html#creacion-del-bucket","title":"Creaci\u00f3n del bucket","text":"<p>2.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio S3. Crea un bucket:</p> <ul> <li>Que el bucket sea de uso general.</li> <li>Pon un nombre del bucket \u00fanico, por ejemplo, <code>web-estatica-nombrealumno</code>.</li> <li>Deja deshabilitadas las ACL.</li> <li>Haz que el acceso al bucket sea p\u00fablico, desmarca la casilla \u201cBloquear todo el acceso p\u00fablico\u201d.</li> </ul> <p>Atenci\u00f3n</p> <p>Ya sabemos que hacer el bucket p\u00fablico es una pr\u00e1ctica peligrosa, pero en este caso no tenemos elecci\u00f3n.</p>"},{"location":"ud04/practica2.html#subir-los-archivos-de-la-web","title":"Subir los archivos de la web","text":"<p>3.- Entra en el bucket creado y carga los archivos descomprimidos.</p> <p>Atenci\u00f3n</p> <p>A la hora de subir el contenido no subas directamente la carpeta <code>hello-cloud-main</code> sino \u00fanicamente los ficheros y carpetas que hay en su interior, asegur\u00e1ndote que el fichero <code>index.html</code> y el resto de archivos y carpetas de ese nivel quedan en la ra\u00edz del bucket.</p>"},{"location":"ud04/practica2.html#activar-el-alojamiento-web-estatico","title":"Activar el alojamiento web est\u00e1tico","text":"<p>4.- Con el contenido ya cargado, vamos a activar el alojamiento web est\u00e1tico. Para ello, en la vista del bucket, ve a la pesta\u00f1a \u201cPropiedades\u201d:</p> <ul> <li>En la secci\u00f3n \u201cAlojamiento de sitio web est\u00e1tico\u201d haz clic en \u201cEditar\u201d \u2192 selecciona \u201cHabilitar\u201d.</li> <li>En Documento de \u00edndice escribe: <code>index.html</code></li> <li>Copia la URL del sitio web que aparece (por ejemplo: <code>http://web-estatica-nombrealumno.s3-website-eu-west-1.amazonaws.com</code>).</li> </ul>"},{"location":"ud04/practica2.html#configurar-la-politica-del-bucket","title":"Configurar la pol\u00edtica del bucket","text":"<p>5.- Si intentamos acceder a la url de la p\u00e1gina web est\u00e1tica nos dar\u00e1 un error de permisos, pues no es suficiente con hacer p\u00fablico el bucket. Es necesario que adem\u00e1s concedamos permisos. En la pr\u00e1ctica anterior vimo c\u00f3mo cambiar estos permisos mediante ACLs, pero AWS nos recomienda que lo hagamos por pol\u00edticas. En esta pr\u00e1ctica vamos a cambiar los permisos mediante pol\u00edticas:</p> <ul> <li>Accede a la pesta\u00f1a Permisos del bucket.</li> <li>Localiza Pol\u00edtica de bucket y pulsa Editar.</li> <li>Pega la siguiente pol\u00edtica en formato JSON, sustituyendo el nombre del bucket por el tuyo:</li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"PublicReadGetObject\",\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:GetObject\",\n      \"Resource\": \"arn:aws:s3:::web-estatica-nombrealumno/*\"\n    }\n  ]\n}\n</code></pre> <p>Esta pol\u00edtica <code>s3:GetObject</code> junto con la opci\u00f3n <code>Allow</code> permite que cualquiera (<code>*</code>) pueda leer los archivos del bucket, pero no modificarlos ni borrarlos.</p> <p>El recurso <code>\"Resource\": \"arn:aws:s3:::web-estatica-nombrealumno/*\"</code> indica el arn del bucket seguido de <code>/*</code>, que significa cualquier objeto dentro del bucket.</p> <p>El arn es el Amazon Resource Name, es decir, un identificador \u00fanico que AWS usa para referirse a cualquier recurso dentro de su infraestructura: un bucket S3, una instancia EC2, una funci\u00f3n Lambda, una pol\u00edtica IAM, etc.</p>"},{"location":"ud04/practica2.html#comprobar-el-funcionamiento","title":"Comprobar el funcionamiento","text":"<ul> <li>Abre la URL del sitio web.</li> <li>Si todo est\u00e1 correcto, la p\u00e1gina <code>index.html</code> y el resto del contenido se mostrar\u00e1 p\u00fablicamente.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el aaceso desde el navegador a la web. Debe verse la url y el contenido de la p\u00e1gina web.</p>"},{"location":"ud04/practica3.html","title":"Pr\u00e1ctica 3. Gesti\u00f3n de vol\u00famenes EBS","text":"<p>Creaci\u00f3n de un volumen EBS y montaje en varias instancias EC2.</p> <p>Recuerda</p> <ul> <li>Los vol\u00famenes EBS equivalen a los discos duros virtuales que utilizan las instancias EC2.</li> <li>Un volumen s\u00f3lo puede estar conectado a una instancia simult\u00e1neamente.</li> <li>Pero una instancia puede conectar varios vol\u00fames EBS simult\u00e1neamente.</li> </ul>"},{"location":"ud04/practica3.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del almacenamiento EBS (Elastic Block Store).</li> <li>Crear y asociar un volumen EBS a una instancia EC2.</li> <li>Formatear, montar y usar un volumen EBS desde Linux.</li> <li>Desasociar y reutilizar un volumen en otra instancia.</li> <li>Crear y restaurar una instant\u00e1nea (snapshot) de un volumen.</li> </ul>"},{"location":"ud04/practica3.html#creacion-de-una-instancia-ec2","title":"Creaci\u00f3n de una instancia EC2","text":"<p>1.- Vamos a crear una instancia EC2 sobre la que montaremos el volumen EBS. Configura:</p> <ul> <li>Nombre: <code>Servidor-A</code></li> <li>AMI: Ubuntu</li> <li>Instance type: <code>t2.micro</code></li> <li>Key pair: selecciona o crea uno nuevo</li> <li>Network settings: deja la VPC y subred por defecto</li> <li>Storage: deja el volumen ra\u00edz predeterminado (8 GB)</li> </ul> <p>Importante</p> <p>Recuerda la zona de disponibilidad en la que se ha creado la m\u00e1quina. El volumen EBS que crearemos debe estar necesariamente en la misma AZ que la EC2.</p> <p>2.- Lanza la instancia y espera a que el estado sea Running.</p> <p>3.- Podemos conectarnos por ssh, pero esta vez lo vamos a hacer desde el propio navegador:</p> <ul> <li>Selecciona la instancia <code>Servidor-A</code> y pulsa sobre el bot\u00f3n Conectar</li> <li>En la pesta\u00f1a Conexi\u00f3n de la instancia EC2 pulsa Conectar</li> <li>Nos aparecer\u00e1 una consola de terminal en el navegador conectada a la instancia <code>Servidor-A</code>.</li> </ul> <p></p> <p></p>"},{"location":"ud04/practica3.html#crear-y-adjuntar-un-volumen-ebs","title":"Crear y adjuntar un volumen EBS","text":"<p>4.- Estando en la pantalla de las instancia de EC2, en el panel lateral aparece un men\u00fa Elastic Block Store \u2192 Vol\u00famenes. Accede a \u00e9l y selecciona:</p> <ul> <li>Crear volumen</li> <li>Tipo: gp3</li> <li>Tama\u00f1o: 20 GiB</li> <li>Availability Zone: la misma que tu EC2</li> <li>Deja los valores por defecto que te propone para las IOPS y el Rendimiento.</li> <li>No marques la opci\u00f3n de cifrado</li> </ul> <p>5.- Una vez creado, selecciona el volumen y pulsa sobre Acciones \u2192 Asociar volumen</p> <ul> <li>Instancia: elige la instancia <code>Servidor-A</code></li> <li>Nombre de dispositivo: selecciona uno de la lista, por ejemplo <code>/dev/sdf</code></li> </ul>"},{"location":"ud04/practica3.html#formatear-y-montar-el-volumen","title":"Formatear y montar el volumen","text":"<p>6.- Accede al terminal de la m\u00e1quina EC2 y verifica desde la instancia que se haya detectado el nuevo disco (puedes verificar que el n\u00famero de serie coincide con el de la consola de EBS):</p> <pre><code>lsblk -o NAME,SIZE,SERIAL,TYPE,MOUNTPOINTS\n</code></pre> <p>Atenci\u00f3n</p> <p>Es posible que la m\u00e1quina EC2 no le asigne el nombre <code>/dev/sdf</code> que hemos seleccionado y en su lugar utilice la nomenclatura <code>/dev/nvmeXnY</code> que corresponde a los discos NVME.</p> <p>7.- Formatea el volumen (sustituye por el nombre de dispositivo que te haya asignado):</p> <pre><code>sudo mkfs -t ext4 /dev/nvme1n1\n</code></pre> <p>F\u00edjate que no hemos creado ninguna partici\u00f3n en el disco, sino que hemos creado el sistema de ficheros directamente sobre todo el disco. Esto puede ser peligroso, pero en el caso de los discos EBS no hay problema de hacerlo as\u00ed.</p> <p>8.- Crea un punto de montaje:</p> <p><pre><code>sudo mkdir /datos\n</code></pre> 9.- Monta el volumen:</p> <p><pre><code>sudo mount /dev/nvme1n1 /datos\n</code></pre> 10.- Comprueba:</p> <p><pre><code>df -h\n</code></pre> 11.- Crea un archivo de prueba:</p> <pre><code>echo \"Prueba EBS\" | sudo tee /datos/info.txt\n</code></pre> <p>12.- Muestra el contenido del archivo creado:</p> <pre><code>echo cat /datos/info.txt\n</code></pre>"},{"location":"ud04/practica3.html#desmontar-y-conectar-el-volumen-a-otra-ec2","title":"Desmontar y conectar el volumen a otra EC2","text":"<p>13.- Vamos ahora a desmontar el volumen en <code>Servidor-A</code> para dejarlo disponible para ser utilizado por otra instancia:</p> <pre><code>sudo umount /datos\n</code></pre> <p>14.- En la consola AWS:</p> <ul> <li>Selecciona el volumen EBS y pulsa sobre Desasociar el volumen desde el men\u00fa de acciones.</li> </ul> <p>15.- Crea una segunda instancia EC2 de Ubuntu:</p> <ul> <li>Nombre: <code>Servidor-B</code></li> <li>Importante: Misma AZ que el <code>Servidor-A</code></li> </ul> <p>16.- Una vez en ejecuci\u00f3n, desde el panel de Acciones de EBS, Asociar volumen \u2192 selecciona el mismo volumen EBS creado anteriormente y lo asocias a <code>Servidor-B</code>.</p> <p>17.- Con\u00e9ctate a <code>Servidor-B</code> y monta el volumen:</p> <pre><code>sudo mkdir /datos\n</code></pre> <pre><code>sudo mount /dev/nvme1n1 /datos\n</code></pre> <pre><code>cat /datos/info.txt\n</code></pre> <p>Ver\u00e1s el contenido creado en la otra m\u00e1quina:</p> <pre><code>Prueba EBS\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que han funcionado todos los comandos ejecutados en <code>Servidor-B</code></p>"},{"location":"ud04/practica3.html#crear-y-restaurar-una-instantanea-snapshot","title":"Crear y restaurar una instant\u00e1nea (snapshot)","text":"<p>18.- Desde la consola EBS \u2192 Volumenes, selecciona tu volumen y pulsa Crear instant\u00e1nea dentro del men\u00fa Acciones.</p> <ul> <li>Descripci\u00f3n: \u201cSnapshot de prueba del volumen EBS\u201d</li> </ul> <p>19.- Espera a que el estado del snapshot sea Completed.</p> <p>20.- Ahora, vamos a crear un nuevo volumen a partir de la instant\u00e1nea creada. Para ello accedemos al panel lateral Elastic Block Store \u2192 Instant\u00e1neas:</p> <ul> <li>Seleccionamos la instant\u00e1nea que acabamos de crear.</li> <li> <p>En el men\u00fa Acciones pulsamos sobre Crear volumen a partir de una instant\u00e1nea:</p> <ul> <li>Seleccionamos el mismo tipo y AZ que el volumen anterior.</li> <li>Dejamos es resto de los valores por defecto.</li> </ul> </li> </ul> <p>21.- Con\u00e9ctalo a cualquiera de las instancias y verifica que el archivo <code>/datos/info.txt</code> sigue existiendo.</p>"},{"location":"ud04/practica3.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Finaliza las instancias pero no las elimines (nos har\u00e1n falta para la siguiente pr\u00e1ctica).</li> <li>Elimina los vol\u00famenes EBS creados.</li> </ul>"},{"location":"ud04/practica4.html","title":"Pr\u00e1ctica 4. Uso compartido de almacenamiento con Amazon EFS","text":"<p>Recuerda</p> <ul> <li>Amazon EFS equivale a montar sistemas de ficheros compatibles con NFS.</li> <li>Se comporta como si fuera un NAS.</li> <li>M\u00faltiples instancias EC2 pueden montar un mismo EFS simult\u00e1neamente.</li> </ul>"},{"location":"ud04/practica4.html#objetivos-de-la-practica","title":"Objetivos de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del servicio Amazon EFS (Elastic File System).</li> <li>Crear un sistema de archivos compartido entre varias instancias EC2.</li> <li>Montar el sistema de archivos en Linux mediante el cliente NFS.</li> <li>Verificar que los cambios realizados desde una instancia se reflejan en la otra.</li> </ul> <p>Atenci\u00f3n</p> <p>Para poder montar el sistema de archivos EFS en una m\u00e1quina EC2 necesitamos instalar unas utilidades en dicha m\u00e1quina. Tenemos 2 opciones:</p> <ul> <li>Instalar el paquete <code>amazon-efs-utils</code>, pero los binarios s\u00f3lo est\u00e1n disponiblen para las AMI de Amazon-Linux</li> <li>Instalar las utilidades de NFS (en Ubuntu son las <code>nfs-common</code>), pero es necesario abrir el puerto 2049 (NFS) en el grupo de seguridad correspondiente.</li> </ul> <p>Elegiremos la segunda opci\u00f3n en esta pr\u00e1ctica.</p>"},{"location":"ud04/practica4.html#crear-el-sistema-de-archivos-efs","title":"Crear el sistema de archivos EFS","text":"<p>1.- En la consola de AWS, ve a EFS \u2192 Crear un sistema de archivos. Configura:</p> <ul> <li>Nombre: <code>efs-practica</code></li> <li>VPC: selecciona la misma VPC donde est\u00e1n tus instancias EC2.</li> <li>No hace falta personalizar el resto de par\u00e1metros. Los dejaremos todos con los valores por defecto.</li> </ul> <p>2.-Una vez creado el sistema de archivos efs, accede a \u00e9l y entra para ver sus propiedades. En la pesta\u00f1a de red:</p> <ul> <li>Aseg\u00farate de que exista un destino de montaje (mount target) en la misma subred o AZ de tus instancias. Por defecto se crea uno en cada subred.</li> <li>F\u00edjate bien en el grupo de seguridad asociado a cada destino de montaje porque habr\u00e1 que modificar las reglas de ese grupo de seguridad.</li> </ul> <p>Apunta el grupo de seguridad asociado al destino de montaje. Nos har\u00e1 falta saberlo m\u00e1s adelante.</p> <p>3.- Copia el nombre de DNS asignado al sistema de ficheros. Debe ser algo as\u00ed: <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code></p>"},{"location":"ud04/practica4.html#crea-las-instancias-de-ec2","title":"Crea las instancias de EC2","text":"<p>4.- Crea 2 m\u00e1quinas EC2 o reutiliza las de la pr\u00e1ctica anterior si a\u00fan las conservas (<code>Servidor-A</code> y <code>Servidor-B</code>).</p> <p>5.- Puesto que vamos a utilizar las m\u00e1quinas Ubuntu y no podemos descargar de los repositorios el paquete <code>amazon-efs-utils</code> vamos a optar por utilizar la opci\u00f3n de conectarnos con los paquetes NFS edt\u00e1ndar (<code>nfs-common</code>) y por tanto ser\u00e1 necesario abrir el puerto. Lo haremos m\u00e1s adelante.</p> <p>Para ello Apunta el grupo de seguridad asociado a las instancias EC2. Nos har\u00e1 falta saberlo en el siguiente punto.</p>"},{"location":"ud04/practica4.html#abrir-el-puerto-2049-en-el-grupo-de-seguridad","title":"Abrir el puerto 2049 en el grupo de seguridad","text":"<p>6.- Accede al grupo de seguridad asociado al EFS y crea una nueva regla de entrada para permitir el tr\u00e1fico por el puerto NFS (2049) desde el grupo de seguridad de las instancias EC2.</p> <p></p>"},{"location":"ud04/practica4.html#configurar-las-instancias-ec2","title":"Configurar las instancias EC2","text":"<p>7.- Con\u00e9ctate a la primera instancia EC2 (<code>Servidor-A</code>) e instala el cliente NFS:</p> <p><pre><code>sudo apt update\nsudo apt install -y nfs-common\n</code></pre> 8.- Crea un punto de montaje local:</p> <p><pre><code>sudo mkdir /mnt/efs\n</code></pre> 9.- Monta el sistema de archivos EFS (pega el ID copiado desde la consola en el paso 3, por ejemplo <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code>):</p> <p><pre><code>sudo mount -t nfs4 -o nfsvers=4.1 fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com:/ /mnt/efs\n</code></pre> 10.- Verifica que el montaje fue correcto:</p> <p><pre><code>df -h\n</code></pre> 11.- Crea un archivo de prueba:</p> <pre><code>echo \"Archivo creado desde Servidor-A\" | sudo tee /mnt/efs/prueba.txt\n</code></pre>"},{"location":"ud04/practica4.html#montar-el-mismo-efs-en-otra-instancia","title":"Montar el mismo EFS en otra instancia","text":"<p>12.- Con\u00e9ctate a la segunda instancia EC2 (<code>Servidor-B</code>) e instala tambi\u00e9n el cliente NFS:</p> <p><pre><code>sudo apt update\nsudo apt install -y nfs-common\n</code></pre> 13.- Crea el mismo punto de montaje local:</p> <p><pre><code>sudo mkdir /mnt/efs\n</code></pre> 14.- Monta el sistema de archivos EFS (pega el ID copiado desde la consola en el paso 3, por ejemplo <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code>):</p> <pre><code>sudo mount -t nfs4 -o nfsvers=4.1 fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com:/ /mnt/efs\n</code></pre> <p>15.- Comprueba que puedes ver el archivo creado desde el otro servidor:</p> <pre><code>cat /mnt/efs/prueba.txt\n</code></pre> <p>Deber\u00edas ver:</p> <pre><code>Archivo creado desde Servidor-A\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que han funcionado todos los comandos ejecutados en <code>Servidor-B</code></p> <p>16.- Ahora crea otro archivo desde el <code>Servidor-B</code>:</p> <pre><code>echo \"Creado desde Servidor-B\" | sudo tee mnt/efs/otro.txt\n</code></pre> <p>17.- Comprueba desde el <code>Servidor-A</code> que aparece el nuevo archivo:</p> <pre><code>ls /mnt/efs\ncat /mnt/efs/otro.txt\n</code></pre>"},{"location":"ud04/practica4.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Finaliza y elimina las instancias.</li> <li>Elimina el sistema de archivos EFS creado.</li> </ul>"},{"location":"ud04/practica5.html","title":"Pr\u00e1ctica 5. CI/CD de una web est\u00e1tica en S3 mediante GitHub Actions","text":"<p>Implementaci\u00f3n Continua/Despliegue Continuo de un sitio web est\u00e1tico en Amazon S3 mediante GitHub Actions.</p>"},{"location":"ud04/practica5.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>CI/CD significa Integraci\u00f3n Continua (Continuous Integration) y Entrega/Despliegue Continuo (Continuous Delivery/Deployment).</p> <p>Es un conjunto de pr\u00e1cticas que automatizan la integraci\u00f3n de c\u00f3digo, las pruebas y el despliegue de aplicaciones para entregar software de forma r\u00e1pida y fiable.</p> <p>GitHub Actions es una herramienta de automatizaci\u00f3n integrada en GitHub que permite ejecutar flujos de trabajo en respuesta a eventos del repositorio, como push, pull request o merge.</p> <p>Se utiliza para implementar CI/CD dentro de GitHub, ya que permite automatizar la integraci\u00f3n, las pruebas y el despliegue del c\u00f3digo directamente desde el repositorio, sin necesidad de usar servicios externos.</p> <p>En esta pr\u00e1ctica utilizaremos GitHub Actions para automatizar la copia del repositorio a un Bucket S3 cada vez que se haga un commit en dicho repositorio. Esto implicar\u00e1 que cada vez que se haga un cambio de c\u00f3digo, se suba autom\u00e1ticamente a AWS para estar disponible en la web.</p>"},{"location":"ud04/practica5.html#preparacion-del-material","title":"Preparaci\u00f3n del material","text":"<p>1.- En primer lugar vamos a hacer un fork a nuestra cuenta de GitHub del repositorio que utilizamos en la pr\u00e1ctica 2 que contiene una web de muestra. Lo haremos pulsanso sobre el bot\u00f3n <code>Fork</code> del repositorio.</p> <ul> <li>Val\u00eddate con tus credenciales en GitHub.</li> <li>Accede al repositorio de GitHub que contiene la web de muestra:    <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> <li>Pulsa en el bot\u00f3n Fork.</li> <li>Ya tienes en tu cuenta un repositorio con el mismo contenido.</li> </ul>"},{"location":"ud04/practica5.html#creacion-del-bucket","title":"Creaci\u00f3n del Bucket","text":"<p>2.- Crea un bucket en Amazon S3:</p> <ul> <li>Servir\u00e1 para Alojar un sitio web est\u00e1tico.</li> <li>Por tanto deber\u00e1s hacerlo p\u00fablico y asignar los permisos correspondientes mediante ACLs o pol\u00edticas (t\u00fa decides, pero se recomienda hacerlo por pol\u00edticas).</li> <li>Recuerda poner que la p\u00e1gina de inicio del sitio web ser\u00e1 <code>index.html</code>.</li> <li>No cargues ning\u00fan dato.</li> <li>Copia la url del bucket y \u00e1brela en un navegador (te dar\u00e1 error 404 de fichero no encontrado).</li> <li>Copia el nombre del bucket. Debe ser algo as\u00ed: <code>s3://demo-bucket-jrpm</code></li> </ul>"},{"location":"ud04/practica5.html#creacion-del-github-action","title":"Creaci\u00f3n del GitHub Action","text":"<p>3.- Volvemos a nuestro repositorio de GitHub y vamos a crear una Action para que cada vez que se haga un commit en el repositorio, se copie todo el contenido al bucket que acabamos de crear.</p> <ul> <li>Para ello, en el repositorio, ve a la opci\u00f3n Actions</li> <li>Pulsa sobre <code>set up a workflow yourself</code></li> <li>En el editor de texto pega el siguiente c\u00f3digo yaml sustituyendo el nombre del bucket de la \u00faltima l\u00ednea por el nuestro que hemos copiado:</li> </ul> <pre><code>name: deploy static website to AWS-S3 - V2\n\non:\n  push:\n\nenv:\n  AWS_REGION: us-east-1\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}\n          aws-region: ${{env.AWS_REGION}}\n\n      - name: Deploy to AWS S3\n        run: aws s3 sync . s3://demo-bucket-jrpm --delete\n</code></pre> <p>Hacemos commit y comprobamos que se nos ha creado un nuevo directorio en el repositorio con el fichero yaml, el cual describe la acci\u00f3n a ralizar cuando hay un commit.</p>"},{"location":"ud04/practica5.html#configuracion-de-los-secretos","title":"Configuraci\u00f3n de los secretos","text":"<p>4.- Si analizamos el c\u00f3digo yaml que hemos copiado veremos que, para que GitHub se conecte al bucket, es necesario pasarle las credenciales de conexi\u00f3n que usamos para la CLI.</p> <p>Estas credenciales no se ponen directamente en el c\u00f3digo pues estar\u00edan visibles para todo el p\u00fablico. En su lugar se hace uso de los secretos:</p> <pre><code>aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\naws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\naws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}\naws-region: ${{env.AWS_REGION}}\n</code></pre> <p>Para configurar los secretos nos vamos a la opci\u00f3n de configuraci\u00f3n del repositorio y creamos los 4 secretos que nos hacen falta: </p> <ul> <li>Settings --&gt; Secrets and Variables --&gt; Actions</li> <li>New repository secret</li> <li>Hay que hacer el proceso para 4 secretos, cuyos nombres y contenidos ser\u00e1n:</li> </ul> Name Secret AWS_ACCESS_KEY_ID El campo <code>aws_access_key_id</code> de los detalles del laboratorio AWS CLI AWS_SECRET_ACCESS_KEY El campo <code>aws_secret_access_key_id</code> del mismo lugar AWS_SESSION_TOKEN El campo <code>aws_session_token</code> del mismo lugar AWS_REGION La regi\u00f3n que estemos utilizando, en nuestro caso <code>us-east-1</code>"},{"location":"ud04/practica5.html#commit-y-prueba-de-despliegue-automatico","title":"Commit y prueba de despliegue autom\u00e1tico","text":"<p>5.- Si todo ha ido bien, podemos entrar en el repositorio y modificar el fichero <code>index.html</code> para que autom\u00e1ticamente se haga el despliegue en el bucket S3 y as\u00ed poder acceder a la url p\u00fablica:</p> <ul> <li>Estando en el c\u00f3digo del repositorio (<code>&lt;&gt; Code</code>) pulsa la tecla <code>.</code> (punto) para que se abra el editor web de GitHub.</li> <li>Modifica el fichero <code>index.html</code> para que donde ponga IES Camp de Morvedre ponga tu nombre.</li> <li>En la barra de tareas de la izquierda pulsa sobre el bot\u00f3n de Control de C\u00f3digo Fuente (el tercero) y haz un commit indicando un mensaje.</li> <li>Al cabo de unos minutos se habr\u00e1 actualizado el bucket.</li> <li>Accede con un navegador a la url del bucket. Debe verse la web con el cambio realizado.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla Actions del repositorio en la que se muestre que ha funcionado el workflow.</p> <p></p>"},{"location":"ud04/ud04.html","title":"Tema 4. Almacenamiento en AWS","text":""},{"location":"ud04/ud04.html#almacenamiento-en-la-nube","title":"Almacenamiento en la nube","text":"<p>El almacenamiento en la nube suele ser m\u00e1s fiable, escalable y seguro que los tradicionales sistemas de almacenamiento en las instalaciones. El almacenamiento en la nube es un componente fundamental del c\u00f3mputo en la nube, pues contiene la informaci\u00f3n que utilizan las aplicaciones. El an\u00e1lisis de big data, los almacenes de datos, el Internet de las cosas (IoT), las bases de datos y las aplicaciones de copias de seguridad y archivado dependen de alg\u00fan tipo de arquitectura de almacenamiento de datos. </p>"},{"location":"ud04/ud04.html#almacenamiento-a-nivel-de-bloque-fichero-y-objeto","title":"Almacenamiento a nivel de Bloque, Fichero y Objeto","text":"<p>Una diferencia clave entre algunos tipos de almacenamiento es saber si ofrecen almacenamiento en el nivel de bloque, a nivel de fichero o a nivel de objeto. </p> <p></p> <p>Esta diferencia tiene un gran impacto en el rendimiento, la latencia y el costo de la soluci\u00f3n de almacenamiento. Las soluciones de almacenamiento en bloque suelen ser m\u00e1s r\u00e1pidas y utilizan menos ancho de banda, pero pueden costar m\u00e1s que el almacenamiento en el nivel de objeto. Pero muchas veces la elecci\u00f3n vendr\u00e1 condicionada por el tipo de uso que deseamos hacer.</p> <p>Almacenamiento en bloque (Block Storage)</p> <ul> <li>Los datos se dividen en bloques de tama\u00f1o fijo (por ejemplo, 512 B o 4 KB).</li> <li>Cada bloque tiene una direcci\u00f3n, pero no contiene metadatos.</li> <li>El sistema operativo o la aplicaci\u00f3n se encarga de organizar los bloques (por ejemplo, mediante un sistema de archivos).</li> <li>Ejemplo t\u00edpico: Discos duros, SSD, vol\u00famenes de m\u00e1quinas virtuales (como los archivos .vdi de VirtualBox o como Amazon EBS).</li> </ul> <p>Almacenamiento de ficheros (File Storage)</p> <ul> <li>Los datos se organizan en un sistema de archivos jer\u00e1rquico (carpetas y subcarpetas).</li> <li>Los usuarios acceden a los archivos mediante rutas (por ejemplo, <code>/documentos/informe.pdf</code>).</li> <li>Se usa un protocolo de red como NFS (Linux/Unix) o SMB/CIFS (Windows) o Amazon EFS.</li> <li>Ejemplo t\u00edpico: Servidores NAS, carpetas compartidas en red.</li> </ul> <p>Almacenamiento de objetos (Object Storage)</p> <ul> <li>Los datos se almacenan como objetos completos, cada uno con:<ul> <li>El dato (contenido del archivo),</li> <li>Un identificador \u00fanico (ID o hash),</li> <li>Y metadatos personalizados.</li> </ul> </li> <li>No hay estructura jer\u00e1rquica: los objetos se guardan en \u201cbuckets\u201d (contenedores).</li> <li>Se accede normalmente mediante API HTTP/HTTPS (REST).</li> <li>Ejemplo t\u00edpico: Amazon S3, Azure Blob Storage, Google Cloud Storage.</li> </ul> <p></p> Caracter\u00edstica Bloques Ficheros Objetos Organizaci\u00f3n Bloques con direcci\u00f3n \u00c1rbol de carpetas y archivos Objetos con metadatos Acceso Bajo nivel (E/S directa) Ruta de archivo API o URL Protocolos comunes iSCSI, Fibre Channel NFS, SMB/CIFS HTTP/HTTPS (REST, S3 API) Usos t\u00edpicos Bases de datos, discos VM Servidores NAS, uso compartido Backups, multimedia, big data Ejemplos en AWS Amazon EBS Amazon EFS Amazon S3 <p>En este tema veremos los siguientes servicios de AWS:</p> <ul> <li>Amazon Simple Storage Service (Amazon S3) --&gt; Almacenamiento a nivel de Objetos</li> <li>Amazon Elastic Block Store (Amazon EBS) --&gt; Almacenamiento a nivel de Bloques</li> <li>Amazon Elastic File System (Amazon EFS) --&gt; Almacenamiento a nivel de Ficheros</li> <li>Amazon Simple Storage Service Glacier --&gt; Almacenamiento a nivel de Objetos</li> </ul>"},{"location":"ud04/ud04.html#amazon-s3","title":"Amazon S3","text":"<p>Amazon S3 (Simple Storage Service) es un servicio administrado de almacenamiento a nivel de objetos en la nube de AWS.</p> <p>Est\u00e1 dise\u00f1ado para ofrecer una alta durabilidad (11 nueves: 99,999999999%), escalabilidad autom\u00e1tica y baja latencia en el acceso a los datos.</p> <p>Sus caracter\u00edsticas principales son:</p> <ul> <li>Permite almacenar y gestionar objetos (archivos) de hasta 5 TB.</li> <li>Los objetos se guardan dentro de buckets, cuyos nombres deben ser \u00fanicos en todo Amazon S3.</li> <li>Por defecto, los datos se almacenan de forma redundante en m\u00faltiples instalaciones y dispositivos, sin que el usuario tenga que administrar servidores.</li> </ul> <p>Se puede almacenar cualquier tipo de archivo: im\u00e1genes, v\u00eddeos, registros, copias de seguridad o instant\u00e1neas de bases de datos.</p>"},{"location":"ud04/ud04.html#conceptos-basicos-de-amazon-s3","title":"Conceptos b\u00e1sicos de Amazon S3","text":"<p>Para utilizar Amazon S3, es importante entender algunos conceptos fundamentales:</p> <p>Buckets:</p> <ul> <li>Son contenedores l\u00f3gicos donde se almacenan los objetos (archivos).</li> <li>Cada bucket debe tener un nombre \u00fanico a nivel mundial.</li> <li>Se puede elegir la regi\u00f3n de AWS donde se almacenar\u00e1 el bucket (por ejemplo <code>us-east-1</code>).</li> <li>Se puede controlar el acceso a cada bucket (qui\u00e9n puede crear, eliminar o listar objetos).</li> <li>Permiten ver registros de acceso al bucket y a los objetos que contiene.</li> </ul> <p>Objetos:</p> <ul> <li>Los archivos almacenados en S3 se llaman objetos.</li> <li> <p>Un objeto est\u00e1 formado por:</p> <ul> <li>Datos (el contenido del archivo).</li> <li>Metadatos (informaci\u00f3n que lo describe, como permisos o URL).</li> </ul> </li> <li> <p>Se puede almacenar cualquier cantidad de objetos dentro de un bucket.</p> </li> <li>Al cargar un archivo, se pueden definir permisos y metadatos personalizados.</li> </ul> <p></p> <p>Cada bucket y objeto tiene una URL \u00fanica, aunque hay dos estilos de URL que pueden usarse para acceder a los objetos.</p> <p>Ejemplo: un archivo <code>video.mp4</code> dentro de un bucket tendr\u00e1 una URL con el nombre del bucket y del objeto.</p> <p></p>"},{"location":"ud04/ud04.html#situaciones-tipicas-de-uso-de-s3","title":"Situaciones t\u00edpicas de uso de S3","text":"<p>Aunque se puede almacenar cualquier tipo de dato, los casos de uso t\u00edpico de S3 suelen ser:</p> <ul> <li> <p>Copia de seguridad y almacenamiento: Se utiliza para guardar copias de seguridad y ofrecer servicios de almacenamiento de datos a terceros.</p> </li> <li> <p>Alojamiento de aplicaciones: Permite implementar, instalar y administrar aplicaciones web directamente desde la nube.</p> </li> <li> <p>Alojamiento multimedia: Ideal para crear infraestructuras redundantes, escalables y de alta disponibilidad que gestionen la carga y descarga de v\u00eddeos, im\u00e1genes o m\u00fasica.</p> </li> <li> <p>Entrega de software: Facilita el alojamiento de aplicaciones o instaladores para que los usuarios puedan descargarlos f\u00e1cilmente.</p> </li> </ul> <p></p>"},{"location":"ud04/ud04.html#control-de-acceso-en-amazon-s3","title":"Control de acceso en Amazon S3","text":"<p>Por defecto, todos los buckets de Amazon S3 son privados, y solo los usuarios con permisos expl\u00edcitos pueden acceder a ellos.</p> <p>Es fundamental gestionar correctamente los permisos y la seguridad de los datos almacenados. Para ello disponemos de varias herramientas de control de acceso. Las m\u00e1s importantes que utilizaremos ser\u00e1n:</p> <p>1. Bloqueo del acceso p\u00fablico:</p> <ul> <li>Impide que los buckets o los objetos sean accesibles p\u00fablicamente.</li> <li>Tiene prioridad sobre otras pol\u00edticas o permisos.</li> <li>Recomendado para evitar exposiciones accidentales de datos.</li> </ul> <p>2. Pol\u00edticas de IAM (Identity and Access Management):</p> <ul> <li>Permiten definir qu\u00e9 usuarios o roles pueden acceder a determinados buckets u objetos.</li> </ul> <p>3. Pol\u00edticas de bucket:</p> <ul> <li>Definen permisos espec\u00edficos sobre un bucket o sus objetos.</li> <li>\u00datiles cuando no se usa autenticaci\u00f3n mediante IAM.</li> <li>Pueden permitir acceso entre cuentas o incluso p\u00fablico/an\u00f3nimo, por lo que deben configurarse con cuidado.</li> <li>Pueden incluir enunciados de denegaci\u00f3n para restringir el acceso incluso si otros permisos lo permiten.</li> </ul> <p>4. Listas de control de acceso (ACL):</p> <ul> <li>M\u00e9todo antiguo, anterior a IAM.</li> <li>Se recomienda usarlo solo cuando sea necesario y evitando configuraciones demasiado permisivas.</li> </ul> <p></p> <p>La situaci\u00f3n del medio muestra una ocasi\u00f3n en que se ha desactivado la configuraci\u00f3n de seguridad de S3 y cualquiera puede acceder p\u00fablicamente a los objetos almacenados en el bucket, por ejemplo cuando alojamos un sitio web est\u00e1tico en un bucket S3. </p> <p>Atenci\u00f3n</p> <p>Usar un bucket de Amazon S3 para alojar un sitio web est\u00e1tico es una forma r\u00e1pida de configurar una arquitectura en AWS, pero en la mayor\u00eda de los casos no se recomienda otorgar acceso p\u00fablico. Normalmente, S3 se utiliza para almacenar datos que son accedidos por aplicaciones externas o para guardar informaci\u00f3n confidencial y copias de seguridad, por lo que los buckets deben mantenerse privados para garantizar la seguridad de los datos.</p>"},{"location":"ud04/ud04.html#amazon-ebs","title":"Amazon EBS","text":"<p>Amazon EBS ofrece vol\u00famenes de almacenamiento persistente en bloque para instancias de Amazon EC2, lo que significa que los datos se conservan incluso despu\u00e9s de apagar el sistema. </p> <p>Cada volumen se replica autom\u00e1ticamente dentro de una zona de disponibilidad, garantizando alta disponibilidad y durabilidad. Permite ajustar la capacidad r\u00e1pidamente (aumentar o reducir el tama\u00f1o en cuesti\u00f3n de minutos) y pagar solo por el almacenamiento aprovisionado.</p> <p>Los beneficios adicionales de EBS son la replicaci\u00f3n en la misma zona de disponibilidad, el cifrado f\u00e1cil y transparente, los vol\u00famenes el\u00e1sticos y las copias de seguridad mediante instant\u00e1neas.</p> <p>Importante</p> <ul> <li>Los vol\u00famenes EBS equivalen a los discos duros virtuales que utilizan las instancias EC2.</li> <li>Un volumen s\u00f3lo puede estar conectado a una instancia simult\u00e1neamente.</li> <li>Pero una instancia puede conectar varios vol\u00fames EBS simult\u00e1neamente.</li> </ul> <p></p> <p>Amazon EBS ofrece tres tipos de vol\u00famenes: </p> <ul> <li>SSD de uso general: Son unidades de estado s\u00f3lido (SSD) optimizadas para cargas de trabajo de transacciones que implican operaciones de lectura/escritura frecuentes de peque\u00f1o tama\u00f1o de E/S. Proporciona un equilibrio entre precio y rendimiento, y es el tipo recomendado para la mayor\u00eda de las cargas de trabajo. Los tipos existentes son gp3 (1.000 MiB/s) y gp2 (128-250 MiB/s) ambas con un m\u00e1ximo de 16.000 IOPS.</li> <li>SSD de IOPS provisionadas: proporciona un rendimiento elevado con cargas de trabajo cr\u00edticas, baja latencia o alto rendimiento. Los tipos existentes con io2 Block Express (4.000 MiB/s con un m\u00e1ximo 246.000 IOPS) e io2 (1.000 MiB/s con 64.000 IOPS).</li> <li>Magn\u00e9ticos (HDD): Son unidades de disco duro (HDD) optimizadas para grandes cargas de trabajo de streaming. Los tipos existentes con st1 (con 500 MiB/s y 500 IOPS) y sc1 (con 250 MiB/s y 250 IOPS).</li> </ul> <p>IOPS</p> <p>El t\u00e9rmino IOPS (operaciones de entrada y salida por segundo) representa una medida de rendimiento frecuente que se utiliza para comparar dispositivos de almacenamiento.  Cuantas m\u00e1s IOPS, mayor velocidad de acceso a los datos. En t\u00e9rminos habituales, un disco HDD ofrece entre 100 y 200 IOPS, un SSD SATA entre 5.000 y 100.000 IOPS, y un SSD NVMe puede superar el mill\u00f3n de IOPS. Estas cifras var\u00edan seg\u00fan el tipo de carga (lectura/escritura y secuencial/aleatoria).</p>"},{"location":"ud04/ud04.html#instantaneas","title":"Instant\u00e1neas","text":"<p>Para proporcionar un nivel a\u00fan mayor de durabilidad de los datos, Amazon EBS permite crear instant\u00e1neas a un momento dado de nuestros vol\u00famenes y volver a crear un volumen nuevo a partir de una instant\u00e1nea en cualquier momento.</p> <p>La primera instant\u00e1nea se denomina instant\u00e1nea de referencia. Cualquier otra instant\u00e1nea posterior a la de referencia captura solo lo que sea diferente de la instant\u00e1nea anterior.</p> <p>Las instant\u00e1neas se almacenan como objetos de Amazon S3.</p>"},{"location":"ud04/ud04.html#amazon-efs","title":"Amazon EFS","text":"<p>Amazon EFS (Elastic File System) es un servicio de almacenamiento de archivos compartido y el\u00e1stico ofrecido por AWS que funciona de manera similar a un NAS (Network Area Storage).</p> <p>Proporciona un sistema de archivos NFS (Network File System) accesible de forma simult\u00e1nea por m\u00faltiples instancias EC2 u otros servicios.</p> <p></p> <p>Sus caracter\u00edsticas principales son:</p> <ul> <li>Escalado autom\u00e1tico: ajusta su capacidad de almacenamiento autom\u00e1ticamente al a\u00f1adir o eliminar archivos.</li> <li>Alta disponibilidad y durabilidad: los datos se replican en varias zonas de disponibilidad (AZ) dentro de una regi\u00f3n.</li> <li>Acceso concurrente: permite que muchas instancias EC2 monten el mismo sistema de archivos al mismo tiempo.</li> <li>Compatibilidad con NFS v4/v4.1, lo que facilita la integraci\u00f3n con sistemas Linux.</li> <li>Pago por uso: se factura solo por la cantidad de datos almacenados (coste mayor por GB que EBS en algunos casos).</li> </ul> <p>Atenci\u00f3n</p> <p>EFS no se puede montar directamente en Windows (solo es compatible con NFS).</p>"},{"location":"ud04/ud04.html#ejemplos-de-uso-de-amazon-efs","title":"Ejemplos de uso de Amazon EFS","text":"<p>Servidores web con contenido compartido:</p> <p>Varios servidores Apache o Nginx montan el mismo EFS para compartir los archivos del sitio web:</p> <ul> <li>Ideal para configuraciones con balanceadores de carga (Elastic Load Balancer).</li> <li>Garantiza que todos los servidores sirvan el mismo contenido actualizado.</li> </ul> <p></p> <p>Almacenamiento de copias de seguridad:</p> <p>Centralizar copias de seguridad de varias instancias EC2 o contenedores.</p> <p>Permite mantener las copias accesibles desde cualquier servidor de la VPC.</p> <p></p> <p>Directorio de usuarios o home compartido:</p> <p>Los usuarios del sistema pueden tener sus directorios personales en EFS, accesibles desde varias m\u00e1quinas Linux.</p> <p></p> <p>Aplicaciones distribuidas:</p> <p>Aplicaciones que necesitan acceso simult\u00e1neo a los mismos archivos, por ejemplo:</p> <ul> <li>Procesamiento de im\u00e1genes o v\u00eddeos.</li> <li>Generaci\u00f3n de informes o resultados de c\u00e1lculo.</li> <li>Sistemas de gesti\u00f3n documental.</li> </ul> <p></p> <p>Almacenamiento para an\u00e1lisis o procesamiento de datos:</p> <p>Conjuntos de datos grandes que son procesados por m\u00faltiples nodos (Hadoop, Spark, etc.).</p> <p>EFS sirve como repositorio central para datos de entrada o resultados temporales.</p> <p></p> <p>Logs centralizados:</p> <p>Varias instancias EC2 pueden escribir sus archivos de logs en un mismo EFS.</p> <p>Facilita el an\u00e1lisis centralizado sin necesidad de configurar un servidor de logs. Ejemplo: <code>/mnt/efs/logs/app1/</code>, <code>/mnt/efs/logs/app2/</code></p> <p></p> <p>Compartir scripts, configuraciones o paquetes:</p> <p>Carpeta EFS con scripts comunes (bash, python, etc.) accesible por todos los servidores.</p> <p>Permite mantener entornos de despliegue uniformes.</p>"},{"location":"ud04/ud04.html#amazon-s3-glacier","title":"Amazon S3 Glacier","text":"<p>Amazon S3 Glacier es un servicio de almacenamiento en la nube de bajo coste dise\u00f1ado para archivar datos y realizar copias de seguridad a largo plazo. Forma parte de Amazon S3 y est\u00e1 pensado para informaci\u00f3n que no se necesita consultar con frecuencia, pero que debe conservarse de forma segura y duradera.</p> <p>Las caracter\u00edticas principales de este servicio son:</p> <ul> <li>Bajo coste: es mucho m\u00e1s econ\u00f3mico que las clases de almacenamiento est\u00e1ndar de S3, ideal para datos que se acceden rara vez.</li> <li>Alta durabilidad: ofrece los mismos once nueves (99,999999999%) de durabilidad que el resto de S3.</li> <li>Seguridad: admite cifrado autom\u00e1tico y control de acceso mediante pol\u00edticas de IAM y de bucket.</li> <li> <p>Recuperaci\u00f3n flexible: los datos pueden recuperarse en diferentes velocidades seg\u00fan la urgencia:</p> <ul> <li>Expedited (r\u00e1pida): segundos o minutos.</li> <li>Standard: unas pocas horas.</li> <li>Bulk (masiva): varias horas, m\u00e1s econ\u00f3mica.</li> </ul> </li> </ul>"},{"location":"ud04/ud04.html#versiones-o-clases-de-s3-glacier","title":"Versiones o clases de S3 Glacier","text":"<p>Amazon S3 incluye tres clases de almacenamiento Glacier, adaptadas a distintos usos:</p> <ol> <li>S3 Glacier Instant Retrieval: acceso casi inmediato (segundos), \u00fatil para archivos que se consultan ocasionalmente pero requieren un acceso instant\u00e1neo. Por ejemplo, historias m\u00e9dicas, archivos multimedia o documentos que se consultan espor\u00e1dicamente.</li> <li>S3 Glacier Flexible Retrieval (antes S3 Glacier): equilibrio entre coste y tiempo de recuperaci\u00f3n (minutos u horas). \u00datil para copias de seguridad, versiones antiguas de proyectos, o datos empresariales que se consultan solo en auditor\u00edas o revisiones anuales.</li> <li>S3 Glacier Deep Archive: la opci\u00f3n m\u00e1s barata, pensada para conservaci\u00f3n de datos a largo plazo (a\u00f1os), con tiempos de recuperaci\u00f3n de 12 a 48 horas. \u00datil en, por ejemplo, almacenamiento de facturas antiguas, archivos legales que han de guardarse durante a\u00f1os, copias de seguridad hist\u00f3ricas o registros que rara vez se necesitan.</li> </ol>"},{"location":"ud05/bdpractica01.html","title":"Bases de Datos RDS con acceso p\u00fablico","text":""},{"location":"ud05/bdpractica01.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica crearemos un servicio de BBDD totalmente gestionado sobre un motor MySQL al que accederemos directamente desde Internet.</p> <p>Peligro</p> <p>El acceso p\u00fablico a una BBDD est\u00e1 totalmente desaconsejado. Es una pr\u00e1ctica muy peligrosa permitir el acceso p\u00fablico a una base de datos, pero en esta pr\u00e1ctica lo haremos para poder conectarnos remotamente desde un cliente de base de datos. </p>"},{"location":"ud05/bdpractica01.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud05/bdpractica01.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud05/bdpractica01.html#creacion-de-la-base-de-datos-rds","title":"Creaci\u00f3n de la Base de Datos RDS","text":"<p>1.-  Accedemos a la consola, dentro de la categor\u00eda Bases de Datos, seleccionamos el recurso Aurora and RDS.</p> <p>Nota</p> <p>RDS permite hasta 6 motores de BBDD distintos. En esta pr\u00e1ctica, el servicio gestionado de BBDD que vamos a utilizar es RDS basado en MySQL, que permite ejecutar bases de datos MySQL.</p> <p></p> <p>2.- Creamos una Base de Datos:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos MySQL.</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Entorno de pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Disponibilidad Implementaci\u00f3n de una instanciade base de datos de zona de disponibilidad \u00fanica (1 instancia)</li> <li>Ponemos un nombre de servidor que debe ser \u00fanico en nuestra cuenta de AWS. Introduce uno que lleve tu nombre o iniciales.</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a.</li> <li>Dejamos las opciones por defecto del tama\u00f1o de la instancia y el almacenamiento.</li> <li>No vamos a conectar nuestra BBDD a ninguna instancia EC2, y dejamos la BBDD en la VPC por defecto (Default VPC).</li> <li>Importante: Permitimos el Acceso P\u00fablico a nuestra BBDD. Esto generar\u00e1 una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Creamos un nuevo grupo de seguridad, por ejemplo bbdd-sg</li> <li>Los dem\u00e1s campos los dejamos por defecto.</li> </ul> <p></p> <p>Nota</p> <p>Podr\u00edamos haber seleccionado el m\u00e9todo de creaci\u00f3n r\u00e1pida, que nos pide muchos menos par\u00e1metros para crear la BBDD, pero nos habr\u00eda dejado la opci\u00f3n de Permitir Acceso P\u00fablico como NO. Ello implica que nos tocar\u00eda acceder a modificar los par\u00e1metros una vez creada la BBDD para permitir ese acceso p\u00fablico, y adem\u00e1s deber\u00edamos permitir la regla de entrada correspondiente en el grupo de seguridad.  </p> <p>Atenci\u00f3n</p> <p>Cuando hemos creado el grupo de seguridad, si no modificamos nada, por defecto AWS permite el acceso a la BBDD desde una \u00fanica IP. Esto es importante tenerlo en cuenta. Si luego intentamos acceder desde otro equipo, o desde el mismo pero en otra red (cambia nuestra IP P\u00fablica), no podremos conectarnos.</p> <p></p> <p>3.- Una vez creado el recurso accedemos a \u00e9l y en el apartado Conectividad y seguridad comprobamos el endpoint y el puerto por al cual accederemos. Copiamos el punto de enlace en el portapapeles.</p> <p>Comprobamos tambi\u00e9n que se nos ha asociado el nuevo grupo de seguridad que hemos creado.</p> <p></p> <p> </p> <p>4.- En el apartado de Configuraci\u00f3n nos aparecen los datos de la configuraci\u00f3n de la m\u00e1quina virtual sobre la que est\u00e1 corriendo nuestro SGBD, as\u00ed como la versi\u00f3n de MySQL instalada y el nombre del usuario administrador.</p> <p></p> <p>5.- Volvemos al apartado de Conectividad y seguridad y accedemos al grupo de seguridad bbdd-sg que se nos ha creado para ver las reglas de firewall que nos ha puesto por defecto. En las reglas de entrada comprobamos que se ha creado la regla para permitir conexiones desde nuestra IP local a la BBDD por el puerto de MySQL (3306).</p> <p></p> <p> </p>"},{"location":"ud05/bdpractica01.html#conexion-a-la-bbdd","title":"Conexi\u00f3n a la BBDD","text":"<p>6.- En nuestra m\u00e1quina local establacemos una conexi\u00f3n mediante un cliente de MySQL de l\u00ednea de comandos, indicando la cadena de conexi\u00f3n y el usuario que hemos definido como administrador. En el par\u00e1metro host <code>-h</code> ponemos el nombre del servidor (endpoint que hemos copiado en el portapapeles) y en el par\u00e1metro de usuario <code>-u</code> el nombre del usuario. Para que nos solicite el password indicamos el par\u00e1metro <code>-p</code>.</p> <p><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p</code></p> <p>Una vez comprobada la conexi\u00f3n, cerramos la sesi\u00f3n:</p> <p><code>exit;</code></p> <p>Atenci\u00f3n</p> <p>Si hemos dejado la opci\u00f3n de Permitir Acceso P\u00fablico como NO o no aparece la regla de seguridad del firewall (grupo de seguridad) no podremos conectarnos.</p> <p></p> <p>7.- Vamos a crear una base de datos con una tabla. Lo vamos a hacer mediante un script de sentencias sql. Para ello comenzamos con la descarga del fichero de creaci\u00f3n de la base de datos.</p> <p>Descarga fichero sql</p> <p>8.- Ejecutamos las instrucciones SQL que hay en el contenido del fichero descargado. Basta con redireccionar la entrada del comando <code>mysql</code> con el fichero descargado de nombre <code>asir.sql</code>.</p> <pre><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p &lt; asir.sql\n</code></pre> <p></p> <p>9.- Comprobamos que se ha ejecutado correctamente y se ha creado la base de datos y la tabla correspondiente. Para ello volvemos a iniciar una conexi\u00f3n en el servidor MySQL y ejecutamos la consulta correspondiente:</p> <pre><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p\n</code></pre> <pre><code>use webasir;\nselect * from clientes;\nexit;\n</code></pre> <p></p> <p>Captura las pantallas</p> <p>Captura la pantalla de establecimiento de conexi\u00f3n a la base de datos.</p> <p>Captura la pantalla resultado de hacer la select de clientes.</p> <p>10.- Podemos establacer conexi\u00f3n remota tambi\u00e9n mediante clientes GUI como DBeaver, HeidiSQL, MySQL Workbench, ...</p> <p></p>"},{"location":"ud05/bdpractica01.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>11.- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. No crees ninguna instant\u00e1nea final ni conserves las copias de seguridad.</p> <p>Atenci\u00f3n</p> <p>Si detenemos un servidor de BBDD (sin eliminarlo), AWS lo iniciar\u00e1 autom\u00e1ticamente a los 7 d\u00edas (si no lo hemos levantado nosotros de manera manual antes). Esto es peligroso, pues si olvidamos eliminar un recurso de BBDD que no utilizamos, se pondr\u00e1 en marcha autom\u00e1ticamente a los 7 d\u00edas de haberlo detenido, con el consiguiente consumo de cr\u00e9dito.</p> <p></p>"},{"location":"ud05/bdpractica02.html","title":"Bases de Datos RDS sin acceso p\u00fablico","text":""},{"location":"ud05/bdpractica02.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear una base de datos RDS similar a la anterior, pero la vamos a ubicar en una subred privada de manera que no sea accesible desde Internet.</p> <p>En una subred p\u00fablica de la VPC crearemos una m\u00e1quina virtual accesible desde Internet y que s\u00ed que podr\u00e1 acceder a la base de datos. Este ser\u00eda un modelo t\u00edpico en el que tenemos un servidor (por ejemplo un servidor web) accesible desde Internet que ataca a una base de datos no accesible desde el exterior, aumentando as\u00ed la seguridad de nuestros datos necesarios para la aplicaci\u00f3n web.</p>"},{"location":"ud05/bdpractica02.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud05/bdpractica02.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud05/bdpractica02.html#creacion-de-la-vpc-y-la-maquina-ec2","title":"Creaci\u00f3n de la VPC y la m\u00e1quina EC2","text":"<p>1.- Creamos una nueva VPC con la siguientes caracter\u00edsticas:</p> <ul> <li>El bloque de CIDR ser\u00e1 10.0.0.0/16</li> <li>Debe tener 2 AZs.</li> <li>2 Subredes p\u00fablicas (10.0.1.0/24 y 10.0.2.0/24) cada una en una AZ.</li> <li>2 Subredes privadas (10.0.3.0/24 y 10.0.4.0/24) cada una en una AZ.</li> <li>No es necesario un Gateway NAT ni un Gateway de S3</li> </ul> <p>Nota</p> <p>Aunque no usemos Multi-AZ, AWS requiere al menos dos subredes privadas en diferentes AZ para RDS. Esto mejora la flexibilidad y disponibilidad, aunque la configuraci\u00f3n inicial sea simple.</p> <p></p> <p>2-  Vamos a crear una instancia EC2 en la primera subred p\u00fablica:</p> <ul> <li>La imagen ser\u00e1 la AMI de Ubuntu.</li> <li>El tama\u00f1o ser\u00e1 suficiente con un tipo de instancia t2.micro.</li> <li>El par de claves utilizaremos el del laboratorio (vockey).</li> <li>La ubicamos en la primera subred p\u00fablica (subnet-public1).</li> <li>Le asignamos una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Nos aseguramos que se crea una regla de firewall para permitir las conexiones por el puerto SSH (22).</li> <li>Para hacer que durante el primer lanzamiento de la instrancia se instale el cliente de MySQL ponemos las siguientes l\u00edneas en el apartado de Datos de usuario:</li> </ul> <pre><code>#!/bin/bash\napt update\napt install -y  mysql-client-core-8.0\n</code></pre> <p></p> <p>3-  Una vez creada la instancia EC2 comprobamos su IP p\u00fablica y nos conectamos por ssh desde nuestra m\u00e1quina local para comprobar que todo funciona.</p> <p></p>"},{"location":"ud05/bdpractica02.html#creacion-de-la-base-de-datos","title":"Creaci\u00f3n de la Base de Datos","text":"<p>El primer requisito para crear una base de datos RDS es definir un grupo de subredes de bases de datos en nuestra VPC.</p> <p>Info</p> <p>Un grupo de subredes de bases de datos es una colecci\u00f3n de subredes dentro de una VPC que RDS utiliza para desplegar instancias de bases de datos. Permite especificar en qu\u00e9 subredes y zonas de disponibilidad se pueden alojar las bases de datos. Es necesario que al menos contenga 2 AZ, por eso la necesidad de crear nuestra VPC con al menos 2 zonas de disponibilidad, aunque solamente utilicemos una.</p> <p>4-  Accedemos a la consola de RDS y creamos grupo de subredes con las 2 subredes privadas:</p> <ul> <li>Seleccionamos las 2 zonas de disponibilidad de nuestra VPC (en principio ser\u00e1n us-east-1a y us-east-1b).</li> <li>Seleccionamos las 2 subredes privadas (subnet-private1 y subnet-private2), puesto que deseamos crear nuestra base de datos dentro de una de las subredes privadas.</li> </ul> <p></p> <p></p> <p>5.- Ahora s\u00ed creamos una Base de Datos RDS:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos MySQL.</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Entorno de pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Ponemos un nombre para la instancia de base de datos que debe ser \u00fanico en nuestra cuenta de AWS. Pon el nombre bbddapellido, sustituye apellido por el tuyo</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a.</li> <li>Dejamos las opciones por defecto del tama\u00f1o de la instancia y el almacenamiento.</li> <li>En el apartado Conectividad:<ul> <li>Indicamos que vamos a conectar nuestra base de datos a una instancia EC2 y la seleccionamos en el desplegable.</li> <li>En el Grupo de subredes elegimos la existente que hemos creado en el punto anterior.</li> <li>NO permitimos el Acceso P\u00fablico a nuestra BBDD.</li> <li>Elegimos como grupo de seguridad, el existente por defecto. Nos informa que adem\u00e1s se crear\u00e1 un nuevo grupo de seguridad para conectar la instancia EC2 con la RDS.</li> </ul> </li> <li>Los dem\u00e1s campos los dejamos por defecto.</li> </ul> <p></p>"},{"location":"ud05/bdpractica02.html#conexion-a-la-base-de-datos-desde-la-maquina-ec2","title":"Conexi\u00f3n a la Base de Datos desde la m\u00e1quina EC2","text":"<p>6.- Iniciamos sesi\u00f3n desde la m\u00e1quina ubuntu y comprobamos que podemos conectarnos a la instancia MySQL, indicando la cadena de conexi\u00f3n y el usuario que hemos definido como administrador. En el par\u00e1metro host <code>-h</code> ponemos el nombre del servidor y en el par\u00e1metro de usuario <code>-u</code> el nombre del usuario. Para que nos solicite el password indicamos el par\u00e1metro <code>-p</code>.</p> <p><code>mysql -h bbddtema5p2.cwhda7oxrrck.us-east-1.rds.amazonaws.com -u admin -p</code></p> <p>Puedes encontrar el par\u00e1metro <code>-h</code> en la pesta\u00f1a de conectividad y seguridadde la base de datos.</p> <p></p> <p></p> <p>Captura las pantallas</p> <p>Captura la pantalla resumen de la base de datos que muestra el punto de enlace de la conexi\u00f3n.</p> <p>Captura la pantalla de establecimiento de conexi\u00f3n a la base de datos desde la m\u00e1quina ubuntu. </p> <p></p>"},{"location":"ud05/bdpractica02.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>Una vez comprobada la conexi\u00f3n, para finalizar la pr\u00e1ctica eliminamos los recursos creados.</p> <p>7- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. No crees ninguna instant\u00e1nea final ni conserves las copias de seguridad.</p> <p>Atenci\u00f3n</p> <p>Si detenemos un servidor de BBDD (sin eliminarlo), AWS lo iniciar\u00e1 autom\u00e1ticamente a los 7 d\u00edas (si no lo hemos levantado nosotros de manera manual antes). Esto es peligroso, pues si olvidamos eliminar un recurso de BBDD que no utilizamos, se pondr\u00e1 en marcha autom\u00e1ticamente a los 7 d\u00edas de haberlo detenido, con el consiguiente consumo de cr\u00e9dito.</p> <p></p> <p></p> <p>8- Desde la consola de AWS, elimina la instancia EC2.</p> <p></p> <p>9.- Desde la consola de AWS, elimina la VPC.</p>"},{"location":"ud05/bdpractica03.html","title":"Cl\u00faster de Aurora","text":""},{"location":"ud05/bdpractica04.html","title":"Bases de Datos NoSQL","text":""},{"location":"ud05/bdpractica04.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En este ejercicio trabajar\u00e1s con una base de datos NoSQL</p>"},{"location":"ud05/bdpractica04.html#preparacion-cli","title":"PREPARACI\u00d3N CLI","text":"<p>Para comenzar esta pr\u00e1ctica, previamente es necesario tener instalada y configurada la interfaz de l\u00ednea de comandos de AWS</p> <p>A continuaci\u00f3n, se debe configurar la AWS CLI con las credenciales del AWS Academy Learner Lab. Para ello, desde la  consola del laboratorio, seleccionamos la opci\u00f3n AWS Details y a continuaci\u00f3n presionamos el bot\u00f3n Show en el apartado correspondiente a la AWS CLI.</p> <p>Como ya sabemos copiamos las credenciales al archivo credentials de aws</p>"},{"location":"ud05/bdpractica04.html#creacion-de-la-tabla-de-amazon-dynamo-db","title":"CREACI\u00d3N DE LA TABLA DE AMAZON DYNAMO DB","text":"<p>Para crear la tabla de Amazon DynamoDB de esta pr\u00e1ctica, accederemos a la consola de Amazon DynamoDB y, desde la opci\u00f3n Tables del men\u00fa lateral, presionamos el bot\u00f3n Create table:</p> <p></p> <p>(Mediante la consola de Administraci\u00f3n de AWS) En el asistente que aparece a continuaci\u00f3n, introduciremos el nombre de la tabla y los atributos que componen la clave primaria y sus correspondientes descriptores de tipos de datos, tal y como se indica a continuaci\u00f3n:</p> <ul> <li>Table name: curso</li> <li>Partition key: modulo (String)</li> <li>Sort key: alumno (String)</li> </ul> <p>El resto de las opciones las dejamos en sus valores por defecto y presionamos el bot\u00f3n Create table</p> <p></p> <p>Tras el proceso de creaci\u00f3n, podremos comprobar en la Consola de Administraci\u00f3n del servicio Amazon DynamoDB que nuestra tabla se ha creado correctamente</p> <p>Por \u00faltimo, vamos a poblar nuestra tabla de Amazon DynamoDB. Para ello ejecutamos el script que realizar\u00e1 tal funci\u00f3n:</p> <p>Descarga el scrip cargar-datos.sh y el archivo .json con los items</p> <p>Descargar cargar datos </p> <p>Descargar items</p> <p>Ahora ejecuta el script que poblar\u00e1 la base de datos de aws con la informaci\u00f3n que tiene en el archivo items-1.json</p> <p><code>./cargar-datos.sh</code></p> <p>Tras esta operaci\u00f3n, podremos volver a la Consola de Administraci\u00f3n del servicio Amazon DynamoDB y, entrando en la tabla curso podremos acceder al enlace del men\u00fa lateral Explorar elementos, seleccionar la tabla curso. Aparecer\u00e1n todos los elementos a\u00f1adidos por el script lanzado:</p> <p></p> <p>La tabla creada contiene informaci\u00f3n simulada de calificaciones de alumnos en diferentes asignaturas.</p>"},{"location":"ud05/bdpractica04.html#manipulacion-de-amazon-dynamo-db","title":"MANIPULACI\u00d3N DE AMAZON DYNAMO DB","text":"<p>Amazon DynamoDB dispone de las siguientes operaciones para manipular los datos de una tabla:</p> <ul> <li>GetItem. Permite recuperar un \u00fanico elemento en una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>PutItem. Permite introducir un \u00fanico elemento en una tabla de Amazon DynamoDB, identificado por los atributos clave, o su sobreescritura si ya exist\u00eda.</li> <li>DeleteItem. Permite eliminar un \u00fanico elemento de una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>UpdateItem. Permite actualizar un \u00fanico elemento de una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>Query. Permite recuperar un conjunto de elementos que tengan el mismo valor en su campo clave de partici\u00f3n (o clave hash) de una tabla de Amazon DynamoDB</li> <li>Scan. Permite recuperar un conjunto de elementos de todas las particiones de una tabla de   Amazon DynamoDB</li> </ul> <p>Ahora vamos a realizar alg\u00fan ejemplo de manipulaci\u00f3n de datos sobre esta base de datos mediante aws cli</p>"},{"location":"ud05/bdpractica04.html#operacion-1-obtener-las-calificaciones-del-alumno-paco-pandereta-en-el-modulo-de-historia","title":"Operaci\u00f3n 1: Obtener las calificaciones del alumno Paco Pandereta en el m\u00f3dulo de Historia","text":"<p>Para saber el dato correspondiente al alumno, es necesario indicar en un documento JSON la informaci\u00f3n con los datos de la clave del alumno que se desea obtener, crearemos un documento json de nombre operacion1.json e insertaremos en \u00e9l el siguiente c\u00f3digo:</p> <pre><code>{\n\"modulo\": { \"S\": \"Historia\" },\n\"alumno\": { \"S\": \"Paco Pandereta\" }\n}\n</code></pre> <p>Para ejecutar la consulta desde la AWS CLI introducimos el siguiente comando:</p> <pre><code>aws dynamodb get-item --table-name curso --key file://operacion1.json --projection-expression \"nota\"\n</code></pre> <p>En el comando anterior, se ejecuta una orden GetItem, indic\u00e1ndose los siguientes par\u00e1metros: --table-name: Nombre de nuestra tabla, en este caso curso --key: Fichero donde se encuentra el documento JSON con la informaci\u00f3n de los atributos clave del elemento que se obtendr\u00e1 --projection-expression: Indica los atributos del elemento obtenido que se proyectar\u00e1n en el resultado de la consulta</p> <p>Como resultado, se obtendr\u00e1 un documento JSON con los datos solicitados:</p> <p></p>"},{"location":"ud05/bdpractica04.html#operacion-2-introducir-un-nuevo-elemento-en-la-tabla-para-un-alumno-llamado-miguel-cervantes-saavedra-que-cursa-el-modulo-de-programacion-y-ha-obtenido-un-10-de-nota","title":"Operaci\u00f3n 2: Introducir un nuevo elemento en la tabla para un alumno llamado Miguel Cervantes Saavedra, que cursa el m\u00f3dulo de Programaci\u00f3n y ha obtenido un 10 de nota","text":"<p>Para introducir el elemento correspondiente al alumno, es necesario indicar en un documento JSON que llamaremos operacion2 la siguiente informaci\u00f3n</p> <pre><code>{\n  \"modulo\": { \"S\": \"Programaci\u00f3n\" },\n  \"alumno\": { \"S\": \"Miguel Cervantes Saavedra\" },\n  \"nota\": { \"N\": \"10\" }\n}\n</code></pre> <p>y despu\u00e9s ejecutar el comando</p> <pre><code>aws dynamodb put-item --table-name curso --item file://operacion2.json\n</code></pre> <p></p>"},{"location":"ud05/bdpractica04.html#las-siguientes-operaciones-realizalas-tu","title":"Las siguientes operaciones realizalas t\u00fa:","text":"<p>Operaci\u00f3n 3: Eliminar el elemento correspondiente al alumno de nombre Rosa Mosqueta Lledo que cursa el m\u00f3dulo de Historia Operaci\u00f3n 4: Actualiza el elemento correspondiente de la tabla, asumiendo que el alumno Rafa Raqueta hay que cambiarle la nota vamos a ponerle un 9 Operaci\u00f3n 5: Obtener las notas y nombres de los alumnos que cursan el m\u00f3dulo de Deportes <code>&lt;br&gt;</code></p> <p>Entrega</p> <p>Contenido del .json y comando ejecutado para realizar las operaciones 3, 4 y 5 Captura las pantallas con el resultado de realizar cada una de las operaciones</p>"},{"location":"ud05/ud5.html","title":"Tema 5. Bases de Datos en AWS","text":""},{"location":"ud05/ud5.html#introduccion","title":"Introducci\u00f3n","text":"<p>Las bases de datos son el coraz\u00f3n de casi cualquier aplicaci\u00f3n moderna. Permiten almacenar, organizar y recuperar informaci\u00f3n de forma estructurada y segura, y ser\u00e1n por tanto un elemento importante de cualquier infraestructura inform\u00e1tica.</p> <p>Para trabajar con una base de datos en AWS podemos optar por 2 modelos diferenciados seg\u00fan sean IaaS o PaaS:</p> <ul> <li>En el primer caso, en un modelo de Infraestructura como Servicio, contratar\u00edamos la m\u00e1quina virtual, en una red virtual e instalar\u00edamos el SGBD que consider\u00e1ramos oportuno (MySQL, SQL Server, PostgrsSQL, \u2026). En este modelo gestionar\u00edamos nosotros toda la infraestructura.</li> <li>En el caso de optar por un modelo de Plataforma como Servicio, contratar\u00edamos directamente el servicio de base de datos, sin preocuparnos por gestionar la infraestructura que hay por debajo (m\u00e1quina, red, sistema operativo y sistema gestor de base de datos). Es lo que se conoce como un servicio gestionado. Las bases de datos gestionadas son servicios de base de datos en la nube en los que el proveedor se encarga de toda la administraci\u00f3n y mantenimiento, desde la instalaci\u00f3n y configuraci\u00f3n inicial hasta la escalabilidad, seguridad, copias de seguridad y actualizaciones.</li> </ul> <p>Servicios BBDD en AWS</p> <p>AWS ofrece varios servicios gestionados de Bases de Datos. Los m\u00e1s populares son:</p> <ul> <li>RDS: Es una base de datos relacional gestionada basada en MySQL, PostrgreSQL, MariaDB, Oracle, Aurora o Microsoft SQL Server.</li> <li>Amazon Aurora: Es un SGBD propio de AWS compatible con MySQL y PostgrSQL que ofrece mejores prestaciones que RDS.</li> <li>Amazon DynamoDB: En este caso se trata de una base de datos NoSQL que soporta modelos de datos clave-valor y documentos.</li> <li>Amazon Neptune: Base de datos de grafos.</li> <li>Amazon Redshift: Base de datos relacional para almacenes de datos de Big Data.</li> </ul> <p>En este tema nos vamos a centrar en los 3 primeros: RDS, Aurora y DynamoDB.</p>"},{"location":"ud05/ud5.html#tipos-de-bases-de-datos","title":"Tipos de bases de datos","text":""},{"location":"ud05/ud5.html#bases-de-datos-relacionales-sql","title":"Bases de datos relacionales (SQL)","text":"<p>Las bases de datos relacionales organizan la informaci\u00f3n en tablas compuestas por filas y columnas, donde los datos se relacionan entre s\u00ed mediante claves primarias y externa. Ejemplos de bases de datos relacionales son MySQL, PostgreSQL, MariaDB, Oracle o SQL Server.</p> <p>En AWS, el servicio que gestiona este tipo de bases de datos es Amazon RDS (Relational Database Service).</p>"},{"location":"ud05/ud5.html#bases-de-datos-nosql","title":"Bases de datos NoSQL","text":"<p>Cuando los datos no siguen un esquema fijo (por ejemplo, registros de usuarios, logs o cat\u00e1logos de productos con diferentes atributos), las bases de datos NoSQL ofrecen mayor flexibilidad y rendimiento.</p> <p>Una base de datos NoSQL es un sistema de almacenamiento de datos que no utiliza el modelo relacional tradicional. En lugar de tablas con filas y columnas, organiza la informaci\u00f3n en estructuras m\u00e1s flexibles como documentos, pares clave-valor, grafos o columnas. Est\u00e1 pensada para manejar grandes vol\u00famenes de datos, alta velocidad de acceso y escalabilidad horizontal, lo que la hace ideal para aplicaciones web, big data y tiempo real.</p> <p>En el caso concreto de DynamoDB, la base de datos NoSQL de AWS, se utiliza un esquema de par clave-valor. </p>"},{"location":"ud05/ud5.html#rds","title":"RDS","text":"<p>Amazon RDS (Relational Database Service) es un servicio administrado que configura y opera una base de datos relacional en la nube.</p> <p>El componente de creaci\u00f3n b\u00e1sico de Amazon RDS es la instancia de base de datos. Una instancia de base de datos es un entorno de base de datos aislado que puede contener varias bases de datos creadas por el usuario. Se puede acceder a ella mediante las mismas herramientas y aplicaciones que se utilizan con una instancia de base de datos independiente.</p> <p>Las instancias de base de datos y el almacenamiento difieren en cuanto a caracter\u00edsticas de rendimiento y precio, lo que le permite personalizar el rendimiento y el costo seg\u00fan las necesidades de la base de datos. Al crear una instancia de base de datos, primero se debe especificar qu\u00e9 motor de base de datos se va a ejecutar. </p> <p>Amazon RDS admite actualmente seis bases de datos: </p> Motor Caracter\u00edsticas Casos de uso MariaDB Open source, compatible con MySQL, alto rendimiento Aplicaciones web, CMS como WordPress MySQL Amplio soporte y comunidad, ideal para proyectos peque\u00f1os y medianos Aplicaciones de comercio electr\u00f3nico o SaaS PostgreSQL Robusto, con soporte para JSON, funciones avanzadas Aplicaciones empresariales y anal\u00edticas Amazon Aurora Compatible con MySQL y PostgreSQL, optimizado por AWS Aplicaciones cr\u00edticas que requieren alta disponibilidad Otros (Oracle, SQL Server) Integraci\u00f3n empresarial, soporte para procedimientos almacenados ERP, CRM, entornos corporativos"},{"location":"ud05/ud5.html#caso-tipico-de-rds-en-una-vpc","title":"Caso t\u00edpico de RDS en una VPC","text":"<p>Un caso sencillo de uso de una instancia RDS es el ubicarla en una subred de nuestra VPC para que sea accesible \u00fanicamente por servicios de nuestra propia VPC (por ejemplo, una instancia EC2 con un servidor web) y no accesible directamente desde el exterior.</p> <p></p>"},{"location":"ud05/ud5.html#alta-disponibilidad","title":"Alta disponibilidad","text":"<p>Una de las funciones m\u00e1s potentes de Amazon RDS es la posibilidad de configurar la instancia de base de datos para una alta disponibilidad con un despliegue Multi-AZ. Amazon RDS genera autom\u00e1ticamente una copia en espera de la instancia de base de datos en otra zona de disponibilidad de la misma VPC. Tras propagar la copia de la base de datos, las transacciones se replican de forma s\u00edncrona en la copia en espera.</p> <p>Replicaci\u00f3n s\u00edncrona y as\u00edncrona</p> <p>Replicaci\u00f3n s\u00edncrona:</p> <ul> <li>La escritura se confirma solo cuando los datos se guardan en todas las zonas.</li> <li>Garantiza que todas las r\u00e9plicas est\u00e9n actualizadas al instante.</li> <li>Ventaja: m\u00e1xima consistencia de datos.</li> <li>Inconveniente: puede tener m\u00e1s latencia porque espera la confirmaci\u00f3n de la r\u00e9plica.</li> </ul> <p>Replicaci\u00f3n as\u00edncrona: </p> <ul> <li>La escritura se confirma solo en la zona principal, y las r\u00e9plicas se actualizan despu\u00e9s.</li> <li>Ventaja: mejor rendimiento y menor latencia.</li> <li>Inconveniente: si falla la zona principal, las r\u00e9plicas pueden quedar ligeramente desactualizadas.</li> </ul> <p>Esta configuraci\u00f3n protege las bases de datos contra errores de la instancia de base de datos e interrupciones de la zona de disponibilidad. </p> <p></p> <p>Si la instancia de base de datos principal falla en un despliegue Multi-AZ, Amazon RDS pone en l\u00ednea autom\u00e1ticamente la instancia de base de datos en espera como nueva instancia principal. Dado que las aplicaciones hacen referencia a la base de datos por su nombre mediante el punto de enlace del sistema de nombres de dominio (DNS), no es necesario cambiar nada en el c\u00f3digo de la aplicaci\u00f3n para utilizar la copia en espera para la conmutaci\u00f3n por error.</p>"},{"location":"ud05/ud5.html#replicas-de-lectura","title":"R\u00e9plicas de lectura","text":"<p>Amazon RDS tambi\u00e9n soporta la creaci\u00f3n de r\u00e9plicas de lectura. Las actualizaciones realizadas en la instancia de base de datos fuente se copian de forma as\u00edncrona en la instancia de r\u00e9plica de lectura. </p> <p>Se puede reducir la carga sobre la instancia de base de datos de origen por medio del enrutamiento de las consultas de lectura desde las aplicaciones a la r\u00e9plica de lectura. </p> <p>Las r\u00e9plicas de lectura permiten escalar horizontalmente y tambi\u00e9n por encima de las restricciones de capacidad de una instancia de base de datos \u00fanica para las cargas de trabajo de las bases de datos con operaciones intensivas de lectura. </p> <p>Las r\u00e9plicas de lectura tambi\u00e9n pueden promoverse para convertirse en la instancia de base de datos primaria, pero esto requiere una acci\u00f3n manual debido a la replicaci\u00f3n as\u00edncrona.</p> <p></p>"},{"location":"ud05/ud5.html#aurora","title":"Aurora","text":"<p>Amazon Aurora es un motor de base de datos relacional administrado, totalmente compatible con MySQL y PostgreSQL. Ofrece el rendimiento y la disponibilidad de las bases de datos comerciales (como Oracle o SQL Server), pero con un coste m\u00e1s reducido y la simplicidad de las bases de datos de c\u00f3digo abierto.</p> <p>Al estar desarrollado de forma nativa por Amazon, est\u00e1 dise\u00f1ado espec\u00edficamente para la nube y se adapta mejor en coste, rendimiento y alta disponibilidad. Est\u00e1 pensado como un subsistema de almacenamiento distribuido de alto rendimiento y tolerante a fallos:</p> <ul> <li>Los datos se replican autom\u00e1ticamente en tres zonas de disponibilidad (Multi-AZ), con hasta seis copias de cada bloque de datos.</li> <li>Esta replicaci\u00f3n es s\u00edncrona entre las zonas, garantizando alta consistencia y recuperaci\u00f3n autom\u00e1tica ante fallos.</li> <li>Adem\u00e1s, permite r\u00e9plicas de lectura (hasta 15) para escalar el rendimiento en aplicaciones con muchas consultas.</li> </ul> <p>Ofrece dos modelos, el cl\u00e1sico basado en instancias y un modelo serverless. </p> <p>Aurora Serverless es una modalidad muy interesante, ya que elimina la necesidad de aprovisionar capacidad de forma fija:</p> <ul> <li>Escala autom\u00e1ticamente el n\u00famero de recursos de c\u00f3mputo (CPU y memoria) seg\u00fan la carga de trabajo.</li> <li>Si no hay actividad, puede detenerse por completo, lo que reduce costes.</li> <li>Cuando vuelve a recibir peticiones, se reactiva autom\u00e1ticamente en pocos segundos.</li> <li>Es ideal para aplicaciones con uso intermitente, entornos de desarrollo o pruebas, y cargas variables o impredecibles.</li> </ul> <p>Aurora tambi\u00e9n realiza copias de seguridad continuas en Amazon S3, sin impacto en el rendimiento, y permite restaurar la base de datos a cualquier punto en el tiempo.</p>"},{"location":"ud05/ud5.html#dynamodb","title":"DynamoDB","text":"<p>DynamoDB es un servicio administrado de base de datos NoSQL muy r\u00e1pido y flexible:</p> <ul> <li>Base de datos NoSQL totalmente gestionada.</li> <li>Almacena datos en formato clave-valor o documento.</li> <li>Escala autom\u00e1ticamente en funci\u00f3n de la carga.</li> <li>Latencia baja (milisegundos) ideal para aplicaciones m\u00f3viles o IoT.</li> <li>Es muy flexible y sin estructura fija (los elementos pueden tener atributos diferentes).</li> </ul> <p>Ejemplo de uso</p> <p>Una aplicaci\u00f3n de videojuegos que almacena estad\u00edsticas de jugadores en tiempo real. DynamoDB gestiona millones de solicitudes sin necesidad de administrar servidores.</p> <p>En el caso concreto de DynamoDB, se utiliza un esquema de par clave-valor. Las bases de datos clave-valor funcionan como un gran diccionario o mapa asociativo, cada dato se guarda con una clave \u00fanica que sirve para identificarlo y recuperarlo:</p> <ul> <li>La clave act\u00faa como un identificador (por ejemplo, un n\u00famero o un nombre).</li> <li>El valor es el dato asociado (que puede ser texto, un objeto, un JSON, etc.).</li> </ul> <p>El acceso es muy r\u00e1pido porque el sistema busca directamente la clave sin recorrer estructuras complejas.</p> <p>Los componentes principales son:</p> <ul> <li>las tablas: son conjuntos de datos, formada por los elementos.</li> <li>los elementos: grupo de atributos que pueden identificar de forma exclusiva a un registro.</li> <li>los atributos: elementos de datos fundamental que no es preciso seguir dividiendo.</li> </ul> <p>DynamoDB soporta dos tipos de claves principales:</p> <ul> <li>La clave de partici\u00f3n es una clave principal simple.</li> <li>La clave de partici\u00f3n y de ordenamiento, tambi\u00e9n conocidas como clave principal compuesta, ya que est\u00e1 formada por dos atributos.</li> </ul> <p></p> <p>Ejemplo de una tabla denominada usuario:</p> Partition Key (clave primaria) Valor (atributos) <code>user_001</code> <code>{ \"nombre\": \"Ana\", \"email\": \"ana@example.com\", \"puntos\": 150 }</code> <code>user_002</code> <code>{ \"nombre\": \"Luis\", \"puntos\": 80 }</code> <code>user_003</code> <code>{ \"nombre\": \"Mar\u00eda\", \"email\": \"maria@example.com\", \"pais\": \"Espa\u00f1a\", \"suscripcion\": \"premium\" }</code> <code>user_004</code> <code>{ \"nombre\": \"Carlos\" }</code> <p>En este ejemplo todos los \u00edtems tienen una clave primaria \u00fanica (<code>user_001</code>, <code>user_002</code>, etc.).</p> <p>No todos los \u00edtems tienen los mismos campos. DynamoDB permite esto porque no requiere un esquema fijo, a diferencia de las bases de datos relacionales.</p> <p>Si hici\u00e9ramos una consulta sobre un item, se nos devolver\u00eda la siguiente informaci\u00f3n en formato json:</p> <pre><code>{\n  \"Item\": {\n    \"user_id\": {\"S\": \"user_003\"},\n    \"nombre\": {\"S\": \"Mar\u00eda\"},\n    \"email\": {\"S\": \"maria@example.com\"},\n    \"pais\": {\"S\": \"Espa\u00f1a\"},\n    \"suscripcion\": {\"S\": \"premium\"}\n  }\n}\n</code></pre>"},{"location":"ud05/ud5.html#seleccion-de-tecnologias-de-almacenamiento","title":"Selecci\u00f3n de tecnolog\u00edas de almacenamiento","text":"<p>La elecci\u00f3n del servicio adecuado depende de varios factores:</p> Requisito Servicio recomendado Motivo Aplicaci\u00f3n web tradicional RDS (MySQL o Aurora) Relacional, consistente, soporta SQL Aplicaci\u00f3n de IoT o juegos DynamoDB Escalabilidad y baja latencia Alta disponibilidad cr\u00edtica Aurora Multi-AZ R\u00e9plicas autom\u00e1ticas, resiliencia Coste bajo y simplicidad RDS con instancias peque\u00f1as Configuraci\u00f3n r\u00e1pida y gesti\u00f3n m\u00ednima"},{"location":"ud07/practica1.html","title":"Practica1","text":"<p>Perfecto \ud83d\udd25 \u2014 te preparo una pr\u00e1ctica completa de laboratorio de AWS centrada en IAM, pol\u00edticas y roles, ideal para un entorno educativo (como el m\u00f3dulo de Implantaci\u00f3n de Sistemas Operativos del ciclo de ASIR).</p>"},{"location":"ud07/practica1.html#practica-creacion-y-aplicacion-de-politicas-y-roles-en-aws","title":"\ud83e\uddea Pr\u00e1ctica: Creaci\u00f3n y aplicaci\u00f3n de pol\u00edticas y roles en AWS","text":""},{"location":"ud07/practica1.html#objetivos","title":"\ud83c\udfaf Objetivos","text":"<ul> <li>Comprender c\u00f3mo funcionan las pol\u00edticas y los roles en AWS IAM.</li> <li>Crear y aplicar una pol\u00edtica personalizada.</li> <li>Asociar un rol a una instancia EC2 para controlar el acceso a S3 sin usar credenciales.</li> </ul>"},{"location":"ud07/practica1.html#1-preparacion-del-entorno","title":"\ud83e\udded 1\ufe0f\u20e3. Preparaci\u00f3n del entorno","text":"<ol> <li>Accede a la Consola de AWS.</li> <li>En el buscador superior, escribe IAM y entra al servicio.</li> <li>Verifica que est\u00e1s en la regi\u00f3n donde crear\u00e1s los recursos (por ejemplo, <code>eu-west-1</code>).</li> </ol>"},{"location":"ud07/practica1.html#2-creacion-de-una-politica-personalizada","title":"\ud83e\udde9 2\ufe0f\u20e3. Creaci\u00f3n de una pol\u00edtica personalizada","text":""},{"location":"ud07/practica1.html#objetivo","title":"\ud83d\udd38 Objetivo:","text":"<p>Permitir solo lectura de objetos dentro de un bucket S3 concreto.</p>"},{"location":"ud07/practica1.html#pasos","title":"\ud83d\udd38 Pasos:","text":"<ol> <li>En el panel lateral, selecciona Policies \u2192 Create policy.</li> <li>Elige la pesta\u00f1a JSON y pega lo siguiente:</li> </ol> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::asir-lab-bucket\",\n        \"arn:aws:s3:::asir-lab-bucket/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <ol> <li>Pulsa Next, asigna el nombre:    \ud83d\udc49 <code>LecturaS3Personalizada</code>    y una descripci\u00f3n breve.</li> <li>Crea la pol\u00edtica.</li> </ol> <p>\ud83d\udcd8 Consejo: sustituye <code>asir-lab-bucket</code> por el nombre real del bucket que usar\u00e1s.</p>"},{"location":"ud07/practica1.html#3-creacion-de-un-rol-con-permisos-controlados","title":"\ud83e\uddd1\u200d\ud83d\udcbb 3\ufe0f\u20e3. Creaci\u00f3n de un rol con permisos controlados","text":""},{"location":"ud07/practica1.html#objetivo_1","title":"\ud83d\udd38 Objetivo:","text":"<p>Permitir que una instancia EC2 lea objetos del bucket S3 usando el rol (sin claves de acceso).</p>"},{"location":"ud07/practica1.html#pasos_1","title":"\ud83d\udd38 Pasos:","text":"<ol> <li>En IAM \u2192 Roles \u2192 Create role.</li> <li>Selecciona AWS service \u2192 EC2, y haz clic en Next.</li> <li>Adjunta la pol\u00edtica reci\u00e9n creada LecturaS3Personalizada.</li> <li>Asigna nombre al rol:    \ud83d\udc49 <code>rol-ec2-lectura-s3</code>.</li> <li>Crea el rol.</li> </ol>"},{"location":"ud07/practica1.html#4-creacion-de-la-instancia-ec2","title":"\ud83d\udcbb 4\ufe0f\u20e3. Creaci\u00f3n de la instancia EC2","text":"<ol> <li>Ve al servicio EC2 \u2192 Instances \u2192 Launch instance.</li> <li> <p>Elige:</p> </li> <li> <p>AMI: Amazon Linux 2 o Ubuntu.</p> </li> <li>Tipo de instancia: <code>t2.micro</code>.</li> <li>En el apartado IAM role, selecciona rol-ec2-lectura-s3.</li> <li>Lanza la instancia.</li> </ol> <p>\ud83d\udca1 Este paso vincula la instancia con el rol IAM, otorg\u00e1ndole permisos temporales sin claves.</p>"},{"location":"ud07/practica1.html#5-verificacion-desde-la-instancia","title":"\ud83e\uddf0 5\ufe0f\u20e3. Verificaci\u00f3n desde la instancia","text":"<ol> <li>Con\u00e9ctate a la instancia mediante SSH.</li> </ol> <p><pre><code>ssh -i \"clave.pem\" ec2-user@&lt;IP-P\u00daBLICA&gt;\n</code></pre> 2. Instala la CLI de AWS (si no est\u00e1 instalada):</p> <p><pre><code>sudo yum install -y awscli\n</code></pre> 3. Comprueba el acceso al bucket:</p> <pre><code>aws s3 ls s3://asir-lab-bucket\n</code></pre> <p>\ud83d\udcd8 Si la pol\u00edtica est\u00e1 bien configurada, ver\u00e1s el listado de objetos. Si intentas subir un archivo, fallar\u00e1:</p> <pre><code>aws s3 cp test.txt s3://asir-lab-bucket/\n</code></pre> <p>\u2192 AccessDenied (porque la pol\u00edtica solo permite lectura).</p>"},{"location":"ud07/practica1.html#6-prueba-con-otro-rol-ampliacion-opcional","title":"\ud83d\udd10 6\ufe0f\u20e3. Prueba con otro rol (ampliaci\u00f3n opcional)","text":"<ol> <li>Crea una nueva pol\u00edtica llamada <code>EscrituraS3Personalizada</code>:</li> </ol> <p><pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:PutObject\"],\n      \"Resource\": [\"arn:aws:s3:::asir-lab-bucket/*\"]\n    }\n  ]\n}\n</code></pre> 2. Crea un nuevo rol rol-ec2-escritura-s3 y as\u00edgnale esa pol\u00edtica. 3. Cambia el rol de la instancia EC2:</p> <ul> <li>EC2 \u2192 Instancia \u2192 pesta\u00f1a Security \u2192 Modify IAM role.</li> <li>Selecciona <code>rol-ec2-escritura-s3</code>.</li> <li>Vuelve a probar el comando <code>aws s3 cp</code>.    \u2192 Esta vez deber\u00eda funcionar.</li> </ul>"},{"location":"ud07/practica1.html#7-limpieza-del-laboratorio","title":"\ud83d\udccb 7\ufe0f\u20e3. Limpieza del laboratorio","text":"<p>Para evitar costes:</p> <ol> <li>Det\u00e9n o elimina la instancia EC2.</li> <li>Elimina los roles creados.</li> <li>Elimina las pol\u00edticas personalizadas.</li> <li>Si creaste buckets, b\u00f3rralos si ya no los necesitas.</li> </ol>"},{"location":"ud07/practica1.html#conclusiones","title":"\ud83e\udde0 Conclusiones","text":"<ul> <li>Las pol\u00edticas IAM definen qu\u00e9 acciones se pueden realizar sobre qu\u00e9 recursos.</li> <li>Los roles permiten asignar permisos a servicios o identidades temporales sin usar credenciales.</li> <li>Las pol\u00edticas pueden ser muy espec\u00edficas, limitando el acceso a buckets, prefijos o acciones concretas.</li> <li>El modelo se basa siempre en el principio de m\u00ednimos privilegios.</li> </ul>"},{"location":"ud07/ud07.html","title":"Tema 7. Modelo de Seguridad de AWS","text":""},{"location":"ud07/ud07.html#modelo-de-seguridad-de-aws","title":"Modelo de Seguridad de AWS","text":"<p>El modelo de seguridad de AWS se basa en el principio de responsabilidad compartida: AWS asegura la infraestructura, y el cliente asegura los datos y la configuraci\u00f3n de sus servicios.</p>"},{"location":"ud07/ud07.html#responsabilidad-compartida","title":"Responsabilidad compartida","text":"Parte Qu\u00e9 asegura AWS Seguridad de la infraestructura f\u00edsica, hardware, redes, centros de datos y servicios gestionados. Cliente Configuraci\u00f3n de los servicios, control de acceso, cifrado de datos, seguridad de aplicaciones y sistemas operativos. <p>Ejemplo</p> <p>En EC2, AWS asegura el hardware y la red, pero nosotros debemos proteger nuestro sistema operativo, usuarios y aplicaciones.</p>"},{"location":"ud07/ud07.html#identidad-y-acceso-iam","title":"Identidad y acceso (IAM)","text":"<p>AWS gestiona la autenticaci\u00f3n y autorizaci\u00f3n mediante IAM (Identity and Access Management):</p> <ul> <li>Usuarios y grupos: cuentas dentro de la organizaci\u00f3n.</li> <li>Roles: permisos temporales para servicios o usuarios externos.</li> <li>Pol\u00edticas: reglas que definen qu\u00e9 acciones puede realizar un usuario o servicio sobre un recurso.</li> </ul>"},{"location":"ud07/ud07.html#cifrado-de-datos","title":"Cifrado de datos","text":"<p>AWS permite cifrar datos en reposo y en tr\u00e1nsito:</p> <ul> <li> <p>En reposo:</p> <ul> <li>S3, EBS, RDS y DynamoDB soportan cifrado con claves gestionadas por AWS ** o propias**.</li> </ul> </li> <li> <p>En tr\u00e1nsito:</p> <ul> <li>TLS/SSL para proteger la comunicaci\u00f3n entre servicios y clientes.</li> </ul> </li> </ul>"},{"location":"ud07/ud07.html#red-y-perimetro","title":"Red y per\u00edmetro","text":"<p>AWS protege la red mediante servicios y configuraciones:</p> <ul> <li>VPC (Virtual Private Cloud): redes privadas aisladas en la nube.</li> <li>Subredes, ACLs y Security Groups: control granular de tr\u00e1fico entrante y saliente.</li> <li>AWS Shield y WAF: protecci\u00f3n frente a ataques DDoS y filtrado de tr\u00e1fico web malicioso.</li> </ul>"},{"location":"ud07/ud07.html#monitorizacion-y-auditoria","title":"Monitorizaci\u00f3n y auditor\u00eda","text":"<ul> <li>CloudTrail: registro de todas las acciones de API realizadas en la cuenta.</li> <li>CloudWatch: monitorizaci\u00f3n de m\u00e9tricas y eventos de los recursos.</li> <li>GuardDuty: detecci\u00f3n de amenazas mediante an\u00e1lisis de logs y patrones sospechosos.</li> </ul>"},{"location":"ud07/ud07.html#cumplimiento-y-certificaciones","title":"Cumplimiento y certificaciones","text":"<p>AWS cumple con normas de seguridad y privacidad reconocidas internacionalmente.</p> <p>Esto permite que las empresas conf\u00eden en la infraestructura para aplicaciones cr\u00edticas y reguladas.</p>"},{"location":"ud07/ud07.html#aws-iam-identity-and-access-management","title":"AWS IAM (Identity and Access Management)","text":"<p>AWS Identity and Access Management (IAM) es el servicio de gesti\u00f3n de identidades y control de acceso de Amazon Web Services.</p> <p>Permite administrar de forma segura qui\u00e9n puede acceder a los recursos de AWS y qu\u00e9 acciones puede realizar.</p> <p>IAM es gratuito (no tiene coste adicional) y se integra en todos los servicios de AWS.</p> <p>Info</p> <p>Es un componente central del modelo de seguridad de AWS y se basa en el principio de m\u00ednimos privilegios: cada usuario o servicio solo debe tener los permisos estrictamente necesarios para realizar su tarea.</p>"},{"location":"ud07/ud07.html#usuario-grupos-roles-y-politicas","title":"Usuario, Grupos, Roles y Pol\u00edticas","text":"<p>IAM se organiza alrededor de identidades, pol\u00edticas y permisos.</p> <p>Usuarios</p> <p>Representan personas o aplicaciones que necesitan acceder a AWS.</p> <ul> <li>Tienen credenciales: nombre de usuario y contrase\u00f1a (para la consola web) o claves de acceso (para la CLI o APIs).</li> <li>Pueden a\u00f1adirse a grupos o recibir permisos directamente.</li> <li>Ejemplo: <code>usuario_admin</code>, <code>usuario_lectura</code>, <code>aplicacion_api</code>.</li> </ul> <p>Grupos</p> <p>Conjuntos l\u00f3gicos de usuarios con permisos comunes.</p> <ul> <li>Sirven para gestionar permisos de forma masiva.</li> <li>Ejemplo: grupo <code>Desarrolladores</code> con permisos sobre instancias EC2 y buckets S3.</li> </ul> <p>Roles</p> <p>Identidades sin credenciales propias, dise\u00f1adas para ser asumidas temporalmente por usuarios, servicios o recursos.</p> <ul> <li>Muy usados para otorgar permisos a servicios de AWS (como EC2 o Lambda) sin exponer claves.</li> <li>Ejemplo: una instancia EC2 que necesita leer un bucket S3 utiliza un rol IAM con ese permiso.</li> </ul> <p>Pol\u00edticas (Policies)</p> <p>Son documentos en formato JSON que definen los permisos.</p> <p>Las vemos con dentenimiento en el siguiente apratado.</p>"},{"location":"ud07/ud07.html#autorizacion-como-aws-decide-si-algo-esta-permitido","title":"Autorizaci\u00f3n: c\u00f3mo AWS decide si algo est\u00e1 permitido","text":"<p>Cada vez que un usuario o servicio hace una petici\u00f3n a AWS, IAM eval\u00faa todas las pol\u00edticas asociadas y aplica una l\u00f3gica de decisi\u00f3n:</p> <ol> <li>Por defecto todo est\u00e1 denegado.</li> <li>Si una pol\u00edtica permite la acci\u00f3n, pasa a estado permitido provisionalmente.</li> <li>Si alguna pol\u00edtica deniega expl\u00edcitamente una acci\u00f3n, la petici\u00f3n se bloquea siempre.</li> </ol> <p>Esto se conoce como el modelo Deny by default.</p>"},{"location":"ud07/ud07.html#roles-y-delegacion-de-permisos","title":"Roles y delegaci\u00f3n de permisos","text":"<p>Los roles IAM permiten delegar permisos de forma temporal y controlada. Se usan, por ejemplo, para:</p> <ul> <li>Permitir que una instancia EC2 acceda a un bucket S3 sin usar claves.</li> <li>Conceder permisos temporales a usuarios externos o cuentas de otra organizaci\u00f3n (cross-account roles).</li> <li>Autorizar a servicios de AWS (como Lambda o ECS) para actuar en nombre del usuario.</li> </ul> <p>Nota</p> <p>IAM es el coraz\u00f3n de la seguridad en AWS: controla qui\u00e9n entra, qu\u00e9 puede hacer y con qu\u00e9 recursos, garantizando una gesti\u00f3n centralizada, segura y flexible del acceso a la nube.</p>"},{"location":"ud07/ud07.html#politicas-de-iam-en-aws","title":"Pol\u00edticas de IAM en AWS","text":"<p>Las pol\u00edticas son documentos en formato JSON que definen los permisos que se conceden o deniegan a un usuario, grupo o rol en AWS.</p> <p>Es decir...</p> <p>Una pol\u00edtica indica qu\u00e9 acciones puede realizar un sujeto (usuario, grupo o rol) sobre qu\u00e9 recursos y bajo qu\u00e9 condiciones.</p> <p>Son el n\u00facleo del modelo de control de acceso en AWS: sin una pol\u00edtica asociada, ning\u00fan usuario o servicio tiene permisos.</p> <ul> <li> <p>Especifican:</p> <ul> <li>Acciones (<code>Action</code>): qu\u00e9 operaciones se permiten o deniegan.</li> <li>Recursos (<code>Resource</code>): sobre qu\u00e9 objetos se aplican.</li> <li>Efecto (<code>Effect</code>): <code>Allow</code> o <code>Deny</code>.</li> </ul> </li> </ul> <p>Cuando un usuario intenta realizar una acci\u00f3n, AWS eval\u00faa las pol\u00edticas siguiendo este orden:</p> <ol> <li>Denegaci\u00f3n expl\u00edcita (Deny) \u2192 siempre prevalece.</li> <li>Permiso expl\u00edcito (Allow) \u2192 concede acceso si no hay una denegaci\u00f3n previa.</li> <li>Por defecto, todo est\u00e1 denegado hasta que una pol\u00edtica lo permita.</li> </ol> <p>Regla de oro</p> <p>Si no hay una pol\u00edtica <code>Allow</code>, la acci\u00f3n no se ejecutar\u00e1.</p> <ul> <li>Ejemplo de pol\u00edtica simple:</li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:ListBucket\", \"s3:GetObject\"],\n      \"Resource\": [\"arn:aws:s3:::mi-bucket\", \"arn:aws:s3:::mi-bucket/*\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"ud07/ud07.html#tipos-de-politicas","title":"Tipos de pol\u00edticas","text":"<p>AWS ofrece varios tipos de pol\u00edticas, clasificadas seg\u00fan c\u00f3mo y d\u00f3nde se aplican:</p> Tipo de pol\u00edtica Descripci\u00f3n Ejemplo Administradas por AWS Pol\u00edticas predefinidas creadas y mantenidas por AWS. Simplifican la gesti\u00f3n y se actualizan autom\u00e1ticamente. <code>AmazonS3ReadOnlyAccess</code>, <code>AdministratorAccess</code> Administradas por el cliente Pol\u00edticas personalizadas creadas por el usuario para definir permisos espec\u00edficos. Pol\u00edtica que permite acceso de lectura a un bucket concreto. Inline (insertadas) Pol\u00edticas directamente incrustadas en un usuario, grupo o rol concreto. No son reutilizables. Pol\u00edtica personalizada dentro de un rol de EC2."},{"location":"ud07/ud07.html#estructura-y-sintaxis-de-una-politica-json","title":"Estructura y sintaxis de una pol\u00edtica (JSON)","text":"<p>Las pol\u00edticas de IAM siguen una estructura JSON con campos obligatorios y opcionales:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::mi-bucket\",\n        \"arn:aws:s3:::mi-bucket/*\"\n      ],\n      \"Condition\": {\n        \"IpAddress\": {\n          \"aws:SourceIp\": \"203.0.113.0/24\"\n        }\n      }\n    }\n  ]\n}\n</code></pre> <p>Desglose de los campos:</p> Campo Descripci\u00f3n Obligatorio Version Indica la versi\u00f3n del lenguaje de pol\u00edticas. Actualmente se usa <code>\"2012-10-17\"</code>. \u2705 Statement Lista de reglas que definen permisos. Puede contener una o varias. \u2705 Effect Determina si la acci\u00f3n se permite (<code>Allow</code>) o deniega (<code>Deny</code>). \u2705 Action Especifica las acciones de AWS que se permiten o deniegan (por ejemplo, <code>s3:PutObject</code>, <code>ec2:StartInstances</code>). \u2705 Resource Indica los recursos espec\u00edficos sobre los que se aplican los permisos, usando su ARN. \u2705 Condition Define condiciones opcionales (por IP, usuario, hora, MFA, etc.) que deben cumplirse para que se concedan los permisos. \u274c"},{"location":"ud07/ud07.html#ejemplo-practico-politica-personalizada","title":"Ejemplo pr\u00e1ctico: pol\u00edtica personalizada","text":"<p>Objetivo: Permitir a un usuario listar y leer objetos del bucket <code>iescamp-datos</code>, pero no borrarlos.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"LeerBucketIESCAMP\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:ListBucket\",\n        \"s3:GetObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::iescamp-datos\",\n        \"arn:aws:s3:::iescamp-datos/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>Sid (Statement ID): campo opcional para identificar el bloque de permisos.</p> <p>Los ARN (Amazon Resource Names) identifican de forma \u00fanica los recursos en AWS.</p> <p>Ejemplo de estructura:</p> <pre><code>arn:aws:servicio:regi\u00f3n:cuenta:recurso\n</code></pre> <p>Ejemplo para un bucket S3:</p> <pre><code>arn:aws:s3:::mi-bucket\narn:aws:s3:::mi-bucket/mis-archivos/*\n</code></pre>"}]}