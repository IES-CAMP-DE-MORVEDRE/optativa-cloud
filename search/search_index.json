{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Introducci\u00f3n a la nube","text":"<p>M\u00f3dulo optativo de Introducci\u00f3n al Cloud Computing de CFGS ASIR, DAM y DAW</p> <p>Iniciar ahora Ver en GitHub</p> <p>La computaci\u00f3n en la nube (cloud computing) ha transformado radicalmente la forma en que las empresas y usuarios acceden, almacenan y procesan la informaci\u00f3n. Este modelo tecnol\u00f3gico permite disponer de recursos inform\u00e1ticos bajo demanda a trav\u00e9s de Internet, sin necesidad de adquirir ni mantener infraestructuras f\u00edsicas propias. En el entorno profesional actual, donde la escalabilidad, la flexibilidad y la eficiencia son factores clave, conocer el funcionamiento y las posibilidades de la nube se ha convertido en una competencia esencial para cualquier t\u00e9cnico en inform\u00e1tica.</p> <p>Estos apuntes est\u00e1n dise\u00f1ados como una introducci\u00f3n pr\u00e1ctica y accesible al mundo de la computaci\u00f3n en la nube para la asignatura optativa de segundo curso de ciclos formativos de grado superior. A lo largo de los diferentes temas se abordar\u00e1n los fundamentos del modelo cloud, los principales tipos de servicios (IaaS, PaaS, SaaS), las plataformas m\u00e1s utilizadas (centr\u00e1ndonos en AWS), as\u00ed como aspectos b\u00e1sicos de seguridad, automatizaci\u00f3n y despliegue de aplicaciones. El objetivo es proporcionar una base s\u00f3lida que permita al estudiante comprender el paradigma cloud y dar sus primeros pasos en el uso de estas tecnolog\u00edas en contextos reales.</p>"},{"location":"pr01/elasticip.html","title":"Creaci\u00f3n y asignaci\u00f3n de una direcci\u00f3n IP el\u00e1stica","text":""},{"location":"pr01/elasticip.html#asignacion-de-una-ip-elastica","title":"Asignaci\u00f3n de una IP el\u00e1stica","text":"<p>1.- Partiendo de una instancia EC2 ya creada, accedemos desde el Panel de Instancias de EC2 al apartado de Direcciones IP el\u00e1sticas del panel lateral.</p> <p></p> <p></p> <p>2.- Pulsamos sobre Asignar direcci\u00f3n el\u00e1stica. Dejamos las opciones por defecto y pulsamos Asignar.</p> <p>Comienza la facturaci\u00f3n</p> <p>De momento ya tenemos una IP fija reservada y ya comienzan a facturarnos por ella aunque no la hemos asociado a ning\u00fan elemento de AWS. </p> <p>Las IP El\u00e1sticas pueden asociarse a varios recursos de AWS, como por ejemplo Instancias EC2, Interfaces de Red El\u00e1sticas, NAT Gateway (por eso son tan caros estos elementos), Balanceadores de Carga, y otros menos comunes.</p> <p></p> <p>3.- El siguiente paso, por tanto, es asociarla a nuestra instancia EC2. La seleccionamos y pulsamos sobre Direcci\u00f3n IP el\u00e1stica asociada</p> <p></p> <p>4.- Seleccionamos la instancia EC2 a la que la queremos asociar y aceptamos.</p> <p></p> <p>A partir de este momento ya tenemos una IP fija asociada a nuestra instancia EC2.</p> <p>Peligro</p> <p>Aunque eliminemos la instancia EC2, la direcci\u00f3n IP el\u00e1stica quedar\u00e1 reservada. Hay que asegurarse siempre de eliminar estos recursos que consumen cr\u00e9dito incluso con el laboratorio apagado.</p>"},{"location":"pr01/elasticip.html#desasociacion-y-liberacion-de-la-ip-elastica","title":"Desasociaci\u00f3n y liberaci\u00f3n de la IP el\u00e1stica","text":"<p>Cuando ya no deseemos hacer uso de la IP el\u00e1stica hay que liberarla, es decir, hacerla p\u00fablica para que est\u00e9 disponible para el resto de usuarios y dejen de facturarnos a nosotros.</p> <p>5.- El primer paso ser\u00e1 desasociar la IP el\u00e1stica de nuestra instancia EC2. Seleccionamos esa opci\u00f3n del men\u00fa acciones.</p> <p></p> <p></p> <p>6.- Una vez desasociada, ya podremos liberar la IP el\u00e1stica, es decir, hacerla p\u00fablica y que deje de pertencernos.</p> <p></p>"},{"location":"pr01/pr01.html","title":"Proyecto 1. Infraestructura Segura de Servidores Internos y P\u00fablicos en AWS","text":""},{"location":"pr01/pr01.html#contexto","title":"Contexto","text":"<p>La empresa NovaWeb Solutions se dedica al desarrollo y despliegue de sitios web para clientes externos. Hasta ahora, su entorno de pruebas y publicaci\u00f3n se encontraba en servidores locales, pero ha decidido migrarlo completamente a la nube de AWS.</p> <p>Tu misi\u00f3n como ingeniero DevOps en la empresa es dise\u00f1ar y desplegar la infraestructura base que dar\u00e1 soporte a sus proyectos, asegurando conectividad, seguridad, y un aprovechamiento eficiente de los recursos.</p>"},{"location":"pr01/pr01.html#objetivos-del-proyecto","title":"Objetivos del proyecto","text":"<p>Implementar una infraestructura propia en AWS que contemple:</p> <ul> <li>Una red estructurada en varias subredes.</li> <li>Servidores Ubuntu distribuidos entre subredes p\u00fablicas y privadas.</li> <li>Un servidor web accesible desde Internet.</li> <li>Un sistema de almacenamiento compartido entre varios servidores.</li> <li>Un volumen adicional en alguno de los servidores para almacenamiento o copias.</li> <li>Gesti\u00f3n controlada del acceso a Internet en las instancias privadas.</li> </ul>"},{"location":"pr01/pr01.html#requisitos-funcionales","title":"Requisitos funcionales","text":""},{"location":"pr01/pr01.html#servidores","title":"Servidores","text":"<ul> <li> <p>Despliega al menos tres instancias Ubuntu Server LTS, con roles diferenciados:</p> <ul> <li> <p>Servidor Web (p\u00fablico): alojar\u00e1 un sitio web accesible desde Internet mediante Apache u otro servidor similar.</p> <ul> <li>Este servidor debe ser accesible por HTTP/HTTPS y SSH.</li> <li>Su direcci\u00f3n IP p\u00fablica debe mantenerse fija a lo largo del tiempo (aunque la instancia se detenga y se inicie de nuevo). Elastic IP.</li> <li>Deber\u00e1 servir el contenido que encontrar\u00e1s en el repositorio de GitHub que contiene una web de muestra:     <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> </ul> </li> <li> <p>Servidor Interno de Aplicaciones (privado): destinado a tareas de soporte y procesamiento interno.</p> <ul> <li>No debe tener acceso directo desde Internet.</li> </ul> </li> <li> <p>Servidor de Copias o Contenidos (privado): centralizar\u00e1 archivos y respaldos utilizados por otros servidores.</p> <ul> <li>Accesible \u00fanicamente desde la VPC.</li> </ul> </li> </ul> </li> <li> <p>En el servidor de Copias, crea y configura un dispositivo o volumen adicional para almacenamiento espec\u00edfico (datos, copias o logs).</p> </li> <li>Elige para cada servidor la familia de instancia m\u00e1s adecuada seg\u00fan su funci\u00f3n y justifica tu elecci\u00f3n en la memoria t\u00e9cnica.</li> </ul>"},{"location":"pr01/pr01.html#diseno-de-red","title":"Dise\u00f1o de red","text":"<ul> <li>Dise\u00f1a la estructura de red completa a partir de la VPC 172.16.0.0/16.</li> <li>Define cu\u00e1ntas subredes necesitas, qu\u00e9 tama\u00f1o debe tener cada una y su funci\u00f3n dentro de la infraestructura (p\u00fablicas, privadas, etc.).</li> <li>Establece las rutas necesarias para que cada servidor tenga la conectividad requerida seg\u00fan su prop\u00f3sito.</li> </ul>"},{"location":"pr01/pr01.html#almacenamiento-compartido","title":"Almacenamiento compartido","text":"<ul> <li>Implementa un sistema de archivos compartido que permita que al menos dos servidores trabajen sobre el mismo conjunto de datos (por ejemplo, el contenido multimedia de la web).</li> </ul>"},{"location":"pr01/pr01.html#acceso-y-seguridad","title":"Acceso y seguridad","text":"<ul> <li>Define grupos de seguridad adaptados a los diferentes roles de los servidores, siguiendo el principio de m\u00ednimo privilegio.</li> <li> <p>Asegura que:</p> <ul> <li>El servidor web sea accesible \u00fanicamente por los puertos necesarios.</li> <li>Los servidores privados puedan comunicarse entre ellos y con el servidor web seg\u00fan sus necesidades.</li> <li>No exista acceso SSH directo desde Internet a los servidores privados.</li> </ul> </li> <li> <p>Durante el proceso de despliegue y configuraci\u00f3n, las instancias privadas deben poder acceder a Internet para instalar y actualizar paquetes.</p> <ul> <li>Con el fin de economizar costos,tras la puesta en marcha del entorno, el acceso a Internet desde las m\u00e1quinas internas deber\u00e1 quedar deshabilitado.</li> </ul> </li> </ul>"},{"location":"pr01/pr01.html#verificaciones","title":"Verificaciones","text":"<ul> <li>Desde tu equipo local, deber\u00e1s poder acceder al servidor web y visualizar correctamente el sitio servido por Apache.</li> <li>Los servidores deben ser accesibles por SSH seg\u00fan las reglas definidas.</li> <li>El sistema de archivos compartido debe estar operativo y accesible entre los servidores que lo utilicen.</li> </ul>"},{"location":"pr01/pr01.html#entregables","title":"Entregables","text":"<p>El proyecto debe incluir:</p> <ul> <li>Un diagrama de arquitectura donde se representen la VPC, las subredes, las rutas, las instancias desplegadas y los servicios que hayas necesitado.</li> <li> <p>Una memoria t\u00e9cnica que describa:</p> <ul> <li>La justificaci\u00f3n del dise\u00f1o de red y segmentaci\u00f3n elegidos.</li> <li>Los tipos de instancia seleccionados y su raz\u00f3n de elecci\u00f3n.</li> <li>La configuraci\u00f3n de seguridad y conectividad.</li> <li>La verificaci\u00f3n de la conexi\u00f3n a cada una de las instancias utilizando claves p\u00fablicas/privadas.</li> <li>El proceso de montaje del almacenamiento compartido y del volumen adicional.</li> <li>Las pruebas de verificaci\u00f3n realizadas.</li> </ul> </li> </ul> <p>Tip</p> <p>Para el diagrama de arquitectura utiliza https://app.diagrams.net/. Puedes utilizar como base el diagrama ejemplo.</p> <p>Importante</p> <p>El documento entregable deber\u00e1 seguir la estructura definida en el este documento.</p>"},{"location":"pr01/pr01.html#ayuda","title":"Ayuda","text":""},{"location":"pr01/pr01.html#asignacion-de-una-ip-fija-elastic-ip-a-una-instancia-ec2","title":"Asignaci\u00f3n de una IP fija (Elastic IP) a una instancia EC2","text":"<p>Para crear y asignar una IP El\u00e1stica a una m\u00e1quina EC2 puedes seguir este manual.</p>"},{"location":"pr01/pr01.html#instalacion-de-servidor-web","title":"Instalaci\u00f3n de servidor web","text":"<p>El servicio del servidor web se deber\u00e1 instalar en el momento de creaci\u00f3n de la instancia. </p> <p>Los comandos necesarios para instalar el servidor web:</p> <pre><code>sudo apt update\nsudo apt install apache2 -y\n</code></pre>"},{"location":"pr01/pr01.html#configuracion-del-servidor-web","title":"Configuraci\u00f3n del servidor web","text":"<p>Para que Apache sirva nuestra p\u00e1gina web, copia el contenido del repositorio clonado a <code>/var/www/html/</code></p>"},{"location":"pr01/pr01.html#reto-adicional-opcional","title":"Reto adicional (opcional)","text":"<ul> <li>Configura una tarea programada en el servidor de copias que sincronice peri\u00f3dicamente los datos del almacenamiento compartido con un directorio local.</li> </ul>"},{"location":"pr01/pr02.html","title":"VPC con Subredes y Base de Datos RDS","text":""},{"location":"pr01/pr02.html#objetivo-general","title":"Objetivo General","text":"<p>En esta pr\u00e1ctica combinada se integran dos ejercicios relacionados con AWS:</p> <ol> <li>Creaci\u00f3n de una VPC con subredes p\u00fablicas y privadas, incluyendo instancias EC2 y configuraci\u00f3n de conectividad.</li> <li>Despliegue de una Base de Datos RDS ubicada en subredes privadas, accesible \u00fanicamente desde una instancia EC2 en la subred p\u00fablica.</li> </ol> <p>El objetivo es tener una visi\u00f3n completa de un entorno t\u00edpico compuesto por un servidor p\u00fablico que accede a una base de datos privada dentro de una VPC segmentada.</p>"},{"location":"pr01/pr02.html#1-arquitectura-en-aws","title":"1. Arquitectura en AWS","text":"<p>La arquitectura resultante ser\u00e1:</p> <ul> <li>Una VPC con bloque CIDR <code>10.0.0.0/16</code>.</li> <li>Subredes:</li> <li>Dos p\u00fablicas: <code>10.0.1.0/24</code> y <code>10.0.2.0/24</code>.</li> <li>Dos privadas: <code>10.0.3.0/24</code> y <code>10.0.4.0/24</code>.</li> <li>Componentes principales:</li> <li>Internet Gateway para salida a Internet desde subredes p\u00fablicas.</li> <li>Instancia EC2 p\u00fablica accesible desde Internet (puertos 22 y 80).</li> <li>Instancia RDS MySQL en subredes privadas sin acceso p\u00fablico.</li> <li>Tablas de enrutamiento distintas para subredes p\u00fablicas y privadas.</li> </ul> <p></p>"},{"location":"pr01/pr02.html#2-creacion-de-la-vpc","title":"2. Creaci\u00f3n de la VPC","text":""},{"location":"pr01/pr02.html#parametros-configurados","title":"Par\u00e1metros configurados","text":"<ul> <li>CIDR: <code>10.0.0.0/16</code></li> <li>Dos AZs para permitir el funcionamiento de RDS.</li> <li>Subredes:</li> <li>P\u00fablicas: <code>10.0.1.0/24</code>, <code>10.0.2.0/24</code></li> <li>Privadas: <code>10.0.3.0/24</code>, <code>10.0.4.0/24</code></li> <li>Internet Gateway asociado a la VPC.</li> <li>No se requiere NAT Gateway, dado que RDS no necesita salida a Internet.</li> </ul>"},{"location":"pr01/pr02.html#3-tablas-de-enrutamiento","title":"3. Tablas de Enrutamiento","text":""},{"location":"pr01/pr02.html#subredes-publicas","title":"Subredes p\u00fablicas","text":"<ul> <li><code>10.0.0.0/16</code> \u2192 local</li> <li><code>0.0.0.0/0</code> \u2192 Internet Gateway</li> </ul> <p>Permiten que la instancia EC2 p\u00fablica reciba tr\u00e1fico desde Internet.</p>"},{"location":"pr01/pr02.html#subredes-privadas","title":"Subredes privadas","text":"<ul> <li><code>10.0.0.0/16</code> \u2192 local</li> <li>Sin rutas de salida a Internet.</li> </ul> <p>Las instancias privadas no son accesibles desde Internet, mejorando la seguridad.</p>"},{"location":"pr01/pr02.html#4-creacion-de-la-instancia-ec2-publica","title":"4. Creaci\u00f3n de la instancia EC2 p\u00fablica","text":"<ul> <li>AMI: Ubuntu Server 24.04 LTS</li> <li>Tipo: <code>t2.micro</code></li> <li>Subred: p\u00fablica (<code>subnet-public1</code>)</li> <li>Permitir IP p\u00fablica</li> <li>Grupo de seguridad:</li> <li>SSH (22) abierto desde Internet</li> <li>HTTP (80) para acceder al servidor web</li> <li>Datos de usuario para instalar MySQL Client:</li> </ul> <pre><code>#!/bin/bash\napt update\napt install -y mysql-client-core-8.0 apache2\n</code></pre> <p>Tras el lanzamiento, conectamos v\u00eda SSH para verificar funcionamiento.</p>"},{"location":"pr01/pr02.html#5-creacion-del-grupo-de-subredes-para-rds","title":"5. Creaci\u00f3n del Grupo de Subredes para RDS","text":"<p>Antes de crear la base de datos es necesario definir un Database Subnet Group:</p> <ul> <li>Subredes privadas: <code>10.0.3.0/24</code> y <code>10.0.4.0/24</code></li> <li>AZs distintas para cumplir requisitos de RDS.</li> </ul>"},{"location":"pr01/pr02.html#6-configuracion-de-la-base-de-datos-rds","title":"6. Configuraci\u00f3n de la Base de Datos RDS","text":"<p>Par\u00e1metros de creaci\u00f3n:</p> <ul> <li>Motor: MySQL</li> <li>Plantilla: Entorno de pruebas</li> <li>Nombre de la instancia: <code>bbddapellido</code></li> <li>Usuario administrador y contrase\u00f1a definidos por el alumno</li> <li>Sin acceso p\u00fablico</li> <li>Database Subnet Group: el creado previamente</li> <li>Grupo de seguridad:</li> <li>Permite acceso \u00fanicamente desde la instancia EC2</li> </ul>"},{"location":"pr01/pr02.html#7-conexion-desde-ec2-a-la-base-de-datos","title":"7. Conexi\u00f3n desde EC2 a la Base de Datos","text":"<p>En la instancia EC2 ejecutamos:</p> <pre><code>mysql -h`&lt;endpoint-rds&gt;` -u admin -p\n</code></pre> <p>El endpoint se obtiene desde el panel de RDS \u2192 pesta\u00f1a Conectividad y seguridad.</p>"},{"location":"pr01/pr02.html#8-pruebas-de-verificacion","title":"8. Pruebas de Verificaci\u00f3n","text":"<ul> <li>Acceso a la instancia EC2 v\u00eda SSH.</li> <li>Visualizaci\u00f3n del servidor Apache desde navegador.</li> <li>Conexi\u00f3n MySQL desde la EC2 a la RDS.</li> <li>Confirmaci\u00f3n de que RDS no es accesible desde Internet.</li> <li>Verificaci\u00f3n de rutas y reglas de seguridad.</li> </ul>"},{"location":"pr01/pr02.html#9-entregables","title":"9. Entregables","text":"<p>Captura las pantallas</p> <p>Captura la pantalla en la que se muestre el acceso desde el navegador a la p\u00e1gina por defecto servida por el servidor web de la m\u00e1quina EC2. Que se vea claramente la url con la IP p\u00fablica de la m\u00e1quina.</p> <p>Captura la pantalla accediendo por ssh a la m\u00e1quina ubuntu.</p> <p>Captura la pantalla resumen de la base de datos que muestra el punto de enlace de la conexi\u00f3n.</p> <p>Captura la pantalla de establecimiento de conexi\u00f3n a la base de datos desde la m\u00e1quina ubuntu.</p>"},{"location":"pr01/pr02.html#10-eliminacion-de-recursos","title":"10. Eliminaci\u00f3n de Recursos","text":"<ol> <li>Elimina instancia RDS.</li> <li>Elimina instancia EC2.</li> <li>Borra la VPC completa y sus componentes asociados (subredes, tablas de enrutamiento, IGW).</li> </ol>"},{"location":"pr02/pr02_asir.html","title":"Proyecto ASIR 2\u00aa Evaluaci\u00f3n:  Despliegue de una Web y Base de Datos Altamente Disponible","text":""},{"location":"pr02/pr02_asir.html#1-contexto-del-proyecto","title":"1. Contexto del proyecto","text":"<p>Nuestra empresa desea implantar una aplicaci\u00f3n web cuyo objetivo principal ser\u00e1 consultar informaci\u00f3n almacenada en una base de datos central. La web actuar\u00e1 \u00fanicamente como visor, mientras que la incorporaci\u00f3n de nuevos datos se realizar\u00e1 a trav\u00e9s de un servicio independiente, preparado para recibir informaci\u00f3n desde distintos sistemas y garantizar un funcionamiento seguro y ordenado. Este planteamiento permitir\u00e1 que la soluci\u00f3n crezca en el futuro sin complicar el uso de la aplicaci\u00f3n web.</p> <p>Debido al car\u00e1cter cr\u00edtico de los datos que se manejan, nuestra empresa desea que los datos est\u00e9n siempre accesibles desde la web, sin permitir ni un solo minuto de p\u00e9rdida de servicio, y con tiempos de respuesta aceptables independientemente de la carga de trabajo, que es imprevisible.</p>"},{"location":"pr02/pr02_asir.html#2-objetivo-general","title":"2. Objetivo general","text":"<p>Como administradores de sistemas queremos desplegar y gestionar una infraestructura en AWS que aloje una aplicaci\u00f3n web en PHP conectada a una base de datos para garantizar alta disponibilidad, escalabilidad autom\u00e1tica y seguridad en el acceso a los datos.</p>"},{"location":"pr02/pr02_asir.html#3-requisitos-funcionales","title":"3. Requisitos funcionales","text":"<p>Dise\u00f1ar e implementar una arquitectura en AWS que permita:</p> <ul> <li>Alojar una p\u00e1gina web en PHP capaz de leer datos desde una base de datos y mostrar elementos multimedia alojados en un bucket S3.</li> <li>Exponer una API REST que permita insertar datos en la base de datos.</li> <li>Garantizar alta disponibilidad tanto en la capa web como en la capa de datos.</li> <li>Garantizar autoescalado en la capa web para evitar p\u00e9rdidas de rendimiento en la experiencia de usuario.</li> <li>Aplicar medidas de seguridad adecuadas en todos los niveles de la infraestructura.</li> </ul>"},{"location":"pr02/pr02_asir.html#31-aplicacion-web","title":"3.1 Aplicaci\u00f3n web","text":"<ul> <li>La aplicaci\u00f3n web deber\u00e1 estar desarrollada en PHP.</li> <li>La web deber\u00e1 consultar y mostrar los datos almacenados en la base de datos.</li> <li>No se permitir\u00e1 la inserci\u00f3n directa de datos en la base de datos desde la web.</li> <li>Los contenidos est\u00e1ticos (las im\u00e1genes y elementos multimedia) de la p\u00e1gina web los debe recuperar de un bucket S3.</li> </ul>"},{"location":"pr02/pr02_asir.html#32-api-de-insercion-de-datos","title":"3.2 API de inserci\u00f3n de datos","text":"<ul> <li>Se deber\u00e1 desarrollar una API REST utilizando AWS Lambda.</li> <li>La API deber\u00e1 recibir datos mediante peticiones HTTP (por ejemplo, <code>POST</code>).</li> <li>La funci\u00f3n Lambda ser\u00e1 la encargada de insertar los datos en la base de datos.</li> <li>Los par\u00e1metros de conexi\u00f3n a la BBDD se almacenar\u00e1n en variables de entorno.</li> </ul>"},{"location":"pr02/pr02_asir.html#33-base-de-datos","title":"3.3 Base de datos","text":"<ul> <li>La base de datos deber\u00e1 ser una base de datos relacional y altamente disponible.</li> <li>Deber\u00e1 permitir la creaci\u00f3n de r\u00e9plicas de lectura para mejorar el rendimiento.</li> <li>Se utilizar\u00e1 al menos una tabla para almacenar la informaci\u00f3n recibida por la API.</li> </ul>"},{"location":"pr02/pr02_asir.html#4-requisitos-no-funcionales","title":"4. Requisitos no funcionales","text":""},{"location":"pr02/pr02_asir.html#41-alta-disponibilidad-y-escalabilidad","title":"4.1 Alta disponibilidad y escalabilidad","text":"<ul> <li>La infraestructura de la web deber\u00e1 ser altamente disponible, distribuy\u00e9ndose en al menos dos zonas de disponibilidad.</li> <li>La capa web deber\u00e1 ser autoescalable, adapt\u00e1ndose autom\u00e1ticamente a la carga.</li> <li>La base de datos deber\u00e1 tolerar fallos sin p\u00e9rdida de servicio.</li> <li>La base de datos podr\u00e1 ser escalable de manera manual.</li> </ul>"},{"location":"pr02/pr02_asir.html#42-seguridad","title":"4.2 Seguridad","text":"<ul> <li>No se permitir\u00e1 el acceso p\u00fablico directo a la base de datos.</li> <li>Se deber\u00e1n utilizar grupos de seguridad siguiendo el principio de m\u00ednimo privilegio.</li> <li>Las comunicaciones entre los distintos componentes deber\u00e1n realizarse de forma segura.</li> </ul>"},{"location":"pr02/pr02_asir.html#43-mantenimiento-y-buenas-practicas","title":"4.3 Mantenimiento y buenas pr\u00e1cticas","text":"<ul> <li>Se deber\u00e1n utilizar servicios gestionados siempre que sea posible.</li> <li>La arquitectura deber\u00e1 ser f\u00e1cilmente ampliable y mantenible.</li> <li>Se valorar\u00e1 el uso de mecanismos de monitorizaci\u00f3n y registro de logs.</li> </ul>"},{"location":"pr02/pr02_asir.html#5-alcance-del-proyecto","title":"5. Alcance del proyecto","text":"<p>El proyecto incluir\u00e1:</p> <ul> <li>Dise\u00f1o de la arquitectura AWS.</li> <li>Creaci\u00f3n de la infraestructura necesaria.</li> <li>Desarrollo b\u00e1sico de la aplicaci\u00f3n web en PHP.</li> <li>Desarrollo de la funci\u00f3n Lambda y la API asociada.</li> <li>Configuraci\u00f3n de la base de datos y sus r\u00e9plicas de lectura.</li> <li>Aplicaci\u00f3n de medidas de seguridad.</li> </ul>"},{"location":"pr02/pr02_asir.html#6-entregables","title":"6. Entregables","text":"<p>Para la evaluaci\u00f3n se deber\u00e1 entregar:</p> <ul> <li>Un documento descriptivo de la arquitectura, incluyendo un diagrama.</li> <li>Justificaci\u00f3n de los servicios AWS utilizados.</li> <li>C\u00f3digo fuente de la aplicaci\u00f3n web y de la funci\u00f3n Lambda.</li> <li>Explicaci\u00f3n de las medidas de seguridad implementadas.</li> <li>Breve gu\u00eda de despliegue y funcionamiento de la soluci\u00f3n.</li> </ul>"},{"location":"pr02/pr02_asir.html#7-criterios-de-evaluacion","title":"7. Criterios de evaluaci\u00f3n","text":"<p>Se valorar\u00e1 especialmente:</p> <ul> <li>Correcta implementaci\u00f3n de la alta disponibilidad y el autoescalado.</li> <li>Uso adecuado de servicios AWS.</li> <li>Seguridad de la arquitectura.</li> <li>Funcionamiento correcto de la web y la API.</li> <li>Uso de mecanismos de monitorizaci\u00f3n y registro de logs.</li> <li>Claridad y calidad de la documentaci\u00f3n entregada.</li> </ul>"},{"location":"ud01/practica00.html","title":"Lanzamiento el laboratorio de AWS Academy","text":""},{"location":"ud01/practica00.html#acceso-a-aws-academy","title":"Acceso a AWS Academy","text":"<p>1.- En primer lugar nos validamos con nuestro usuario y contrase\u00f1a en la p\u00e1gina de AWS Academy</p> <p>AWS Academy</p> <p></p>"},{"location":"ud01/practica00.html#acceso-al-learner-lab","title":"Acceso al Learner Lab","text":"<p>2.- En el panel de control de los cursos disponibles seleccionamos el Learner Lab correspondiente.</p> <p></p> <p></p> <p>3.- En el apartado Contenidos pulsamos sobre la opci\u00f3n Lanzamiento del laboratorio.</p> <p></p> <p></p>"},{"location":"ud01/practica00.html#lanzamiento-del-laboratorio","title":"Lanzamiento del laboratorio","text":"<p>4.- Se abre una nueva ventana con el entorno virtual de AWS en el que se nos muestra el cr\u00e9dito en d\u00f3lares que nos queda para realizar pruebas en un entorno real.</p> <p>Pulsamos sobre el bot\u00f3n Start Lab.</p> <p></p> <p></p> <p>5.- Esperamos a que el icono situado a la derecha del texto AWS pase a verde, y pulsamos sobre el texto AWS. </p> <p></p> <p></p> <p>6.- Accedemos a la consola de AWS en un entorno real en la nube (con servicios restringidos).</p> <p></p>"},{"location":"ud01/practica01.html","title":"La Interfaz de L\u00ednea de Comandos","text":""},{"location":"ud01/practica01.html#instalando-aws-cli","title":"Instalando AWS CLI","text":"<p>AWS CLI, es el cliente de AWS mediante el cual podremos utilizar la terminal para poder trabajar con nuestro entorno en lugar de utilizar la herramienta gr\u00e1fica.</p> <p>En este apartado indicar\u00e9 la p\u00e1gina de la documentaci\u00f3n desde donde podremos ir siguiendo las instrucciones de instalaci\u00f3n:</p> <p>https://docs.aws.amazon.com/es_es/cli/latest/userguide/getting-started-install.html </p> <p>Desde aqu\u00ed podremos seleccionar el sistema operativo en el que trabajamos y poder seguir las instrucciones de instalaci\u00f3n.</p> <p></p> <p>Una vez finalizada la instalaci\u00f3n podremos comprobar la versi\u00f3n instalada mediante el comando <code>aws --version</code>.</p> <p></p>"},{"location":"ud01/practica01.html#el-laboratorio","title":"El laboratorio","text":"<p>Teniendo un laboratorio en marcha y el cliente instalado, el siguiente paso es conectarlos. Para ello hay que seguir los siguientes pasos:</p> <p>Ver credenciales del laboratorio, dentro de AWS Details opci\u00f3n Show</p> <p></p> <p>Haremos click en show:</p> <p></p> <p>Ahora utilizaremos el siguiente comando para enlazar la terminal con el lab.</p> <p><code>aws configure</code></p> <p>E iremos copiando y pegando la informaci\u00f3n que nos vaya pidiendo:</p> <p></p> <p>Una vez configurado comprobaremos si podemos recuperar la informaci\u00f3n del usuario:</p> <p><code>aws sts get-caller-identity</code></p> <p>En el caso de los labs vemos que no logra conectarse y devuelve un error. Para paliar este error accederemos a la carpeta personal del usuario y dentro de \u00e9sta hay una carpeta oculta .aws (creada cuando hemos hecho aws configure), y dentro de esta carpeta tenemos el archivo credentials, el cual tiene la informaci\u00f3n que hemos introducido antes. Ahora bien, para arreglarlo vaciaremos el contenido del archivo y copiaremos toda la informaci\u00f3n de AWS Details dentro del archivo:</p> <p></p> <p>seleccionamos todo el texto que aparece dentro del recuadro y lo copiamos en el archivo credentials</p> <p>Y una vez hecho comprobaremos si nos devuelve las credenciales:</p> <p></p> <p>Al ser un entorno preparado de laboratorio las credenciales devueltas son de un perfil general (Estudiante  de  prueba) pero si fueran credenciales reales devolver\u00eda el nombre correspondiente. Destacar que Arn significa Amazon Resource Name que es el identificador que genera AWS para identificar recursos/servicios.</p>"},{"location":"ud01/ud01.html","title":"Tema 1. Introducci\u00f3n a la Nube P\u00fablica","text":""},{"location":"ud01/ud01.html#introduccion-a-cloud-computing","title":"Introducci\u00f3n a Cloud Computing","text":"<p>El Cloud Computing o computaci\u00f3n en la nube es un modelo de prestaci\u00f3n de servicios inform\u00e1ticos que permite acceder a recursos como servidores, almacenamiento, bases de datos, redes, software y m\u00e1s, a trav\u00e9s de Internet y bajo demanda. En lugar de instalar y mantener infraestructura f\u00edsica localmente, las empresas y usuarios acceden a estos servicios desde centros de datos remotos gestionados por proveedores como Amazon Web Services (AWS), Microsoft Azure o Google Cloud.</p> <p>La computaci\u00f3n en la nube se distingue por la noci\u00f3n de que los recursos son virtuales y sin l\u00edmites y que los detalles de los sistemas f\u00edsicos en los que se ejecuta el software se abstraen al usuario. Cuando un usuario ejecuta una aplicaci\u00f3n en la nube desconoce por completo el hardware que est\u00e1 utilizando, la plataforma sobre la que corre, etc. Cuando almacenamos datos en Dropbox, o leemos el correo en Gmail o editamos una hoja de c\u00e1lculo en OneDrive desde un ordenador o una tableta, desconocemos los sistemas f\u00edsicos sobre los que trabajamos, ni la plataforma, ni la ubicaci\u00f3n de los servidores, ni nada por el estilo. Lo vemos de manera abstracta. Una nube.</p> <p>Este modelo se basa en el pago por uso, lo que permite a los usuasurio o las organizaciones consumir solo los recursos que necesitan en cada momento.</p>"},{"location":"ud01/ud01.html#que-ventajas-nos-proporciona-el-cloud-computing","title":"\u00bfQu\u00e9 ventajas nos proporciona el Cloud Computing?","text":"<p>Migrar nuestra estructura f\u00edsica hacia un modelo de computaci\u00f3n en la nube nos puede proporcionar una serie de ventajas con respecto al modelo tradicional (llamado on-premise):</p> <ol> <li>Escalabilidad: La nube permite aumentar o disminuir los recursos (como potencia de c\u00e1lculo, almacenamiento o capacidad de red) de forma sencilla y r\u00e1pida seg\u00fan las necesidades del momento. Esto es ideal para empresas con cargas de trabajo variables o en crecimiento.</li> <li>Elasticidad: La elasticidad va un paso m\u00e1s all\u00e1: permite que los sistemas se ajusten autom\u00e1ticamente a los cambios de demanda, a\u00f1adiendo o quitando recursos sin intervenci\u00f3n humana. Por ejemplo, una web que recibe muchas visitas en horas punta puede ampliar sus servidores autom\u00e1ticamente y luego reducirlos cuando baja la carga.</li> <li>Ahorro de costos: Al eliminar la necesidad de comprar, instalar y mantener hardware local, el cloud computing reduce significativamente los costos iniciales. Adem\u00e1s, el modelo de pago por uso evita pagar por recursos infrautilizados.</li> <li>Disponibilidad global: Los servicios en la nube est\u00e1n disponibles desde cualquier lugar con conexi\u00f3n a Internet, lo que facilita el trabajo remoto, el acceso desde distintas ubicaciones y el despliegue internacional de aplicaciones.</li> <li>Seguridad: Aunque suele haber dudas al respecto, los proveedores de nube invierten grandes recursos en proteger sus infraestructuras. Ofrecen herramientas avanzadas de cifrado, control de accesos, copias de seguridad y cumplimiento de normativas internacionales, que suelen ser m\u00e1s seguras que muchas soluciones locales mal gestionadas.</li> </ol>"},{"location":"ud01/ud01.html#inconvenientes-del-cloud-computing","title":"Inconvenientes del Cloud Computing","text":"<ol> <li>Dependencia de la conexi\u00f3n a Internet: Si no se dispone de una conexi\u00f3n estable y r\u00e1pida, el acceso a los servicios puede verse comprometido. </li> <li>Latencia:: Dependiendo de la ubicaci\u00f3n del servidor y la calidad de la conexi\u00f3n, puede haber retrasos en la respuesta (latencia), lo cual afecta el rendimiento de algunas aplicaciones.</li> <li>P\u00e9rdida de control sobre la infraestructura: Al estar alojados en servidores externos, los usuarios no tienen acceso f\u00edsico ni completo control sobre los sistemas, lo que puede ser una desventaja en algunos contextos empresariales.</li> <li>Costes a largo plazo: Aunque el coste inicial es bajo, si no se gestionan bien los recursos (por ejemplo, si se dejan servicios sobreescalados o encendidos sin necesidad), el gasto mensual puede aumentar significativamente.</li> <li>Problemas de compatibilidad o migraci\u00f3n: Migrar sistemas existentes a la nube puede ser complejo y requerir tiempo, adaptaci\u00f3n o incluso redise\u00f1o de ciertas aplicaciones.</li> <li>Preocupaciones legales y de privacidad: Algunas organizaciones deben cumplir normativas estrictas sobre la ubicaci\u00f3n de los datos (Leyes estatales y Europeas). Usar servicios en la nube ubicados en otros pa\u00edses puede suponer problemas legales si no se gestionan adecuadamente.</li> </ol>"},{"location":"ud01/ud01.html#modelos-de-servicio","title":"Modelos de Servicio","text":"<p>Los modelos de servicio del cloud computing describen el tipo de servicio que el proveedor est\u00e1 ofreciendo. Se construyen uno sobre otro y definen lo que un proveedor debe manejar y lo que es responsabilidad del cliente.</p> <p>Los tres principales modelos de servicio com\u00fanmente aceptados son:</p> <ul> <li> <p>Infraestructura como Servicio: IaaS ofrece m\u00e1quinas virtuales, almacenamiento virtual, infraestructura virtual, y otros activos de hardware como recursos que los usuarios pueden contratar. El proveedor de servicios de IaaS gestiona toda la infraestructura, mientras que el usuario es responsable de todos los dem\u00e1s aspectos de la implementaci\u00f3n (como el sistema operativo, las aplicaciones, y las interacciones del usuario con el sistema).</p> <p>Ejemplo IaaS: Las m\u00e1quinas virtuales de AWS (Amazon EC2) y de Azure (Microsoft Azure VMs).</p> </li> <li> <p>Plataforma como servicio: PaaS proporciona un entorno para desarrollar, probar y desplegar aplicaciones sin gestionar directamente el hardware ni los servicios necesarios. Ofrece las m\u00e1quinas virtuales, los sistemas operativos, los servicios, los marcos de desarrollo, etc. El usuario no se ha de encargar de gestionar la infraestructura de la nube, los sistemas operativos ni el software del servicio gestionado.</p> <p>Ejemplo PaaS: AWS RDS (Bases de Datos gestionadas de AWS), Lambda (funciones serverless de AWS), Azure App Service (despliegue de aplicaciones Web de Azure).</p> </li> <li> <p>Software como Servicio: Con SaaS el usuario accede a una aplicaci\u00f3n completa a trav\u00e9s de Internet. No se preocupa por la infraestructura ni por el mantenimiento. La aplicaci\u00f3n se proporciona al cliente a trav\u00e9s de una interfaz de cliente ligero (un navegador, por lo general), y la responsabilidad del cliente comienza y termina con la entrada y la gesti\u00f3n de sus datos y la interacci\u00f3n con el usuario. Todo, desde la aplicaci\u00f3n hasta la infraestructura, pasando por el almacenamiento de los datos es responsabilidad del proveedor.</p> <p>Ejemplo SaaS: Mircosoft 365, Google Docs, Trello, Genially, Canva, Spotify.</p> </li> </ul> <p></p> <p>Los tres modelos de servicio diferentes en su conjunto han llegado a ser conocido como el modelo SPI (Software, Plataforma e Infraestructura) de cloud computing. Pero podemos encontrar muchos otros modelos de servicio menos conocidos. Algunos ejemplos:</p> <ul> <li> <p>FaaS (Function as a Service): Se ejecutan funciones (trozos de c\u00f3digo) en respuesta a eventos. Es la base del serverless computing.</p> <p>Ejemplo: AWS Lambda, Azure Functions.</p> </li> <li> <p>BaaS (Backend as a Service): Proporciona servicios de backend listos para usar: autenticaci\u00f3n, bases de datos, notificaciones push, etc.</p> <p>Ejemplo: Firebase, AWS Amplify.</p> </li> <li> <p>STaaS (Almacenamiento como servicio): Permite a los usuarios almacenar datos (a nivel de bloque y a nivel de archivo)en la nube sin preocuparse por la infraestructura f\u00edsica. Es escalable, accesible desde cualquier lugar y se paga por el espacio utilizado.</p> <p>Ejemplo: Amazon S3, Azure Blob Storage y en cierto modo tambi\u00e9n DropBox.</p> </li> </ul> <p>Sin embargo, los servicios de SPI abarcan todas las otras posibilidades.</p> <p> </p>"},{"location":"ud01/ud01.html#introduccion-a-amazon-web-services","title":"Introducci\u00f3n a Amazon Web Services","text":""},{"location":"ud01/ud01.html#principales-proveedores-de-cloud-computing","title":"Principales proveedores de Cloud Computing","text":"<p>Existen muchos proveedores de soluciones de cloud computing, pero los 3 m\u00e1s importantes son:</p> <ul> <li>Amazon Web Services (AWS)</li> <li>Microsoft Azure</li> <li>Google Cloud Platform</li> </ul> <p>Estos 3 proveedores en su cartera de productos de cloud computing ofrecen todo tipo de soluciones que abarcan todas las posibilidades del modelo SPI: Redes, M\u00e1quinas Virtuales, Contenedores, Sistemas Gestores de Bases de Datos, Almacenamiento, Serverless, Alojamiento de Aplicaciones, Gesti\u00f3n de APIs, Seguridad e Identidad; IoT, IA y aprendizaje autom\u00e1tico; y muchos m\u00e1s servicios.</p> <p>Existe una gran variedad de servicios ofrecidos por todos los proveedores de Cloud, los cuales suelen tener equivalencias entre ellos. Algunas de las equivalencias m\u00e1s importantes son las que se muestran en la siguiente imagen.</p> <p></p>"},{"location":"ud01/ud01.html#amazon-web-services","title":"Amazon Web Services","text":"<p>Amazon.com comenz\u00f3 siendo una tienda online de libros que, con el paso del tiempo, fue creciendo y acab\u00f3 generaliz\u00e1ndose en el gigante actual de ventas por Internet. Este tremendo crecimiento necesitaba de infraestructuras web masivas (sobre todo los Black Friday), innovadoras y caras para la \u00e9poca, que ten\u00edan contratadas en empresas externas.</p> <p>A medida que iban creciendo, optaron por desarrollar de forma interna toda la infraestructura web necesaria a su medida y ahorrar en costes a largo plazo, con la idea a\u00f1adida de vender sus servicios a terceros.</p> <p>La idea fue todo un \u00e9xito, actualmente Amazon Web Services es la divisi\u00f3n que m\u00e1s beneficios da en el grupo Amazon. En 2024 tuvo unos 39.000 millones de d\u00f3lares de beneficio.</p> <p>Es y ha sido la plataforma de Cloud Computing pionera  desde 2006. La m\u00e1s avanzada y evolucionada frente al resto de competencia que debe seguir sus pasos.</p> <p>\u00bfQui\u00e9n usa Amazon Web Services? \u00bfC\u00f3mo es que nunca lo he o\u00eddo? Son preguntas frecuentes para este gigante silencioso. Basta con dar algunos apuntes para tener idea de su dimensi\u00f3n e importancia:</p> <ul> <li>Clientes conocidos que usan o comenzaron usando sus servicios al completo: Instagram, Pinterest, Netflix, Spotify, AirBnB, Tinder, Twitch, Linkedin, BBC, Vimeo, y por supuesto Amazon.com</li> <li>Los clientes que usan sus servicios parcialmente, como S3 CloudFront son incontables como Vodafone o Facebook, siendo paradigm\u00e1tico el uso de Apple, que tiene alojado all\u00ed parte del contenido de iCloud a nivel mundial.</li> </ul>"},{"location":"ud01/ud01.html#infraestructura-aws","title":"Infraestructura AWS","text":"<p>Las diferentes plataformas cloud ofrecen una infraestructura dividida en Regiones y Zonas de disponibilidad.</p> <p>A lo largo de todo el globo terr\u00e1queo se han construido enormes centros de datos que se conocen como Regiones. Estas regiones son zonas geogr\u00e1ficas, y dentro de cada una de ellas hay diferentes grupo de centros de datos l\u00f3gicos que se conocen como Zonas de Disponibilidad (AZ - Availability Zone) situadas en ubicaciones aisladas. Normalmente cada regi\u00f3n contiene una media de 3 zonas de disponibilidad.</p> <p>Cada zona de disponibilidad est\u00e1 aislada, pero las zonas de disponibilidad de una regi\u00f3n est\u00e1n conectadas mediante redes troncales privadas que proporciona un menor coste y una latencia de red entre regiones mejor que las conexiones p\u00fablicas de Internet.</p> <p>Por tanto, cada regi\u00f3n consta de varias zonas de disponibilidad aisladas y separadas f\u00edsicamente dentro de un \u00e1rea geogr\u00e1fica. Cada zona de disponibilidad tiene alimentaci\u00f3n, refrigeraci\u00f3n y seguridad f\u00edsica independientes y est\u00e1 conectada a trav\u00e9s de redes redundantes de latencia ultrabaja. Esto permite que los clientes trabajen con bases de datos y aplicaciones con un nivel de disponibilidad, tolerancia a errores y escalabilidad mayor que el que ofrecer\u00eda un centro de datos \u00fanico.</p> <p>Nota</p> <p>Dentro de AWS Academy siempre vamos a trabajar dentro de la regi\u00f3n <code>us-east-1</code>, correspondiente al Norte de Virginia (es la regi\u00f3n asignada tambi\u00e9n a la capa gratuita, y adem\u00e1s, es la m\u00e1s econ\u00f3mica).</p> <p>Una zona de disponibilidad se representa mediante un c\u00f3digo de regi\u00f3n seguido de un identificador de letra, por ejemplo, <code>us-east-1a</code>.</p> <p>Dentro de la regi\u00f3n us-east-1 ubicada en el Norte de Virginia, se encuentran 6 zonas de disponibilidad: us-east-1a, us-east-1b, us-east-1c, us-east-1d, us-east-1e, us-east-1f. En cambio, en us-east-2 s\u00f3lo tiene tres AZ: us-east-2a, us-east-2b y us-east-2c.</p> <p>La soluci\u00f3n ideal para garantizar una tolerancia a fallos es replicar los datos y la aplicaci\u00f3n en varias zonas de disponibilidad de una regi\u00f3n, y posteriormente, replicarlos a su vez entre diferentes regiones. La replicaci\u00f3n de datos entre regiones y zonas de disponibilidad es responsabilidad del cliente, mediante el dise\u00f1o de una arquitectura con un cl\u00faster que reparta las peticiones a partir de un balanceador de carga entre, al menos, dos AZ distintas. As\u00ed, si cae una AZ, la otra dar\u00e1 respuesta a todas las peticiones.</p> <p></p> <p>Atenci\u00f3n</p> <p>No todos los servicios de AWS est\u00e1n disponibles en todas las regiones.</p> <p>Para hacernos una idea de la infraestructura global de AWS hay que saber que la nube de AWS est\u00e1 dividida en 37 Regiones (entre ellas Espa\u00f1a) repartidas por todo el mundo. Estas 37 regiones incorporan unas 3 Zonas de Disponibilidad (AZ) de media cada una, teniendo 117 AZ en total.</p> <p>Cada Zona de Disponibilidad tiene entre 1 y 6 datacenters (DC), usualmente 4. Esto implica, por tanto, que la infraestructura de AWS est\u00e1 repartida entre 160 y 450 DC en todo el mundo (el n\u00famero exacto no se sabe por razones de seguridad). Si cada DC de cada una de las AZ tiene entre 50.000 y 80.000 servidores en rack, podemos multiplicar y hacernos una idea del enorme tama\u00f1o que tiene la infraestructura global de AWS.</p> <p>AWS dispone desde 2022 de una Regi\u00f3n ubicada en Espa\u00f1a (concretamente en Huesca) denominada <code>eu-south-2</code> que incorpora 3 AZs. Amazon ya ha anunciado su plan de expansi\u00f3n en esta regi\u00f3n que incrementar\u00e1 con 5 campus m\u00e1s destinados a Datacenters e instalaciones auxiliares.</p>"},{"location":"ud01/ud01.html#principales-servicios-de-aws","title":"Principales Servicios de AWS","text":"<p>Los principales servicios de AWS, clasificados por categor\u00eda ser\u00edan los siguientes:</p> <ul> <li> <p>C\u00f3mputo</p> <ul> <li> <p>Amazon EC2 (Elastic Compute Cloud)</p> <p>Proporciona m\u00e1quinas virtuales configurables. Ideal para ejecutar servidores, aplicaciones o entornos de desarrollo.</p> </li> <li> <p>AWS Lambda</p> <p>Servicio serverless que ejecuta funciones en respuesta a eventos. No requiere administrar servidores.</p> </li> <li> <p>Amazon ECS / EKS</p> <p>Para desplegar contenedores: ECS usa infraestructura AWS propia, EKS gestiona cl\u00fasteres de Kubernetes.</p> </li> </ul> </li> <li> <p>Almacenamiento</p> <ul> <li> <p>Amazon S3 (Simple Storage Service)</p> <p>Almacenamiento de objetos (archivos). Escalable, duradero y muy utilizado para copias de seguridad, sitios web est\u00e1ticos o repositorios de datos.</p> </li> <li> <p>Amazon EBS (Elastic Block Store)</p> <p>Discos virtuales para instancias EC2. Pensado para almacenamiento persistente de bloques.</p> </li> <li> <p>Amazon Glacier</p> <p>Almacenamiento de archivos a largo plazo con acceso diferido, ideal para archivos que se consultan muy poco.</p> </li> </ul> </li> <li> <p>Bases de datos</p> <ul> <li> <p>Amazon RDS (Relational Database Service)</p> <p>Gestiona bases de datos relacionales (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server).</p> </li> <li> <p>Amazon DynamoDB</p> <p>Base de datos NoSQL totalmente gestionada. Ideal para aplicaciones de alto rendimiento y baja latencia.</p> </li> <li> <p>Amazon Aurora</p> <p>Motor de base de datos relacional compatible con MySQL/PostgreSQL, optimizado para la nube.</p> </li> </ul> </li> <li> <p>Redes y entrega de contenido</p> <ul> <li> <p>Amazon VPC (Virtual Private Cloud)</p> <p>Permite crear redes virtuales privadas dentro de AWS, con control sobre IPs, subredes, firewalls, etc.</p> </li> <li> <p>Elastic Load Balancing (ELB)</p> <p>Distribuye el tr\u00e1fico entre m\u00faltiples instancias EC2 para mejorar rendimiento y disponibilidad.</p> </li> <li> <p>Amazon CloudFront</p> <p>Red de entrega de contenido (CDN) para distribuir sitios web, v\u00eddeos u otros contenidos con baja latencia.</p> </li> </ul> </li> <li> <p>Desarrollo y herramientas de DevOps</p> <ul> <li> <p>AWS Elastic Beanstalk</p> <p>Despliegue autom\u00e1tico de aplicaciones web (Java, Python, PHP, Node.js, .NET, Ruby, Go, etc.) sin necesidad de configurar servidores, balanceadores de carga, ni escalado. (PaaS)</p> </li> <li> <p>AWS CodePipeline</p> <p>Automatiza el flujo de integraci\u00f3n y despliegue continuo (CI/CD).</p> </li> <li> <p>AWS CodeBuild / CodeDeploy</p> <p>Servicios para compilar y desplegar c\u00f3digo de forma autom\u00e1tica.</p> </li> <li> <p>AWS CloudFormation</p> <p>Permite definir la infraestructura (redes, m\u00e1quinas, servicios gestionados,...) como c\u00f3digo (IaC) usando plantillas en JSON o YAML.</p> </li> </ul> </li> <li> <p>Seguridad, identidad y cumplimiento</p> <ul> <li> <p>AWS IAM (Identity and Access Management)</p> <p>Control de acceso granular a recursos AWS: usuarios, roles, pol\u00edticas y permisos.</p> </li> <li> <p>AWS KMS (Key Management Service)</p> <p>Gesti\u00f3n de claves criptogr\u00e1ficas para cifrar datos de forma segura.</p> </li> </ul> </li> <li> <p>Monitorizaci\u00f3n y gesti\u00f3n</p> <ul> <li> <p>Amazon CloudWatch</p> <p>Monitorea m\u00e9tricas, logs y alarmas de recursos en tiempo real.</p> </li> <li> <p>AWS CloudTrail</p> <p>Registro de auditor\u00eda de todas las llamadas a la API de AWS. \u00datil para trazabilidad y seguridad.</p> </li> </ul> </li> <li> <p>Inteligencia Artificial y Machine Learning</p> <ul> <li> <p>Amazon SageMaker</p> <p>Plataforma para crear, entrenar y desplegar modelos de aprendizaje autom\u00e1tico a escala.</p> </li> <li> <p>Amazon Rekognition</p> <p>Analiza im\u00e1genes y v\u00eddeos para detectar objetos, rostros y texto.</p> </li> <li> <p>Amazon Polly</p> <p>Convierte texto en voz natural (TTS).</p> </li> </ul> </li> </ul>"},{"location":"ud01/ud01.html#migrando-hacia-el-marco-de-adopcion-de-la-nube-de-aws-caf-de-aws","title":"Migrando hacia el marco de adopci\u00f3n de la nube de AWS (CAF de AWS)","text":"<p>Para ayudar a las organizaciones a planificar y ejecutar con \u00e9xito la adopci\u00f3n de servicios en la nube existe un marco metodol\u00f3gico llamado Cloud Adoption Framework (CAF) de AWS. Migrar hacia este marco implica transformar procesos, cultura y tecnolog\u00eda para alinear los objetivos empresariales con las capacidades de la nube.</p> <p>Adoptar este marco no es simplemente un cambio t\u00e9cnico, sino una transformaci\u00f3n organizativa progresiva que incluye:</p> <ol> <li> <p>Evaluaci\u00f3n y diagn\u00f3stico</p> <p>Identificar el nivel de madurez digital actual.</p> <p>Analizar cargas de trabajo y procesos que pueden migrarse o redise\u00f1arse.</p> </li> <li> <p>Dise\u00f1o del plan de adopci\u00f3n</p> <p>Crear una hoja de ruta para la migraci\u00f3n, identificando prioridades y dependencias.</p> <p>Definir una arquitectura de destino basada en buenas pr\u00e1cticas de AWS.</p> </li> <li> <p>Preparaci\u00f3n del personal</p> <p>Capacitaci\u00f3n t\u00e9cnica en herramientas y servicios cloud.</p> <p>Formaci\u00f3n en nuevas metodolog\u00edas (DevOps, IaC, seguridad en la nube).</p> </li> <li> <p>Migraci\u00f3n y modernizaci\u00f3n</p> <p>Mover aplicaciones y datos de forma controlada (lift &amp; shift, refactorizaci\u00f3n, etc.).</p> <p>Aprovechar servicios nativos de AWS para optimizar coste, rendimiento y resiliencia.</p> </li> <li> <p>Gobierno y control continuo</p> <p>Establecer pol\u00edticas de uso, presupuestos, auditor\u00edas y automatizaci\u00f3n de la seguridad.</p> </li> </ol> <p>Ejemplo pr\u00e1ctico</p> <p>Una empresa que ofrece servicios web quiere modernizar su infraestructura. Aplicando el CAF:</p> <ul> <li>Eval\u00faa qu\u00e9 aplicaciones pueden migrarse.</li> <li>Forma a su equipo t\u00e9cnico en AWS.</li> <li>Define una arquitectura escalable basada en contenedores.</li> <li>Automatiza pol\u00edticas de seguridad y monitorizaci\u00f3n.</li> <li>Mejora el time-to-market de sus desarrollos y reduce el gasto en hardware.</li> </ul>"},{"location":"ud02/practica1.html","title":"Creaci\u00f3n de una M\u00e1quina Virtual (pr\u00e1ctica guiada)","text":""},{"location":"ud02/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear en la nube una m\u00e1quina virtual de Windows Server 2025 y nos conectaremos a ella por RDP. Conoceremos los recursos de AWS asociados a la creaci\u00f3n de esa m\u00e1quina virtual:</p> <ul> <li>La instancia EC2 (la propia m\u00e1quina virtual).</li> <li>El volumen EBS asociado (el disco duro de la m\u00e1quina virtual).</li> <li>La red (VPC) y la subred virtual a la que est\u00e1 conectada la m\u00e1quina.</li> <li>Un Internet Gateway (puerta de enlace) para salir a Internet desde la red virtual.</li> <li>Una direcci\u00f3n IP P\u00fablica para conectarnos desde el exterior.</li> <li>Un grupo de seguridad (firewall) para controlar los accesos.</li> </ul>"},{"location":"ud02/practica1.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud02/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud02/practica1.html#acceso-a-ec2","title":"Acceso a EC2","text":"<p>1.- Vamos a crear directamente una m\u00e1quina en la red virtual (VPC) creada por defecto. Para ello accedemos directamente al servicio de m\u00e1quinas virtuales de AWS llamado EC2 (Amazon Elastic Compute Cloud).</p> <ul> <li>Buscamos el servicio EC2 en la consola.</li> <li>Accedemos y pulsamos sobre Lanzar la Instancia.</li> </ul> <p>Nota</p> <p>Tenemos una red creada de manera predeterminada con una direcci\u00f3n de red 172.31.0.0/16, la cual tiene 6 subredes ubicadas en 6 zonas de disponibilidad distintas de la regi\u00f3n en la que se lanza el laboratorio (Norte de Virginia: us-east-1). Vamos a crear la m\u00e1quina en esta red por defecto.</p> <p></p>"},{"location":"ud02/practica1.html#lanzamiento-de-la-instancia","title":"Lanzamiento de la instancia","text":"<p>2.- Para lanzar la instancia EC2 es necesario asignarle una serie de par\u00e1metros obligatorios y configurar otros opcionales.</p> <ul> <li>El nombre del equipo ser\u00e1 W2025</li> <li>Seleccionamos una imagen (AMI) de Microsoft Windows Server 2025 Base.</li> <li>En el tama\u00f1o de la m\u00e1quina seleccionamos un tipo de instancia t3.medium (2 CPUS y 4 GiB de RAM)</li> <li>En el par de claves podemos elegir entre crear un nuevo par de claves o utilizar las ya creadas de nuestro laboratorio (vockey). Seleccionamos las ya creadas vockey.</li> <li>En la configuraci\u00f3n de red pulsamos en Editar:<ul> <li>Dejamos la VPC (la red virtual) predeterminada.</li> <li>Seleccionamos una subred (por ejemplo la asociada a la zona de disponibilidad 2 cuyo nombre es us-east-1b y su direcci\u00f3n de red es 172.31.16.0/20)</li> <li>Habilitamos la asignaci\u00f3n de una IP P\u00fablica para conectarnos desde Internet a esta m\u00e1quina.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-remoto y le ponemos una descripci\u00f3n (acceso remoto a W2025)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 3389 (RDP) desde cualquier lugar de Internet (0.0.0.0/0)</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 30GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p></p>"},{"location":"ud02/practica1.html#comprobacion-de-los-recursos-creados","title":"Comprobaci\u00f3n de los recursos creados","text":"<p>Tras unos minutos se nos crea la instancia, y con ella los siguientes recursos que podemos comprobar.</p> <p>3.- Accede al panel principal de EC2.</p> <p></p> <p>Comprueba pinchando sobre el enlace correspondiente que se ha creado:</p> <ul> <li>Una instancia (m\u00e1quina).</li> <li>Un volumen EBS (disco duro).</li> <li>2 Grupos de seguridad (el que ven\u00eda por defecto y el que hemos creado llamado acceso-remoto).</li> </ul> <p></p> <p>4.- Accede en la consola al panel de VPC.</p> <p></p> <p>Comprueba que nos aparece una VPC que ya ven\u00eda creada por defecto. Accede a ella y ver\u00e1s las subredes y recursos asociados:</p> <ul> <li>6 Subredes en 6 AZs</li> <li>1 Tabla de enrutamiento utilizada por todas las subredes.</li> <li>1 Conexi\u00f3n de red a Internet: Internet Gateway</li> </ul> <p></p> <p></p>"},{"location":"ud02/practica1.html#acceso-por-rdp","title":"Acceso por RDP","text":"<p>Vamos a iniciar una sesi\u00f3n de escritorio remoto en la m\u00e1quina creada. Al crear la m\u00e1quina no nos ha solicitado nombre de usuario y contrase\u00f1a. Por seguridad, nos crea una contrase\u00f1a compleja que solamente podemos ver utilizando el par de claves p\u00fablica y privada que hemos seleccionado al crear la m\u00e1quina.</p> <p>El primer paso para poder ver la contrase\u00f1a es descargarnos el fichero de la clave o copiar el contenido. </p> <p>5.- Accede a la consola de lanzamiento del laboratorio y en Detalles pulsa sobre una de las opciones de descarga o visualizaci\u00f3n de la clave privada. Descarga, por ejemplo, el fichero PEM.</p> <p></p> <p>6.- En la consola de AWS accede al panel de la instancia EC2 que acabamos de lanzar y pulsa sobre Conectar. En la pesta\u00f1a de Cliente RDP descarga el archivo RDP y pulsa sobre Obtener Contrase\u00f1a. Para descifrarla te pide la clave privada que acabas de descargar.</p> <p>7.- Una vez descifrada la contrase\u00f1a, ya podemos abrir el fichero RDP descargado e introducir el usuario (Administrator) y la contrase\u00f1a para iniciar sesi\u00f3n.</p> <p>Captura la pantalla</p> <p>Haz una captura de pantalla en la que se vea la conexi\u00f3n por RDP a la m\u00e1quina Windows Server 2025 como parte de las pr\u00e1cticas a entregar.</p>"},{"location":"ud02/practica1.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>8.- Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Terminamos la instancia. En el panel de EC2, con la instancia seleccionada, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> <li>Por \u00faltimo, eliminamos el grupo de seguridad acceso-remoto.</li> </ul> <p>Recuerda finalizar el laboratorio cuando acabes con las pr\u00e1cticas.</p>"},{"location":"ud02/practica2.html","title":"Pr\u00e1cticas entregables","text":""},{"location":"ud02/practica2.html#practica-1","title":"Pr\u00e1ctica 1","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-virtual-practica-guiada","title":"Creaci\u00f3n de una M\u00e1quina Virtual (pr\u00e1ctica guiada)","text":"<p>Reproduce la pr\u00e1ctica guiada y haz una captura de pantalla en la que se vea la conexi\u00f3n por RDP a la m\u00e1quina Windows Server 2025 creada.</p>"},{"location":"ud02/practica2.html#practica-2","title":"Pr\u00e1ctica 2","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux","title":"Creaci\u00f3n de una M\u00e1quina Linux","text":"<p>Necesitamos una m\u00e1quina que act\u00fae como servidor de Bases de Datos y para ello vamos a crear una instancia EC2.</p> <p>Queremos que el tama\u00f1o de la m\u00e1quina se adapte a esa funci\u00f3n de servidor de Base de Datos. Decide t\u00fa qu\u00e9 familia de instancias utilizar.</p> <p>Como sistema operativo utilizaremos Ubuntu, y deseamos que al crearse la m\u00e1quina se instale autom\u00e1ticamente el paquete del gestor de base de datos mysql.</p> <p>No vamos a utilizar el par de claves del laboratorio, sino crear un par de claves nuevo para conectarnos por ssh. El usuario de conexi\u00f3n ser\u00e1 el que nos cree por defecto.</p> <p>Tip</p> <p>Para instalar mysql hay que actualizar los repositios de Linux y a continuaci\u00f3n instalar el paquete con el comando <code>apt install mysql-server -y</code></p> <p>Tip</p> <p>Recuerda cambiar los permisos del fichero de la clave privada y a\u00f1adirlo con el par\u00e1metro <code>-i</code> dentro del comando <code>ssh</code></p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el tama\u00f1o de la instancia, los datos de usuario y el par de claves utilizado y la conexi\u00f3n por ssh a la m\u00e1quina Linux.</p>"},{"location":"ud02/practica2.html#practica-3","title":"Pr\u00e1ctica 3","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux-desde-la-cli","title":"Creaci\u00f3n de una M\u00e1quina Linux desde la CLI","text":"<p>Ahora que ya hemos practicado con el entorno gr\u00e1fico, vamos a comenzar a utilizar la terminal. Para ello, tal y como se explic\u00f3 en el Tema 1, debemos configurar las credenciales en el archivo <code>credentials</code> para poder estar conectados con el lab.</p> <p>En esta pr\u00e1ctica vamos a hacer un script (en Windows o Linux) para crear una m\u00e1quina virtual con los valores por defecto mediante el comando <code>aws ec2 run-instances</code> .</p> <p>Nota</p> <p>Necesitamos especificar algunos par\u00e1metros m\u00ednimos, entre ellos el identificador de la AMI a utilizar. Existen herramientas y comandos para conocer las IDs de las AMIs, pero nosoros accederemos a la consola gr\u00e1fica y, al intentar crear una instancia, veremos la ID de la AMI que nos interesa para poder introducirla en el comando.</p> <p>Recuerda que como usuario de aws academy debes utilizar la regi\u00f3n us-east-1 que te permite crear los recursos que se piden en este curso.</p> <p>Crearemos un fichero de script con el siguiente comando:</p> WindowsLinux <pre><code>aws ec2 run-instances `\n--image-id ami-0b09ffb6d8b58ca91 `\n--count 1 `     \n--instance-type m1.small `     \n--key-name vockey `     \n--region us-east-1\n</code></pre> <pre><code>aws ec2 run-instances \\\n--image-id ami-0b09ffb6d8b58ca91 \\\n--count 1 \\\n--instance-type m1.small \\\n--key-name vockey \\\n--region us-east-1    \n</code></pre> <p>Una vez guardado, damos permiso de ejecuci\u00f3n (en Linux) y lo ejecutamos anteponiendo <code>./</code> al nombre del script (en Windows y Linux).</p> <p>Al ejecutarlo, el comando nos devuelve una cadena json con informaci\u00f3n relativa a la instancia creada, pero no nos aparece ni la IP P\u00fablica ni el nombre DNS P\u00fablico asignados.</p> <p>Para poder ver dicha informaci\u00f3n y as\u00ed poder conectarnos mediante ssh, ejecutamos el comando <code>aws ec2 describe-instances</code> y filtramos la informaci\u00f3n de salida para que nos aparezca la palabra <code>PublicIpAddress</code>. En este caso no vamos a conectarnos por SSH pues en el script ser\u00eda necesario abrir el puerto 22 en el grupo de seguridad. Lo veremos en el siguiente tema.</p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el comando de creaci\u00f3n de la instancia.</p>"},{"location":"ud02/practica2.html#practica-4","title":"Pr\u00e1ctica 4","text":""},{"location":"ud02/practica2.html#creacion-de-una-maquina-linux-desde-la-cli_1","title":"Creaci\u00f3n de una M\u00e1quina Linux desde la CLI","text":"<p>Modifica el script de la pr\u00e1ctica anterior para lanzar una nueva instancia cuyo tam\u00f1o sea <code>t2.micro</code>, la AMI sea una basada en Debian y el par de claves sea el creado en la pr\u00e1ctica 2.</p> <p>Captura las pantallas</p> <p>Captura las pantallas necesarias en la que se vea el script y la ejecuci\u00f3n del mismo.</p>"},{"location":"ud02/practica2.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Termina todas la instancias. En el panel de EC2, con las instancias seleccionadas, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> </ul> <p>Recuerda finalizar el laboratorio cuando acabes con las pr\u00e1cticas.</p>"},{"location":"ud02/ud02.html","title":"Tema 2. Capa Inform\u00e1tica","text":""},{"location":"ud02/ud02.html#que-es-una-capa-informatica","title":"\u00bfQu\u00e9 es una Capa Inform\u00e1tica?","text":"<p>La capa inform\u00e1tica (o de c\u00f3mputo) de AWS es el nivel de la nube encargado de proporcionar recursos de procesamiento (CPU, memoria y red) que permiten ejecutar aplicaciones, sistemas operativos y servicios. Esta capa ofrece distintos modelos de uso, desde m\u00e1quinas virtuales hasta entornos sin servidor.</p> <p>Es decir, son los servicios que sustituyen o complementan a los servidores f\u00edsicos o m\u00e1quinas virtuales tradicionales en un centro de datos.</p>"},{"location":"ud02/ud02.html#que-otros-componentes-interactuan-con-la-capa-informatica","title":"\u00bfQu\u00e9 otros componentes interact\u00faan con la capa inform\u00e1tica?","text":"<ul> <li>Capa de almacenamiento (S3, EBS, EFS): Proporciona d\u00f3nde guardar los datos que las aplicaciones procesan.</li> <li>Capa de red (VPC, Route 53, ELB): Permite la comunicaci\u00f3n entre instancias, usuarios y servicios de AWS.</li> <li>Capa de bases de datos (RDS, DynamoDB, Aurora): Proporciona sistemas gestionados para almacenar, consultar y organizar datos.</li> <li>Capa de seguridad e identidad (IAM, Security Groups, NACLs): Garantiza que solo los usuarios o servicios autorizados accedan a los recursos de c\u00f3mputo.</li> <li>Capa de monitorizaci\u00f3n y gesti\u00f3n (CloudWatch, CloudTrail): Supervisa el estado y el rendimiento de los recursos inform\u00e1ticos.</li> </ul>"},{"location":"ud02/ud02.html#servicios-de-computo-en-aws","title":"Servicios de c\u00f3mputo en AWS.","text":"<p>Cuando hablamos de capa inform\u00e1tica en AWS pensamos r\u00e1pidamente en la posibilidad de crear m\u00e1quinas virtuales en la nube. Este popular servicio es el conocido como EC2, pero no es el \u00fanico servicio que ofrece AWS relacionado con la capa de c\u00f3mputo.</p> <p>AWS ofrece varias opciones de inform\u00e1tica para satisfacer diferentes necesidades. Las opciones clave de inform\u00e1tica de tiempo de ejecuci\u00f3n se pueden agrupar en cuatro categor\u00edas de modelos inform\u00e1ticos en la nube: </p> <ul> <li>M\u00e1quinas virtuales (VM)</li> <li>Contenedores</li> <li>Plataforma como servicio (PaaS)</li> <li>Sin servidor (Serverless)</li> </ul> <p></p> <p>En este tema nos vamos a centrar en el servicio EC2.</p>"},{"location":"ud02/ud02.html#amazon-ec2","title":"Amazon EC2","text":"<p>Amazon Elastic Compute Cloud (Amazon EC2) proporciona m\u00e1quinas virtuales en las que podemos alojar el mismo tipo de aplicaciones que podr\u00edamos ejecutar en un servidor en nuestras oficinas (servidores web, de aplicaciones, de correo, de bases de datos, multimedia, ...), ofreciendo capacidad de c\u00f3mputo segura y de tama\u00f1o ajustable en la nube.</p> <p>Amazon EC2 proporciona m\u00e1quinas virtuales y se puede considerar una forma de infraestructura como servicio (IaaS). Podemos elegir el sistema operativo, as\u00ed como el tama\u00f1o y las capacidades de los recursos de los servidores que lancemos, pero los servicios de IaaS nos obligan a estar a cargo de muchas de las responsabilidades de la administraci\u00f3n del servidor tales como actualizaciones del sistema operativo, copias de seguridad, instalaci\u00f3n y actualizaci\u00f3n de aplicaciones y servicios, etc.</p> <p>La computaci\u00f3n el\u00e1stica (Elastic Compute) se refiere a la capacidad para aumentar o reducir f\u00e1cilmente la cantidad de servidores que ejecutan una aplicaci\u00f3n de manera autom\u00e1tica, as\u00ed como para aumentar o reducir la capacidad de procesamiento (CPU), memoria RAM o almacenamiento de los servidores existentes.</p> <p>Cuando hablemos de una m\u00e1quina virtual lanzada en Amazon EC2 nos referiremos a ella como una instancia EC2.</p>"},{"location":"ud02/ud02.html#parametros-de-configuracion-de-una-instancia-ec2","title":"Par\u00e1metros de configuraci\u00f3n de una instancia EC2","text":"<p>Cuando creemos una instancia EC2 deberemos especificarle algunos par\u00e1metros necesarios para su configuraci\u00f3n y su seguridad. Algunos de ellos los vamos a ver en este tema y otros los iremos desarrollando en temas siguientes.</p> <p>Entre estos par\u00e1metros necesarios habr\u00e1 que indicarle a la consola que la instancia debe tener un tama\u00f1o de procesador y memoria, un sistema de almacenamiento o disco duro virtual, con un sistema operativo basado en una imagen de m\u00e1quina que se crear\u00e1 con unos datos de usuario; adem\u00e1s deber\u00e1 estar conectada en una red privada virtual de AWS y necesitaremos un par de claves p\u00fablica/privada para conectarnos a la m\u00e1quina.</p> <p></p>"},{"location":"ud02/ud02.html#amis","title":"AMIs","text":"<p>Una AMI (Amazon Machine Image) es una plantilla preconfigurada que contiene la informaci\u00f3n necesaria para crear una m\u00e1quina virtual (instancia) en Amazon EC2.</p> <p>Podr\u00eda decirse que es como una \u201cfoto\u201d de un servidor que sirve de modelo para lanzar nuevas instancias en AWS. A partir de esa imagen se pueden crear tantas m\u00e1quinas virtuales como se necesiten, todas con la misma configuraci\u00f3n inicial.</p> <p>Una AMI incluye:</p> <ul> <li>El sistema operativo (Linux, Windows, etc.).</li> <li>Opcionalmente, aplicaciones o configuraciones adicionales.</li> <li>Permisos de acceso (qui\u00e9n puede usarla).</li> <li>Informaci\u00f3n sobre el tipo de almacenamiento que utilizar\u00e1.</li> </ul> <p>Podemos encontrarnos varios tipos de AMI:</p> <ul> <li>De AWS: proporcionadas y mantenidas por Amazon (ej. Amazon Linux, Ubuntu, Windows Server).</li> <li>De la comunidad: compartidas por otros usuarios.</li> <li>Privadas/personalizadas: creadas por la propia organizaci\u00f3n o usuario con sus programas y configuraciones.</li> <li>Del Marketplace: publicadas por proveedores de software (ej. im\u00e1genes con Oracle, SAP, etc.).</li> </ul>"},{"location":"ud02/ud02.html#tipo-de-instancias","title":"Tipo de instancias","text":"<p>Un tipo de instancia EC2 define una configuraci\u00f3n de caracter\u00edsticas de rendimiento de CPU, memoria, almacenamiento y red que proporcionan un nivel determinado de rendimiento inform\u00e1tico. Ser\u00e1 lo equivalente a decir el tama\u00f1o de la instancia ajustando los tama\u00f1os de dichas caracter\u00edsticas de la m\u00e1quina virtual.</p> <p>La nomenclatura del tipo de instancia nos determina la familia, la generaci\u00f3n y el tama\u00f1o.</p> <p></p> <p>Para el tipo de instancia <code>m5d.xlarge</code> la letra m indica el nombre de la familia, al cual le sigue un n\u00famero, en este caso el 5. </p> <p>Este n\u00famero indica la generaci\u00f3n de ese tipo de familia. Por lo tanto, una instancia m5 es la quinta generaci\u00f3n de la familia m. En general, los tipos de instancias que son de una generaci\u00f3n m\u00e1s alta son m\u00e1s potentes y ofrecen un mejor relaci\u00f3n calidad-precio.</p> <p>La parte siguiente del nombre corresponde a la capacidad de la instancia. Cuando se comparan las capacidades, es importante tener en cuenta la parte del coeficiente de la categor\u00eda de capacidad. \u00a0 Por ejemplo, una instancia <code>m5.2xlarge</code> tiene el doble de vCPU y memoria que una instancia <code>m5.xlarge</code> que tiene, a su vez, el doble de vCPU y memoria que una instancia <code>m5.large</code>. \u00a0</p> <p>Nota</p> <p>Adem\u00e1s de tener en cuenta las necesidades de CPU, RAM y almacenamiento de las cargas de trabajo, tambi\u00e9n es importante tener en cuenta los requisitos del ancho de banda de la red, que tambi\u00e9n est\u00e1 vinculada al tama\u00f1o de la instancia de EC2. Si ejecutamos trabajos que hacen un uso intensivo de la red, es posible que debamos aumentar las especificaciones de las instancias para satisfacer nuestras necesidades.</p> <p>Cada tipo de instancia proporciona un nivel de rendimiento de red documentado. Por ejemplo, una instancia <code>a1.medium</code> brinda hasta 10\u00a0Gb/s, pero una instancia <code>p3dn.24xlarge</code> proporciona hasta 100\u00a0Gb/s.</p> <p>Las familias de las instancias se agrupan seg\u00fan su prop\u00f3sito y caracter\u00edsticas de hardware como se resume la siguiente tabla:</p> Familia Optimizado para Ejemplos t, m Uso general Web, apps ligeras, desarrollo, pruebas c CPU intensiva An\u00e1lisis, servicios web, juegos multijugador, codificaci\u00f3n de v\u00eddeos r, x RAM intensiva Bases de datos, cach\u00e9 en memoria, an\u00e1lisis de Big Data i, d Disco Duro r\u00e1pido Bases de datos NoSQL, Big Data, Almacenamiento de Datos p, g, f Computaci\u00f3n acelerada HPC, Machine Learning e IA, gr\u00e1ficos"},{"location":"ud02/ud02.html#par-de-claves","title":"Par de Claves","text":"<p>Amazon EC2 utiliza la criptograf\u00eda de clave p\u00fablica para cifrar y descifrar la informaci\u00f3n de inicio de sesi\u00f3n. La tecnolog\u00eda utiliza una clave p\u00fablica para cifrar un dato y luego el destinatario usa la clave privada para descifrar los datos. El conjunto de clave p\u00fablica y clave privada se denomina par de claves. </p> <p>Esta criptograf\u00eda de clave p\u00fablica nos permite acceder de forma segura a nuestras instancias mediante una clave privada en lugar de una contrase\u00f1a, de hecho EC2 deshabilita en las m\u00e1quinas Linux el acceso por contrase\u00f1a mediante SSH, oblig\u00e1ndonos a conectarnos mediante este par de claves.</p> <p>Cuando lanzamos una instancia es neccesario especificar un par de claves. Podemos especificar un par de claves existente o uno nuevo que se cree durante el lanzamiento. Si creamos un nuevo par de claves, debemos descargarlo y guardarlo en un lugar seguro. Esta oportunidad es la \u00fanica posibilidad de guardar el archivo de clave privada.\u00a0La clave p\u00fablica la almacena AWS dentro de la instancia, mientras que la clave privada la almacenamos nosotros.</p> <p>Atenci\u00f3n</p> <p>Si perdemos las claves, tendremos que destruir la instancia y volver a crearla.</p> <p>Para conectarnos a una instancia de Windows, utilizaremos la clave privada a fin de obtener la contrase\u00f1a de administrador y, a continuaci\u00f3n, iniciar sesi\u00f3n en el escritorio de Windows de la instancia de EC2 mediante el Protocolo de escritorio remoto (RDP). Para establecer una conexi\u00f3n SSH desde una m\u00e1quina Windows a una instancia de EC2, podemos utilizar una herramienta como PuTTY, que requerir\u00e1 la misma clave privada.</p> <p>Con las instancias de Linux, en el momento de arranque, se coloca el contenido de la clave p\u00fablica en la instancia. Se crea una entrada en <code>~/.ssh/authorized_keys</code>. Para iniciar sesi\u00f3n en nuestra instancia de Linux (por ejemplo, mediante SSH), debemos proporcionar la clave privada cuando establezcamos la conexi\u00f3n.\u00a0El siguiente ejemplo muestra c\u00f3mo hacer una conexi\u00f3n por ssh a la m\u00e1quina remota ubicada en 3.83.80.53 utilizando la clave privada descargada en el fichero <code>labuser.pem</code>:</p> <pre><code>ssh -i labsuser.pem ec2-user@3.83.80.52\n</code></pre> <p>Claves en AWS Academy</p> <p>Nuestro usuario del laboratorio tiene creado por defecto un par de claves que se conocen como <code>vockey</code>. Esta claves se pueden descargar desde la opci\u00f3n AWS Details del laboratorio de Learner Lab. Para poder conectarnos es necesario adem\u00e1s dar permisos para que s\u00f3lo nuestro usuario pueda utilizar la clave: <code>chmod 400 labuser.pem</code></p> <p>Usuarios Linux por defecto</p> <p>Al crear una instancia basada en una AMI de Linux se crean unos usuarios por defecto. En el caso de una AMI Ubuntu el usuario es <code>ubuntu</code> y para las AMIs de Amazon Linux el usuario es <code>ec2-user</code>.</p>"},{"location":"ud02/ud02.html#configuracion-de-la-red","title":"Configuraci\u00f3n de la red","text":"<p>Un paso necesario para la creaci\u00f3n de una instrancia EC2 es especificar la ubicaci\u00f3n de red en la que se implementar\u00e1, teniendo en cuenta la regi\u00f3n donde nos encontramos antes de lanzar la instancia. Hay que elegire la VPC (la red) y la subred dentro de la misma, ya sea de las que tenemos creadas o pudiendo crear los recursos en este paso.</p> <p>Adem\u00e1s, cuando se lanza una instancia en una VPC predeterminada, AWS le asigna una direcci\u00f3n IP p\u00fablica de forma predeterminada. En caso contrario, si la VPC no es la predeterminada, AWS no asignar\u00e1 una direcci\u00f3n IP p\u00fablica, a no ser que lo indiquemos de forma expl\u00edcita.</p> <p>A la creaci\u00f3n y configuraci\u00f3n de la red le dedicaremos un tema entero.</p>"},{"location":"ud02/ud02.html#almacenamiento","title":"Almacenamiento","text":"<p>Al lanzar la instancia EC2 configuraremos las opciones de almacenamiento. Se puede definir el tama\u00f1o del volumen ra\u00edz en el que est\u00e1 instalado el sistema operativo invitado, o incluso a\u00f1adir vol\u00famenes de almacenamiento adicionales.</p> <p>Algunas AMI est\u00e1n configuradas para lanzar m\u00e1s de un volumen de almacenamiento de forma predeterminada y, de esa manera, proporcionar almacenamiento independiente del volumen ra\u00edz. Para cada volumen que tenga la instancia, podemos indicar el tama\u00f1o de los discos, los tipos de volumen, si el almacenamiento se conservar\u00e1 en el caso de terminaci\u00f3n de la instancia y si se debe utilizar el cifrado.</p> <ul> <li>Configurar el volumen ra\u00edz.<ul> <li>D\u00f3nde est\u00e1 instalado el sistema operativo invitado.</li> </ul> </li> <li>Adjuntar vol\u00famenes de almacenamiento adicionales (opcional).<ul> <li>Es posible que la AMI ya incluya m\u00e1s de un volumen.</li> </ul> </li> <li>Para cada volumen, especificaremos lo siguiente:<ul> <li>Tama\u00f1o del disco (en GB).</li> <li>El tipo de volumen<ul> <li>Hay disponibles diferentes tipos de unidades de estado s\u00f3lido (SSD) y unidades de disco duro (HDD).</li> </ul> </li> <li>Si el volumen se eliminar\u00e1 al finalizar la instancia.</li> <li>Si se debe utilizar el cifrado.</li> </ul> </li> </ul> <p>Al almacenamiento tambi\u00e9n le dedicaremos un tema entero.</p>"},{"location":"ud02/ud02.html#datos-de-usuario","title":"Datos de usuario","text":"<p>Al crear las instancias de EC2, tenemos la opci\u00f3n de pasar datos de usuario a la instancia. Los datos de usuario pueden automatizar la finalizaci\u00f3n de las instalaciones y configuraciones en el lanzamiento de la instancia. Por ejemplo, un script de datos de usuario podr\u00eda aplicar parches y actualizar el sistema operativo de la instancia, buscar e instalar claves de licencia de software, o instalar software adicional. </p> <p></p> <p>En el script de datos de usuario de ejemplo, ver\u00e1 un script de shell Linux Bash de tres l\u00edneas sencillo. La primera l\u00ednea indica que el script debe ser ejecutado por el shell de Bash. La segunda l\u00ednea invoca la utilidad <code>apt update</code> para actualizar los repositorios de una distribuci\u00f3n Ubuntu, por ejemplo. La tercera l\u00ednea del script indica que se debe instalar la utilidad Wget para descargar archivos de la Web.</p> <p>En una instancia de Windows, el script de datos de usuario debe escribirse en un formato compatible con una ventana del s\u00edmbolo del sistema (comandos por lotes) o con Windows PowerShell.</p> <p>Nota</p> <p>El script s\u00f3lo se ejecuta la primera vez que se inicia la instancia.</p> <p>Cuando se lanza una instancia se crean una serie de metadatos a los que se puede acceder desde la misma instancia mediante la url <code>http://169.254.169.254/latest/meta-data/\u200b</code> y que a su vez podemos acceder desde el script de datos de usuario.</p> <p></p>"},{"location":"ud02/ud02.html#costos-de-las-instancias-ec2","title":"Costos de las instancias EC2","text":"<p>No todas las m\u00e1quinas EC2 cuestan lo mismo. Evidentemente las m\u00e1s grandes cuestan m\u00e1s, pero adem\u00e1s existen una serie de factores que influir\u00e1n en el costo de nuestra m\u00e1quina EC2:</p> <ul> <li>Tipo de instancia (m\u00e1s CPU/memoria \u21d2 m\u00e1s caro).</li> <li>Regi\u00f3n en la que se lanza (cada regi\u00f3n tiene precios distintos).</li> <li>Tiempo de uso (horas/minutos encendida).</li> <li>Almacenamiento asociado (EBS, snapshots).</li> <li>Tr\u00e1fico de red (salida de datos hacia Internet suele ser de pago).</li> </ul> <p>El costo habitual de las m\u00e1quinas EC2 viene determinado por el uso que hagamos de ellas. Mientras la m\u00e1quina est\u00e1 apagada no se nos factura el costo asociado a la computaci\u00f3n (pero ojo, s\u00ed otros costos como almacenamiento). Este pago por uso se conoce como pago bajo demanda. Normalmente cuando iniciemos una instancia usaremos este tipo de pago (el cr\u00e9dito concedido por AWS Academy es en esa modalidad), pero conviene conocer el resto de formas que ofrecen diferentes facturaciones:</p> <ul> <li>Pago por uso (On-Demand): se paga por hora o por segundo de uso, sin compromiso. Es la modalidad de pago por defecto.</li> <li>Instancias reservadas: precio m\u00e1s bajo a cambio de un compromiso de 1 o 3 a\u00f1os.</li> <li>Instancias spot: muy baratas, pero pueden ser interrumpidas por AWS si necesita los recursos.</li> <li>Savings Plans: descuentos a cambio de comprometerse a un nivel de gasto mensual.</li> </ul>"},{"location":"ud02/ud02.html#precauciones-a-tener-en-cuenta","title":"Precauciones a tener en cuenta","text":"<ul> <li>Apagar las instancias cuando no se usan: aunque est\u00e9n inactivas, si est\u00e1n \u201crunning\u201d generan costos.</li> <li>Revisar el almacenamiento EBS: incluso si se apaga la instancia, los discos EBS asociados siguen cobrando.</li> <li>Controlar el tama\u00f1o de las instancias: usar solo la potencia que realmente se necesita.</li> <li>Monitorizar el tr\u00e1fico de red: grandes transferencias de datos a Internet incrementan la factura.</li> <li>Usar la capa gratuita (Free Tier): ofrece 750 horas/mes de una instancia t2.micro o t3.micro durante 12 meses, pero solo en determinadas condiciones.</li> <li>Configurar alarmas en AWS Budgets o CloudWatch: para evitar gastos inesperados.</li> </ul> <p>Atenci\u00f3n</p> <p>EC2 es flexible pero puede ser caro si no se controla. Lo importante es elegir el modelo de facturaci\u00f3n adecuado y vigilar los recursos que siguen generando gasto aunque no se usen. El costo de EC2 depende del tipo de instancia, el tiempo de uso, el almacenamiento y la red. Para evitar sorpresas en la factura, hay que apagar instancias cuando no se usan, vigilar discos y transferencias, y aprovechar la capa gratuita.</p>"},{"location":"ud03/redpractica00.html","title":"Pr\u00e1ctica 0. Creaci\u00f3n de una VPC de forma autom\u00e1tica","text":"<p>Una VPC es una red virtual aislada desde un punto de vista l\u00f3gico, a la que asignamos un direccionamiento de red, y que podemos subdividir en subredes, como se hace en una infraestructura tradicional. La diferencia es que en este caso todo lo definimos por software, ya sea desde la consola de AWS, desde la terminal con comandos de CLI, o utlizando alg\u00fan lenguaje de programaci\u00f3n soportado por el SDK de AWS.</p> <p>AWS tiene regiones en diferentes paises, y cada regi\u00f3n tiene varias zonas de disponibilidad que est\u00e1n separadas f\u00edsicamente unas de otras (unos 100 km como mucho). Cada zona de disponibilidad a su vez tiene varios datacenters.</p> <p>Una VPC se define a nivel de regi\u00f3n, y puede abarcar una o m\u00e1s zonas de disponibilidad. As\u00ed, podemos crear subredes en varias de estas zonas y desplegar nuestros recursos de manera que sean altamente disponibles.</p> <p>En el esquema siguiente se muestra una VPC dentro de una regi\u00f3n con tres zonas de disponibilidad. En cada una de ellas hay definida una subred, en las que se pueden lanzar instancias EC2 de manera que podamos tener un servicio replicado (o diferentes servicios) en diferentes zonas geogr\u00e1ficas:</p> <p></p> <p>Existen diferentes formas para crear una VPC y sus elementos. Vamos a comenzar por la manera m\u00e1s sencilla, creando de manera autom\u00e1tica los elementos que componen una VPC.</p>"},{"location":"ud03/redpractica00.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a realizar la creaci\u00f3n simult\u00e1nea de los elementos de red desde la consola de AWS. Aprenderemos a:</p> <ul> <li>Crear una VPC y asignar un bloque de CIDR IPv4 a la red.</li> <li>Crear subredes dentro de esa VPC y asignarles un bloque de direcciones CIDR IPv4.</li> <li>Ubicar cada subred dentro de una zona de disponibilidad (AZ).</li> </ul> <p>Una vez que creemos la VPC, crearemos 2 instancias EC2 en dicha VPC y accediendo por SSH a ellas comprobaremos las direcciones IP privadas que se le han asignado dentro del bloque de direcciones de la subred.</p>"},{"location":"ud03/redpractica00.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":"<p>Vamos a crear una VPC que contendr\u00e1 una \u00fanica subred en una Zona de Disponibilidad. La subred ser\u00e1 p\u00fablica, lo que significa que sus elementos ser\u00e1n accesibles desde Internet con la correspondiente apertura de puertos (grupos de seguridad).</p> <ul> <li>La direcci\u00f3n de la Red ser\u00e1 <code>192.168.0.0/16</code></li> <li>La direcci\u00f3n de la subred p\u00fablica ser\u00e1 <code>192.168.5.0/24</code></li> </ul>"},{"location":"ud03/redpractica00.html#creacion-simultanea-de-los-elementos-de-red-desde-la-consola-de-aws","title":"Creaci\u00f3n simult\u00e1nea de los elementos de red desde la consola de AWS","text":"<p>Ahora que ya hemos comprobado que podemos utilizar instancias dentro del espacio de Amazon, el siguiente paso es crear un \u2019trozo\u2019 de nube y ser conscientes del direccionamiento que podemos emplear dentro del espacio que AWS nos da. Podemos acceder al servicio VPC busc\u00e1ndolo en la barra superior de la consola de AWS, una vez hemos arrancado el Learner Lab y accedido a la consola:</p> <p></p> <p></p> <p>Lo primero ser\u00e1 utilizar la creaci\u00f3n de subredes en el mismo momento que se crea una VPC (opci\u00f3n VPC y m\u00e1s). Seleccionaremos el servicio VPC, con  direccionamiento <code>192.168.0.0/16</code>, y dentro de la VPC crearemos una \u00fanica subred p\u00fablica con direccionamiento <code>192.168.5.0/24</code>:</p> <p> </p> <p>En este caso estamos utilizando una \u00fanica zona de disponibilidad con una subred p\u00fablica, concretamente la zona con nombre <code>us-east-1a</code> en la regi\u00f3n del Norte de Virginia (<code>us-east-1</code>):</p> <p>En este punto no vamos a seleccionar Gateways NAT ni puntos de enlace de la VPC, que son conceptos que veremos m\u00e1s adelante.</p> <p></p> <p>Una vez pulsemos sobre el bot\u00f3n de Crear VPC, podremos ir viendo los elementos que se van creando, en funci\u00f3n de las opciones que se elijan:</p> <p></p> <p>Una vez creada la VPC, es interesante seleccionar la pesta\u00f1a de Mapa de recursos que nos permite comprobar de una manera visual los elementos creados y c\u00f3mo se relacionan entre ellos:</p> <p></p> <p>En el men\u00fa lateral izquierdo del Panel de VPC, tenemos diferentes opciones para trabajar con los diferentes  elementos que pueden estar presentes en una VPC. Podemos mostrar informaci\u00f3n sobre los elementos creados:</p> <p>La VPC  :</p> <p></p> <p>La subred :</p> <p></p> <p>Es importante fijarnos en el identificador que se genera para cada recurso, porque muchas veces creamos elementos y les perdemos la trazabilidad. Adem\u00e1s, para utilizar la CLI (Command Line Interface), necesitaremos el identificador de cada servicio. </p>"},{"location":"ud03/redpractica00.html#creacion-de-una-instancia-ec2-en-la-subred-creada","title":"Creaci\u00f3n de una instancia EC2 en la subred creada","text":"<p>Crea una instancia EC2 de Ubuntu con un grupo de seguridad por defecto, de manera que se despliegue en la subred que acabamos de crear, y selecciona la opci\u00f3n de Asignar autom\u00e1ticamente la IP p\u00fablica. Para ello, en el momento de lanzar la instancia, edita la configuraci\u00f3n de red y seleccionar la VPC y la subred reci\u00e9n creadas:</p> <p></p> <p></p>"},{"location":"ud03/redpractica00.html#creacion-de-una-segunda-instancia-ec2-en-la-subred-creada","title":"Creaci\u00f3n de una segunda instancia EC2 en la subred creada","text":"<p>Crea una segunda m\u00e1quina EC2 Ubuntu, asign\u00e1ndole el grupo de seguridad que se ha creado al lanzar la EC2 anterior, despleg\u00e1ndola tambi\u00e9n en la misma subred.</p> <p>Con todo esto la arquitectura finalmente creada es la que se muestra a continuaci\u00f3n:</p> <p></p> <p>Accede por ssh a las instancias y comprueba sus direcciones ip privadas.</p> <p>Captura las pantallas</p> <p>Entrega captura de pantalla resultado de ejecutar el comando <code>ip a</code> una vez est\u00e1s conectado por ssh en cada una de las instancias.</p>"},{"location":"ud03/redpractica01.html","title":"Pr\u00e1ctica 1. Creaci\u00f3n de una VPC de forma manual","text":""},{"location":"ud03/redpractica01.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a realizar la creaci\u00f3n independiente de los elementos de red desde la consola de AWS, el resultado ser\u00e1 el mismo que en la pr\u00e1ctica anterior pero se trata de que entiendas qu\u00e9 papel juegan cada uno de los siguientes conceptos en la VPC:</p> <ul> <li>Red</li> <li>Subred</li> <li>Zona de disponibilidad</li> <li>Direcci\u00f3n IP P\u00fablica</li> <li>Nombre de host DNS</li> <li>Gateway de internet IGW</li> <li>Tabla de enrutamiento</li> </ul>"},{"location":"ud03/redpractica01.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":"<p>Vamos a crear una VPC y todos sus elementos necesarios paso a paso. La VPC tendr\u00e1 las siguientes direcciones:</p> <ul> <li>Red: 192.168.0.0/16</li> <li>Subred: 192.168.0.0/24</li> </ul> <p>Captura las pantallas</p> <p>Esta tarea la documentar\u00e1s paso a paso. Para comprobar que ha funcionado correctamente, al final entregar\u00e1s tambi\u00e9n una captura del resultado de acceder por ssh a las instancia y comprobar su direcci\u00f3n privada.</p>"},{"location":"ud03/redpractica01.html#creacion-independiente-de-los-elementos-de-red-desde-la-consola-de-aws","title":"Creaci\u00f3n independiente de los elementos de red desde la consola de AWS","text":"<p>En la pr\u00e1ctica anterior hemos creado una VPC completa (utilizando la ayuda para la configuraci\u00f3n que nos ofrece AWS) porque ya conoc\u00edamos de antemano todos los elementos que necesit\u00e1bamos. Pero puede darse el caso de que tengamos que crear los  elementos por separado. De eso trata esta alternativa, por tanto, seleccionaremos la opci\u00f3n Solo la VPC al crearla.</p>"},{"location":"ud03/redpractica01.html#creacion-de-la-vpc","title":"Creaci\u00f3n de la VPC","text":"<p>Lo primero es crear una VPC con su direccionamiento (por ejemplo, <code>192.168.0.0/16</code>) seleccionando la opci\u00f3n Solo la VPC:</p> <p></p> <p></p>"},{"location":"ud03/redpractica01.html#creacion-de-las-subredes","title":"Creaci\u00f3n de las subredes","text":"<p>A continuaci\u00f3n, una vez creada la VPC, desde la opci\u00f3n de Subredes, crearemos la subred asoci\u00e1ndola a la VPC que acabamos de crear y d\u00e1ndole un nombre y un rango de direcciones IPv4, que debe estar dentro del rango de la VPC. Por ejemplo, podemos asignar el rango 192.168.0.0/24:</p> <p></p> <p></p> <p>En este caso no hemos asignado una zona de disponibilidad en concreto, con lo que la subred se puede crear en cualquiera de las seis zonas de disponibilidad que hay en la regi\u00f3n del Norte de Virginia (us-east-1).</p> <p></p>"},{"location":"ud03/redpractica01.html#comprobacion-de-funcionamiento-con-una-ec2","title":"Comprobaci\u00f3n de funcionamiento con una EC2","text":"<p>Vamos a lanzar una instancia EC2 y comprobar si funciona la arquitectura que acabamos de hacer. Para ello, al crear la instancia, seleccionaremos la VPC y subred que hemos creado. </p> <p></p> <p></p> <p>Es importante habilitar la asignaci\u00f3n de una IP p\u00fablica.</p> <p>Nota</p> <p>AWS solo asigna autom\u00e1ticamente direcciones IP p\u00fablicas en la VPC por defecto, pero no en las creadas por nosotros.</p> <p></p> <p></p> <p>Una vez creado, nos daremos cuenta de que S\u00cd que se asigna una IP p\u00fablica pero NO un nombre de host DNS. El problema reside en que en la VPC no hemos habilitado esta resoluci\u00f3n.</p> <p></p>"},{"location":"ud03/redpractica01.html#nombre-de-host-dns","title":"Nombre de host DNS","text":"<p>Para habilitar el nombre de host DNS, accedemos al men\u00fa de VPC y seleccionaremos la VPC creada:</p> <p></p> <p></p> <p>Y editaremos la configuraci\u00f3n para habilitar la opci\u00f3n nombres de host DNS.</p> <p></p> <p></p> <p>Ahora cuando volvamos a comprobar las propiedades de la EC2 creada, podremos ver que ya le ha asignado un nombre de host DNS a trav\u00e9s del cual podremos acceder por ssh (tambi\u00e9n lo podr\u00edamos hacer utilizando la ip p\u00fablica).</p> <p>Cuando intentemos acceder por ssh, nos daremos cuenta de que NO es posible hacerlo, ya que a nuestra VPC le falta un elemento/servicio que permita a todo lo que haya dentro poder configurarse para poder conectarse con el exterior y viceversa. </p>"},{"location":"ud03/redpractica01.html#internet-gateway","title":"Internet Gateway","text":"<p>El elemento que nos falta es el gateway de Internet (Internet Gateway o puerta de enlace de Internet - IGW). Podemos  crear  este  elemento dede la opci\u00f3n Puerta  de  enlace  de  Internet que encontraremos en el men\u00fa lateral izquierdo del panel del servicio VPC:</p> <p></p> <p></p> <p></p> <p>Si visualizamos el listado de los IGWs que hay creados, veremos que el estado del nuevo IGW aparece como detached, as\u00ed que tendremos que asign\u00e1rselo a la VPC deseada. En las acciones del IGW, le daremos a conectar a VPC:</p> <p></p> <p></p> <p></p> <p>\u00a1Pero seguimos sin poder conectarnos!</p> <p>Falta configurar un elemento encargado de gestionar el tr\u00e1fico dentro de la VPC: la tabla de enrutamiento.  </p>"},{"location":"ud03/redpractica01.html#tablas-de-enrutamiento","title":"Tablas de enrutamiento","text":"<p>Al  crear  una  VPC,  se  crea  un  tabla  de  enrutamiento  por defecto, y tenemos que asociarle la subred creada para poder crear rutas para esa subred, desde la opci\u00f3n correspondiente del panel de VPC (puedes localizar la subred entre las distintas que puedan haber observando la VPC a la que pertenece):</p> <p></p> <p></p> <p>Asociaremos la subred expl\u00edcitamente, aunque si no lo hacemos, la subred se asocia con la tabla de enrutamiento por defecto de la VPC.</p> <p></p> <p>Podemos volver a comprobar si nos podemos conectar a la instancia EC2, y seguimos SIN CONEXI\u00d3N. </p> <p>Lo \u00fanico que nos falta es modificar las rutas de la tabla de enrutamiento asociada a la subred. Si nos fijamos en las rutas que hay (seleccionando la subred, pesta\u00f1a \u2018Tabla de enrutamiento\u2019), s\u00f3lo se est\u00e1 enrutando la red de la VPC en local, es  decir  las subredes que tenga a su alcance (192.168.0.0/16). </p> <p>Hay que a\u00f1adir una ruta e indicar  que  todo lo que vaya a <code>0.0.0.0</code> (todo el tr\u00e1fico) salga por el Internet Gateway que hemos creado y asociado a nuestra VPC. Para ello seleccionamos la tabla de enrutamiento, editamos las rutas, y seleccionamos la opci\u00f3n Agregar ruta:</p> <p></p> <p>Una vez a\u00f1adida, comprobamos que aparece la nueva ruta en la lista de rutas de la tabla de enrutamiento:</p> <p></p> <p>Una vez hecho esto, ahora s\u00ed que podremos conectarnos por ssh a cualquier instancia EC2 lanzada en la subred que hemos creado (siempre que la EC2 tenga asignada una direcci\u00f3n IP p\u00fablica, y de que el grupo de seguridad asociado, concepto del que hablaremos m\u00e1s adelante, permita tr\u00e1fico entrante al puerto de ssh).</p> <p>Captura la pantalla</p> <p>Accede por ssh a la instancia EC2 y comprueba con el comando <code>ip a</code> su direcci\u00f3n privada. Captura la pantalla.</p>"},{"location":"ud03/redpractica02.html","title":"Pr\u00e1ctica 2. Creaci\u00f3n de una VPC con 2 subredes","text":""},{"location":"ud03/redpractica02.html#objetivo-de-la-practica","title":"Objetivo de la Pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a implementar un esquema en el que tendremos una red virtual con dos subredes (subred-publica y subred-privada). </p> <p>En cada una de esas subreeds crearemos una m\u00e1quina virtual Ubuntu:</p> <ul> <li>La primera ser\u00e1 accesible desde el exterior de la red (desde Internet) y para ello crearemos un grupo de seguridad en el que habilitaremos el puerto 22 (ssh) y el 80 (http) para que puedan entrar desde cualquier direcci\u00f3n. Adem\u00e1s necesitaremos una IP P\u00fablica y un Internet Gateway que dar\u00e1 salida al exterior a todos los elementos de la subred.</li> <li>La segunda m\u00e1quina estar\u00e1 en la subred-privada y configuraremos su grupo de seguridad para que sea accesible \u00fanicamente desde la subred-p\u00fablica, sin acceso desde el exterior. Para que esta m\u00e1quina tenga acceso a Internet (por ejemplo para poder hacer actualizaciones) pero no sea accesible desde Internet, necesitaremos un NAT-Gateway que se ubicar\u00e1 en la subred-p\u00fablica</li> </ul>"},{"location":"ud03/redpractica02.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud03/redpractica02.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud03/redpractica02.html#creacion-de-la-nueva-vpc","title":"Creaci\u00f3n de la nueva VPC","text":"<p>1.- Procedemos a crear la nueva VPC:</p> <ul> <li>Le decimos que queremos crear la VPC y m\u00e1s.</li> <li>Asignamos un nombre a la VPC, por ejemplo practica02</li> <li>Como direcci\u00f3n de red (Bloque de CIDR IPv4) dejamos la 10.0.0.0/16</li> <li>Seleccionamos una \u00fanica zona de disponibilidad (AZ).</li> <li>Le decimos que nos cree una subred p\u00fablica y otra privada.</li> <li>Personalizamos los bloques de direcciones de modo que las subredes tengan las siguientes direcciones:<ul> <li>Subred p\u00fablica: 10.0.1.0/24</li> <li>Subred privada: 10.0.2.0/24</li> </ul> </li> <li>Como deseamos que la subred privada tenga salida a Internet, creamos un Gateway NAT en 1 AZ (ojo, esto nos incrementar\u00e1 el coste considerablemente).</li> <li>No vamos a conectar ning\u00fan bucket de S3, por tanto no seleccionamos ning\u00fan Gateway de S3 en el apartado de Puntos de enlace de la VPC.</li> </ul> <p></p> <p></p> <p></p>"},{"location":"ud03/redpractica02.html#comprobacion-de-los-recursos-creados","title":"Comprobaci\u00f3n de los recursos creados","text":"<p>2.- Comprobamos los recursos creados:</p> <ul> <li>La VPC (practica02-vpc).</li> <li>Las 2 subredes (practica02-subnet-public1 y practica02-subnet-private1).</li> <li>El Internet Gateway (practica02-igw).</li> <li>Las 2 tablas de enrutamiento (una por cada subred: practica02-rtb-public y practica02-rtb-private).</li> <li>Una tabla de enrutamiento por defecto.</li> <li>Un Grupo de Seguridad por defecto.</li> <li>El NAT Gateway (practica02-nat-public1) ubicado en la subred p\u00fablica para dar salida a Internet en la subred privada.</li> <li>Una IP El\u00e1stica asociada al NAT Gateway (practica02-eip).</li> </ul> <p></p>"},{"location":"ud03/redpractica02.html#tablas-de-enrutamiento","title":"Tablas de enrutamiento","text":"<p>Al crearse la VPC se han creado 3 tablas de enrutamiento: una por defecto y dos asociadas a las 2 subredes que hemos creado. Las 2 tablas asociadas a las nuevas subredes son las siguientes:</p> <p>Tabla de entutamiento de la subred privada</p> <p>Uso T\u00edpico</p> <p>Subred privada que aloja recursos como:</p> <ul> <li>Bases de datos, servidores de aplicaciones o backend.</li> <li>Instancias que requieren acceso saliente a Internet (actualizaciones, APIs externas), pero que no deben recibir tr\u00e1fico entrante directamente desde Internet.</li> </ul> Destino Objetivo 10.0.0.0 /16 local 0.0.0.0 /16 nat-gateway <p>Interpretaci\u00f3n:</p> <ul> <li>10.0.0.0/16 -&gt; local:         Permite que todos los recursos dentro de la VPC con direcci\u00f3n en el rango 10.0.0.0/16 se comuniquen entre s\u00ed sin salir de la red privada.</li> <li>0.0.0.0/0 -&gt; NAT-Gateway:         Redirige el tr\u00e1fico saliente destinado a Internet al NAT Gateway que se encuentra en la subred p\u00fablica.         El NAT Gateway permite que las instancias en la subred privada se comuniquen con Internet sin ser directamente accesibles desde \u00e9l.</li> </ul> <p></p> <p>Tabla de entutamiento de la subred p\u00fablica</p> <p>Uso T\u00edpico</p> <p>Subred p\u00fablica que aloja recursos como:</p> <ul> <li>Servidores web o aplicaciones que necesitan acceso desde Internet.</li> <li>Instancias EC2 con direcciones IP p\u00fablicas.</li> </ul> Destino Objetivo 10.0.0.0 /16 local 0.0.0.0 /16 Internet-gateway <p>Interpretaci\u00f3n:</p> <ul> <li>10.0.0.0/16 -&gt; local:         Igual que en la tabla privada, permite la comunicaci\u00f3n entre recursos dentro de la VPC sin salir de la red.</li> <li>0.0.0.0/0 -&gt; Internet-Gateway:         Define que todo el tr\u00e1fico destinado a Internet (es decir, fuera del rango 10.0.0.0/16) sea redirigido al Internet Gateway.         Este es el componente clave que convierte esta subred en una subred p\u00fablica.</li> </ul> <p></p>"},{"location":"ud03/redpractica02.html#creacion-de-una-instancia-ec2-en-la-subred-publica","title":"Creaci\u00f3n de una instancia EC2 en la subred p\u00fablica","text":"<p>Vamos a crear una m\u00e1quina Ubuntu en la subred p\u00fablica a la cual nos podremos conectar desde Internet.</p> <p>3.- Accedemos al panel de EC2 y lanzamos una instancia.</p> <ul> <li>La nombramos ub01</li> <li>La imagen ser\u00e1 una AMI de Ubuntu 24.04 LTS.</li> <li>En tipo de instancia seleccionamos una t2.micro (1 CPU y 1GB de RAM) incluida en la capa gratuita.</li> <li>Seleccionamos el par de claves vockey proporcionadas por el laboratorio.</li> <li>Editamos la configuraci\u00f3n de red.<ul> <li>Incluimos la m\u00e1quina en la subred p\u00fablica creada.</li> <li>Habilitamos la asignaci\u00f3n de una IP P\u00fablica.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-publico y le ponemos una descripci\u00f3n (acceso ssh a subred publica)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 22 (SSH) desde cualquier lugar de Internet (0.0.0.0/0)</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 8GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p>Nota</p> <p>Hay que tener en cuenta que la direcci\u00f3n IP asignada ser\u00e1 din\u00e1mica, por lo que si dese\u00e1ramos que nuestra m\u00e1quina fuera, por ejemplo, un servidor web, habr\u00eda que asociarle una IP el\u00e1stica, que equivale a asignarle una IP p\u00fablica est\u00e1tica.</p> <p></p>"},{"location":"ud03/redpractica02.html#conexion-mediante-ssh","title":"Conexi\u00f3n mediante SSH","text":"<p>Al crear la instancia no nos ha preguntado por ning\u00fan usuario ni contrase\u00f1a en el sistema operativo. AWS crea unos usuarios por defecto que var\u00edan dependiendo del tipo de AMI seleccionada. Se pueden consultar aqu\u00ed.</p> <p>Para conectarnos a la m\u00e1quina mediante ssh lo debemos hacer con un par de claves. En nuestro caso le hemos indicado que utilizar\u00edamos las del laboratorio (vockey), por tanto el primer es descargarnos el fichero de la clave.</p> <p>4.- Accedemos a la consola de lanzamiento del laboratorio y en Detalles pulsamos sobre la descarga del fichero PEM.</p> <p></p> <p>5.- Una vez descargado el fichero de clave debemos cambiar los permisos de dicho archivo:</p> <ul> <li>En Linux: <code>chmod 400 labuser.pem</code></li> <li>En Windows: Dejamos \u00fanicamente los permisos para nuestro usuario, eliminando los accesos del resto de usuarios.</li> </ul> <p>6.- Lanzamos el ssh indicando el fichero de la clave privada descargada y sustituyendo por la url correspondiente:</p> <pre><code>ssh -i \"labuser.pem\" ubuntu@ec2-204-236-197-47.compute-1.amazonaws.com\n</code></pre> <p></p>"},{"location":"ud03/redpractica02.html#instalacion-de-un-servidor-web","title":"Instalaci\u00f3n de un servidor web","text":"<p>Una vez dentro de la m\u00e1quina vamos a instalar un servidor web.</p> <p>7.- Ejecutamos:</p> <pre><code>sudo apt update\nsudo apt install apache2 -y\n</code></pre> <p></p>"},{"location":"ud03/redpractica02.html#acceso-a-la-pagina-web","title":"Acceso a la p\u00e1gina web","text":"<p>8.- Una vez instalado el servidor Apache, accedemos desde el navegador de nuestra m\u00e1quina local a la direcci\u00f3n IP P\u00fablica de  nuestra m\u00e1quina AWS.</p> <p>A pesar de tener instalado y corriendo el servidor web, el navegador no es capaz de resolver la direcci\u00f3n puesto que en el firewall de la instancia (grupo de seguridad acceso-publico) s\u00f3lo hemos permitido conexiones desde el puerto 22.</p> <p>Vamos a permitir conexiones tambi\u00e9n del puerto 80 (http) a\u00f1adiendo una nueva regla de entrada en el grupo de seguridad acceso-publico.</p> <p> 9.- En la consola de AWS, dentro del panel de VPC, accedemos al grupo de seguridad acceso-publico para editar sus propiedades:</p> <ul> <li>En las Reglas de entrada a\u00f1adimos una del tipo HTTP (Puerto TCP 80) para permitir accesos desde cualquier direcci\u00f3n (0.0.0.0/0).</li> </ul> <p> 10.- Guardamos las reglas y ya podemos acceder desde el navegador a la p\u00e1gina por defecto del servidor Apache instalado en nuestra m\u00e1quina.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre el acceso desde el navegador a la p\u00e1gina por defecto servida por el servidor Apache de la m\u00e1quina EC2. Que se vea claramente la url con la IP p\u00fablica de la m\u00e1quina.</p> <p></p>"},{"location":"ud03/redpractica02.html#creacion-de-una-instancia-ec2-en-la-subred-privada","title":"Creaci\u00f3n de una instancia EC2 en la subred privada","text":"<p>Vamos a crear una m\u00e1quina Ubuntu en la subred privada a la cual NO nos podremos conectar desde Internet.</p> <p>11.- Accedemos al panel de EC2 y lanzamos una instancia.</p> <ul> <li>La nombramos ub02</li> <li>La imagen ser\u00e1 una AMI de Ubuntu 24.04 LTS.</li> <li>En tipo de instancia seleccionamos una t2.micro (1 CPU y 1GB de RAM) incluida en la capa gratuita.</li> <li>Seleccionamos el par de claves vockey proporcionadas por el laboratorio.</li> <li>Editamos la configuraci\u00f3n de red.<ul> <li>Incluimos la m\u00e1quina en la subred privada creada.</li> <li>NO habilitamos la asignaci\u00f3n de una IP P\u00fablica.</li> <li>Creamos un grupo de seguridad (reglas de firewall) nuevo y lo llamamos acceso-privado y le ponemos una descripci\u00f3n (acceso ssh a subred privada)</li> <li>Como regla de entrada dejamos la que viene por defecto que habilita el puerto 22 (SSH) desde tipo de origen Personalizado, y como origen seleccionamos el grupo de seguridad acceso-publico</li> </ul> </li> <li>Dejamos las opciones de almacenamiento que nos propone por defecto: 8GiB en un disco SSD de uso general.</li> <li>Lanzamos la instancia.</li> </ul> <p>Nota</p> <p>En el grupo de seguridad asociado a esta instancia hemos dicho que s\u00f3lo se pueden admitir conexiones por ssh provenientes del grupo de seguridad acceso-publico, de modo que para poder conectarnos a la m\u00e1quina ub02 \u00fanicamente podremos hacerlo desde la m\u00e1quina ubu01.</p> <p></p>"},{"location":"ud03/redpractica02.html#conexion-mediante-ssh_1","title":"Conexi\u00f3n mediante SSH","text":"<p>La m\u00e1quina ubu02 no tiene direcci\u00f3n p\u00fablica, y adem\u00e1s, aunque la tuviera, el grupo de seguridad solamente admite conexiones desde la subred p\u00fablica, y no desde Internet. Por todo ello, si deseamos conectarnos a esta m\u00e1quina, el \u00fanico modo es hacerlo desde la m\u00e1quina ub01. Para ello necesitamos 2 requisitos:</p> <ul> <li>Averiguar la IP de la m\u00e1quina (Sabemos que al estar en la subred privada estar\u00e1 en el rango de direcciones 10.0.2.0/24)</li> <li>Pasar la clave privada (<code>labuser.pem</code>) que descargamos en nuestra m\u00e1quina local a la m\u00e1quina ub01, pues nos har\u00e1 falta para conectarnos a ub02.</li> </ul> <p>12.- Comenzamos accediendo desde el panel de EC2 a los detalles de la instancia ub02 y copiamos la direcci\u00f3n IP privada.</p> <p>13.- En segundo lugar, desde nuestra m\u00e1quina host (y con la conexi\u00f3n ssh cerrada) copiamos el archivo <code>labuser.pem</code> a la m\u00e1quina ubu01 mediante el comando <code>scp</code>:</p> <pre><code>scp -i labsuser.pem labsuser.pem ubuntu@ec2-18-212-203-120.compute-1.amazonaws.com:/home/ubuntu/clave_privada\n</code></pre> <p>14.- Iniciamos sesi\u00f3n en ub01:</p> <pre><code>ssh -i \"labuser.pem\" ubuntu@ec2-204-236-197-47.compute-1.amazonaws.com\n</code></pre> <p>15.- Comprobamos con un ls que se ha copiado el fichero y cambiamos los permisos:</p> <p><pre><code>ls -l\nchmod 400 clave_privada\n</code></pre> 16.- Nos conectamos con esa clave a la m\u00e1quina ub02 mediante la IP privada que anotamos:</p> <pre><code>ssh -i clave_privada ubuntu@10.0.2.112\n</code></pre> <p>17.- Comprobamos que tenemos conexi\u00f3n de salida a Internet gracias al NAT Gateway:</p> <pre><code>sudo apt update\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el comando <code>apt update</code> y que se vea la direcci\u00f3n IP interna (aparece en el prompt de comandos).</p> <p></p>"},{"location":"ud03/redpractica02.html#eliminacion-del-nat-gateaway","title":"Eliminaci\u00f3n del NAT Gateaway","text":"<p>18.- Accedemos a la consola de VPC y en Gateways NAT eliminamos el gateway (practica02-nat-public1) que creamos al crear la VPC.</p> <p>19.- Intenta en ubu02 acceder a Internet, por ejemplo actualizando los repositorios:</p> <pre><code>sudo apt update\n</code></pre> <p>Ya hemos perdido la conexi\u00f3n a Internet.</p> <p></p>"},{"location":"ud03/redpractica02.html#eliminacion-de-recursos","title":"Eliminaci\u00f3n de recursos","text":"<p>20.- Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Comenzamos liberando la IP el\u00e1stica que se asoci\u00f3 al NAT Gateway. Accedemos a la consola de EC2 y en IP El\u00e1sticas seleccionamos la opci\u00f3n Publicar direcci\u00f3n IP el\u00e1stica. (Publicar = hacer p\u00fablica = disponible).</li> <li>Terminamos las instancias. En el panel de EC2, con la instancia seleccionada, pulsamos sobre la Acci\u00f3n Terminar (eliminar) instancia. Nos informa que el volumen EBS asociado tambi\u00e9n se eliminar\u00e1.</li> <li>Por \u00faltimo, esperamos unos minutos a que se acaben de terminar la instancias y eliminamos los grupos de seguridad acceso-publico y acceso-privado, comenzando por este \u00faltimo.</li> </ul> <p>Recuerda finalizar el laboratorio.</p>"},{"location":"ud03/redpractica03.html","title":"Redpractica03","text":""},{"location":"ud03/redpractica03.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta tarea aprenderemos a crear subredes privadas y a configurar diferentes recursos de red de manera que se pueda acceder a Internet desde una instancia desplegada en una subred privada. Tambi\u00e9n trataremos diferentes aspectos de seguridad para controlar el tr\u00e1fico de red, tanto a nivel de instancias como a nivel  de  subred.  En  concreto, utilizaremos  los  siguientes  servicios  y  recursos  relacionados  con  la  parte  de  redes de AWS:</p> <ol> <li>VPC</li> <li>Subredes p\u00fablicas y privadas</li> <li>Tablas de enrutamiento y rutas</li> <li>Gateway de Internet</li> <li>Gateway NAT</li> <li>Grupos de seguridad</li> <li>ACL de red</li> </ol> <p>El escenario propuesto que vamos a desarrollar consistir\u00e1 en una VPC con una subred p\u00fablica y una subred privada, la cual s\u00f3lo tendr\u00e1 acceso al exterior pasando primero por la subred p\u00fablica, y se lanzar\u00e1 una instancia EC2 en cada subred. Para que la instancia desplegada en la subred privada tenga acceso a Internet, se utilizar\u00e1 un Gateway NAT, que  es  un  recurso  de  red  que  podemos  desplegar  en  una  subred  p\u00fablica  que  tenga conexi\u00f3n a un Gateway de Internet, de manera que permita la salida a Internet desde los recursos desplegados en subredes privadas, sin m\u00e1s que redirigir de manera apropiada el tr\u00e1fico de red mediante rutas.</p> <p>Los rangos utilizados para la VPC y subredes de la pr\u00e1ctica guiada que tienes a continuaci\u00f3n son:</p> <ul> <li>Direccionamiento VPC: 172.16.0.0/16</li> <li>Direccionamiento subred p\u00fablica: 172.16.0.0/20</li> <li>Direccionamiento subred privada: 172.16.64.0/20</li> </ul> <p></p> <p>Aunque es posible desplegar todos los recursos de red al crear la VPC, vamos a crear \u00fanicamente la VPC, la subred p\u00fablica, el Gateway de Internet y las tablas de rutas por defecto. Para ello se utilizar\u00e1 la consola gr\u00e1fica de AWS. Despu\u00e9s, a\u00f1adiremos uno a uno los recursos de la parte privada.</p> <p>El objetivo inicial entonces en cuanto a la parte de red, es tener una VPC, una subred p\u00fablica, un Gateway de Internet (IGW) y una tabla de enrutamiento, que vamos creando desde la opci\u00f3n de creaci\u00f3n de VPC como ya se vio</p>"},{"location":"ud03/redpractica03.html#que-tienes-que-hacer-en-esta-tarea","title":"Qu\u00e9 tienes que hacer en esta tarea","text":"<ul> <li>La tarea consiste en realizar un despliegue de una t\u00edpica arquitectura de dos capas, donde en la parte p\u00fablica tendremos un servidor web, y en la privada un servidor de base de datos:</li> <li>Crea  una  VPC  con  dos  subredes,  una  p\u00fablica  y  otra  privada, puedes poner el mismo direccionamiento de red que tienes en esta tarea guiada o puedes escoger otro. Para que desde la subred privada se pueda acceder al exterior deber\u00e1s utilizar un NAT Gateway.</li> <li>En la subred p\u00fablica, lanza una instancia EC2 e instala un servidor web Apache, que ser\u00e1 accesible desde cualquier equipo externo a la VPC por el puerto 80, utilizando tanto su nombre DNS como su direcci\u00f3n IP p\u00fablica.</li> <li>En la subred privada, lanza otra instancia EC2 e instala un servicio de MySQL. Para acceder a esta instancia, tendr\u00e1s que acceder primero a la instancia p\u00fablica (utiliza para ello el agente ssh).</li> <li>Los grupos de seguridad asociados a las instancias deben permitir s\u00f3lo el tr\u00e1fico de entrada  necesario, utilizando una regla encadenada en el caso del grupo de seguridad asociado a la instancia de base de datos,  de  manera  que  s\u00f3lo  acepte  tr\u00e1fico  entrante  del protocolo adecuado desde la instancia del servidor web.</li> <li>Con\u00e9ctate con ssh a la instancia de la subred p\u00fablica, y realiza una prueba de conexi\u00f3n al servidor de base de datos, utilizando para ello la aplicaci\u00f3n cliente mysql (que tendr\u00e1s que instalar previamente).</li> </ul> <p>Para entregar</p> <ul> <li>Adjunta   a  la  tarea   un   documento  pdf   con   las   siguientes  capturas:  mapa  de  la  VPC, configuraci\u00f3n  de  las reglas de entrada  de los grupos de seguridad de las dos instancias, conexi\u00f3n al servidor Apache desde un navegador, y conexi\u00f3n al servicio de base de datos desde la instancia del servidor web.</li> </ul> <p>Nota: No es necesario utilizar ACLs de red en esta tarea, el tr\u00e1fico de red se controlar\u00e1 \u00fanicamente con los grupos de seguridad asociados a las instancias, y por el hecho de que el servidor de base de datos residir\u00e1 en una subred privada.</p>"},{"location":"ud03/redpractica03.html#veamos-ahora-el-ejemplo-de-como-hacer-esto","title":"Veamos ahora el ejemplo de c\u00f3mo hacer esto","text":""},{"location":"ud03/redpractica03.html#vpc-con-su-direccionamiento","title":"VPC con su direccionamiento:","text":"<p>Y ahora el direccionamiento de la subred p\u00fablica (la subred privada la crearemos m\u00e1s adelante):</p> <p></p> <p></p> <p>Partiendo de aqu\u00ed, el siguiente objetivo es crear otra subred (que ser\u00e1 la subred privada), utilizando la opci\u00f3n Subredes del Panel de VPC:</p> <p></p> <p>Subred privada (hay que elegir la VPC que acabamos de crear):</p> <p></p> <p>Como se puede comprobar, realmente en ning\u00fan momento estamos indicando que la subred sea privada. Simplemente creamos subredes, y ser\u00e1n las tablas de enrutamiento las que decidan si la subred es p\u00fablica o privada, dependiendo de si \u00e9sta puede alcanzar o no un elemento de red que permita la comunicaci\u00f3n con el exterior.</p> <p>A continuaci\u00f3n, lanzaremos una instancia EC2 en la subred p\u00fablica y otra en la subred privada. Las instancias pueden ser por ejemplo Amazon Linux o Ubuntu, tama\u00f1o t3.micro, con creaci\u00f3n de grupo de seguridad por defecto y clave privada \u2018vockey\u2019. En las opciones para lanzar las instancias, hay que editar la configuraci\u00f3n de red y seleccionar la VPC y subred  en  la  queremos  lanzarla.  Tambi\u00e9n  seleccionaremos  la  opci\u00f3n  para  asignar autom\u00e1ticamente una IP p\u00fablica.</p> <p>En la imagen siguiente se muestra la configuraci\u00f3n para el caso de la instancia EC2 p\u00fablica, para la privada habr\u00eda que cambiar s\u00f3lo la subred:</p> <p></p> <p>Si  intentamos  conectarnos  por  ssh  a  la  instancia  desplegada  en  la  subred  privada utilizando su direcci\u00f3n ip p\u00fablica, comprobaremos que no es posible el acceso. La subred privada no est\u00e1 asociada de ninguna manera con la subred con el Internet Gateway para poder enrutar el tr\u00e1fico al exterior.</p> <p>Si comprobamos la tabla de enrutamiento asociada a la VPC (desde el panel de VPC, opci\u00f3n Tablas de enrutamiento), podremos ver en la pesta\u00f1a de asociaciones de subred, que \u00fanicamente tenemos la subred p\u00fablica asociada a la tabla de enrutamiento:</p> <p></p> <p>La subred privada aparece en la pesta\u00f1a \u201cSubredes sin asociaciones expl\u00edcitas\u201d, lo que quiere decir que est\u00e1 preparada para ser a\u00f1adida a la tabla de enrutamiento, pero a\u00fan no lo hemos hecho.</p> <p>B\u00e1sicamente lo que pretendemos es hacer que la subred privada salga al exterior a trav\u00e9s de la subred p\u00fablica. Para ello, cada subred tiene su propia tabla de enrutamiento, y en el caso de la subred p\u00fablica existe una ruta hacia el Gateway de Internet para poder salir al exterior:</p> <p></p> <p>En este punto podr\u00edamos conectarnos por ssh a la instancia de la red p\u00fablica y hacer ping a www.google.es y deber\u00eda funcionar:</p> <p></p> <p>Tambi\u00e9n podemos conectarnos por ssh desde la instancia en la subred p\u00fablica a la instancia de la subred privada y probar el mismo comando ping, que obviamente no funcionar\u00e1 todav\u00eda. En el siguiente punto veremos c\u00f3mo hacer esta conexi\u00f3n ssh a la instancia EC2 de la subred privada, \u2018saltando\u2019 desde la instancia p\u00fablica.</p>"},{"location":"ud03/redpractica03.html#conexion-ssh-a-las-instancias-publica-y-privada","title":"Conexi\u00f3n SSH a las instancias p\u00fablica y privada","text":"<p>A continuaci\u00f3n, veremos c\u00f3mo hacer la conexi\u00f3n ssh a las instancias EC2 utilizando la misma clave privada,  sin  necesidad  de  copiar  la  clave  privada  (labsuser.pem)  a  la instancia  p\u00fablica  (tambi\u00e9n  se  podr\u00eda  hacer usando diferentes credenciales de acceso, pero aprovecharemos que las dos instancias se han creado con la misma clave \u2018vockey\u2019). Para ello utilizaremos el reenv\u00edo de agente SSH, que permitir\u00e1 conectarnos desde un host basti\u00f3n en una subred p\u00fablica a la instancia privada.</p> <p>Seguiremos los pasos indicados  para  equipos  Linux.  En sistemas Windows,  se puede utilizar el programa PuTTY (puedes consultar este  art\u00edculo  donde se detalla c\u00f3mo realizar la conexi\u00f3n a una EC2 con Linux desde un host basti\u00f3n).  En primer lugar, comprobamos que las claves privadas tienen los permisos adecuados. Luego, desde el terminal ejecutaremos los siguientes comandos:</p> <p>Ejecutamos ssh-agent en segundo plano:</p> <p><code>eval $(ssh-agent)</code></p> <p>Cargamos en memoria la clave privada de la instancia:</p> <p><code>ssh-add labsuser.pem</code></p> <p>Podemos ver las claves a\u00f1adidas al agente ssh mediante el comando:</p> <p><code>ssh-add -l</code></p> <p>Nos conectamos en primer lugar a la instancia de la subred p\u00fablica. Con la opci\u00f3n -A, las claves se mantienen en memoria, y no es necesario utilizar la opci\u00f3n -i para indicar la clave (utiliza el nombre de usuario</p> <p>adecuado seg\u00fan la AMI de la instancia):</p> <p><code>ssh -A ec2-user@direcci\u00f3n-ip-p\u00fablica</code></p> <p>Una vez conectados a la instancia p\u00fablica, desde ella nos conectamos a la instancia de la subred privada utilizando su direcci\u00f3n IP privada:</p> <p><code>ssh ec2-user@direccion-ip-privada</code></p> <p>Una vez hemos logrado tener acceso a la instancia de la subred privada, si intentamos hacer  por  ejemplo un  ping  a www.google.es,  comprobaremos que  no  funciona. Hasta ahora lo que hemos logrado hacer es llegar hasta la instancia, pero, \u00bfy si la instancia necesita actualizarse o tener acceso a Internet por cualquier motivo? Para esta casu\u00edstica podemos  utilizar  el  servicio  NAT  Gateway ,  que  es  un  servicio  que  permite  que  las instancias de una subred privada puedan conectarse a servicios fuera de la VPC, pero los servicios externos no pueden iniciar una conexi\u00f3n con esas instancias.</p>"},{"location":"ud03/redpractica03.html#creacion-de-un-nat-gateway-y-modificacion-de-la-tabla-de-rutas-de-la-subred-privada","title":"Creaci\u00f3n de un NAT Gateway y modificaci\u00f3n de la tabla de rutas de la subred privada","text":"<p>Lo primero que haremos ser\u00e1 crear un NAT Gateway desde la opci\u00f3n correspondiente del panel de VPC:</p> <p></p> <p>Aqu\u00ed aparece por primera vez el concepto de ip el\u00e1stica. Una ip el\u00e1stica es una direcci\u00f3n ip p\u00fablica est\u00e1tica, que vamos a poder reutilizar en otros servicios.  Es decir, si hubiera un servicio que necesitase de una direcci\u00f3n ip p\u00fablica, o bien podemos utilizar las que AWS asigna por defecto de forma din\u00e1mica, o si ya necesitamos una direcci\u00f3n est\u00e1tica que no cambie (para un servidor web, por ejemplo) se podr\u00eda reutilizar la ip el\u00e1stica creada. Por supuesto,  reservar  direcciones  ip  de  esta  forma  conlleva  un  gasto  asociado, independientemente de que est\u00e9n o no asignadas a recursos. En las cuentas de AWS se pueden utilizar hasta 5 direcciones el\u00e1sticas por regi\u00f3n, aunque se puede solicitar el aumento de este l\u00edmite.</p> <p>El servicio NAT Gateway necesita tener asignado una direcci\u00f3n ip el\u00e1stica, por eso hay que pinchar en la opci\u00f3n de asignar ip el\u00e1stica. La creaci\u00f3n de este elemento de red lleva un rato, y habr\u00e1 que esperar a que est\u00e9 en estado \u201cavailable\u201d. En este caso el NAT Gateway lo vamos a crear en la subred p\u00fablica (ya veremos m\u00e1s adelante el motivo).</p> <p></p> <p>Cabe destacar que el servicio NAT Gateway, al tener una ip el\u00e1stica asociada, supondr\u00e1 un coste adicional incluso cuando apaguemos el laboratorio. Lo mismo pasa con otros servicios  de  AWS  (cuando  paramos el laboratorio, las instancias EC2 se detienen y dejamos de pagar por el uso de CPU, pero seguimos pagando por el almacenamiento asignado a su disco de sistema).</p> <p>A continuaci\u00f3n, vamos a configurar la subred privada para que tenga conexi\u00f3n al exterior. Para ello, primero  vamos  a  crear  una  tabla  de  enrutamiento que  podemos  llamar  \u2018rt- privada\u2019, y despu\u00e9s le asociaremos la subred:</p> <p></p> <p>Cuando se cree la tabla de enrutamiento, le asociaremos la subred privada desde la pesta\u00f1a \u201cAsociaciones de subredes\u201d, haciendo clic en \u201cEditar asociaciones de subredes\u201d:</p> <p></p> <p>Despu\u00e9s, accediendo desde la pesta\u00f1a \u2018Rutas\u2019 de la tabla de enrutamiento, a\u00f1adiremos una ruta para redirigir el tr\u00e1fico que vaya a Internet hacia el NAT Gateway que hemos creado, y \u00e9ste ya se encargar\u00e1 de dar salida hacia Internet:</p> <p></p> <p></p> <p>Ahora podremos hacer dos comprobaciones:</p> <ul> <li>Seguimos sin poder conectarnos por ssh directamente a la ip p\u00fablica de la instancia privada desde una m\u00e1quina local:</li> </ul> <p></p> <p></p> <ul> <li>Si hacemos ping desde la EC2 de la subred privada al exterior, S\u00cd que obtendremos respuesta:</li> </ul> <p></p>"},{"location":"ud03/redpractica03.html#nacl-network-access-control-list","title":"NACL (Network Access Control List)","text":"<p>Una NACL es un componente de seguridad que act\u00faa como un firewall, permitiendo o denegando el tr\u00e1fico entrante o saliente a nivel de subred dentro de una VPC. Hasta ahora hemos estado trabajando con los grupos de seguridad, que son b\u00e1sicamente son firewalls  con  estado  que  podemos  asignar  a  diferentes  recursos en AWS, como una instancia EC2. Con los grupos de seguridad, cuando se establece una conexi\u00f3n entrante, se puede devolver una respuesta sin que sea necesario habilitar una regla de salida que lo permita expl\u00edcitamente. Sin embargo, AWS ofrece otro nivel de seguridad, que son las NACL o ACL de red.</p> <p>A diferencia de las reglas asociadas a un grupo de seguridad, las reglas de NACL son sin estado. Por ejemplo, si queremos que una instancia responda a un ping, a\u00f1adimos en su grupo de seguridad asociado una regla que permita el tr\u00e1fico entrante ICMP. Cuando se realiza el ping, la entrada se permite e impl\u00edcitamente se permite la salida por cualquier puerto, ya que es una conexi\u00f3n establecida. Sin embargo, en el caso de las NACL, este permiso impl\u00edcito NO es dado, hay que configurar tanto las reglas de entrada como las de salida.</p>"},{"location":"ud03/redpractica03.html#escenario-de-prueba","title":"Escenario de prueba","text":"<p>Vamos a comprobar que los grupos de seguridad son capaces de guardar el estado y las ACLs de red no. Para ello, montaremos en una VPC una subred p\u00fablica y lanzaremos una instancia EC2 en dicha subred. Permitiremos la entrada del ping mediante una NACL definida en la subred pero NO la salida, para comprobar que el ping NO sale, y luego m\u00e1s tarde lo permitiremos.</p> <p>Antes de continuar, es recomendable eliminar todo lo que hemos hecho anteriormente para no confundirnos y tener los siguientes conceptos claros. Si no queremos eliminar los recursos individualmente, se puede realizar un reset del laboratorio para eliminar todos los recursos, pero dejar\u00e1 \u00e9ste inaccesible durante un rato.</p> <p>El escenario de prueba es b\u00e1sico, con una VPC con una sola subred p\u00fablica que enrutar\u00e1 el tr\u00e1fico externo mediante un Gateway de Internet:</p> <p></p>"},{"location":"ud03/redpractica03.html#creacion-de-la-vpc-e-instancia-ec2","title":"Creaci\u00f3n de la VPC e instancia EC2","text":"<p>Lo primero es crear la VPC junto con la subred. Nos podemos guiar con las siguientes capturas:</p> <p></p> <p>Una vez creada la infraestructura de red, pasaremos a lanzar la instancia dentro de la subred en la VPC reci\u00e9n creada:</p> <p></p> <p>Una vez la instancia est\u00e9 en ejecuci\u00f3n, podemos probar que podemos acceder por ssh, y a continuaci\u00f3n salir y probar a hacer un ping desde nuestra m\u00e1quina local a la instancia:</p> <p></p> <p>A continuaci\u00f3n, modificaremos el grupo de seguridad asociado a la instancia para permitir tr\u00e1fico ICMP entrante desde cualquier sitio, y comprobar que el ping funciona. Una vez hecha esta comprobaci\u00f3n, a\u00f1adiremos una capa adicional de seguridad a nivel de subred con reglas ACL.</p> <p>Hay  que  tener  en  cuenta  que  en  los  grupos  de  seguridad,  por  defecto  todo  el  tr\u00e1fico entrante se deniega, y se permite todo el de salida. Por lo tanto, daremos permiso al protocolo ICMP en una regla de entrada y salida del ping y luego denegaremos la salida del ping y ver como ya no responde.</p> <p>El  grupo de  seguridad  asociado  a  la  instancia  EC2  configurado para  permitir el  ping tendr\u00eda un aspecto como el siguiente:</p> <p></p> <p>Observamos en las reglas de salida que todo el tr\u00e1fico est\u00e1 permitido:</p> <p></p> <p>En este punto, podemos probar de nuevo el ping de la m\u00e1quina local a la EC2, y veremos que funciona.</p> <p>Para comprobar que los grupos de seguridad \u2018recuerdan\u2019 las peticiones entrantes, vamos a eliminar la regla que permite toda la salida de todo el tr\u00e1fico. Para ello, editamos las reglas de salida del grupo de seguridad:</p> <p></p> <p>Una vez eliminada la regla, comprobamos que no hay reglas de salida:</p> <p></p> <p>Si volvemos a probar el ping, comprobaremos que sigue funcionando incluso, despu\u00e9s de eliminar la regla de tr\u00e1fico de salida. Las ACL de red nos van a permitir tener un mayor control sobre el tr\u00e1fico entrante y saliente a una subred, a cambio de una mayor sobrecarga en las tareas de administraci\u00f3n.</p>"},{"location":"ud03/redpractica03.html#creacion-de-una-acl-de-red-nacl","title":"Creaci\u00f3n de una ACL de red (NACL)","text":"<p>En el momento de la creaci\u00f3n de la VPC, la subred, y la tabla de rutas correspondiente, tambi\u00e9n se ha creado una ACL de red predeterminada asociada a nuestra subred, aunque es posible crear m\u00e1s ACLs desde el panel de VPC, opci\u00f3n ACL de red. Podemos observar la ACL de red por defecto asociada a nuestra subred:</p> <p></p> <p></p> <p>Cada subred de una VPC debe estar asociada a una ACL de red. Si no asociamos una subred de forma expl\u00edcita a una ACL de red, la subred se asociar\u00e1 de manera autom\u00e1tica a la ACL de red predeterminada, que por defecto permite todo el tr\u00e1fico  de  entrada y salida de la subred. Se puede crear una ACL de red personalizada y asociarla a una subred para permitir o denegar el tr\u00e1fico entrante o saliente espec\u00edfico a nivel de subred. Adem\u00e1s, es posible asociar una ACL de red con varias subredes, pero una subred s\u00f3lo puede asociarse a una ACL de red a la vez. Al asociar una ACL de red a una subred, se quita la asociaci\u00f3n anterior.</p> <p>A continuaci\u00f3n crearemos el NACL en la VPC con la que estamos trabajando y le asociaremos la subred, lo que eliminar\u00e1 la asociaci\u00f3n con la NACL predeterminada:</p> <p></p> <p>Y comprobamos que tiene asociada la subred p\u00fablica desde la pesta\u00f1a \u201cAsociaciones de subredes\u201d:</p> <p></p> <p>Si observamos las reglas de entrada y salida de la NACL reci\u00e9n creada, comprobaremos que por defecto se deniega todo el tr\u00e1fico de entrada y salida a la subred:</p> <p></p> <p>Podemos a\u00f1adir y eliminar reglas de entrada y salida. Las reglas se eval\u00faan comenzando por la regla de n\u00famero m\u00e1s bajo. En cuanto una regla coincide con el tr\u00e1fico, esta se aplica  independientemente  de  cualquier  regla  con  un  n\u00famero  mayor  que  pueda contradecirla.</p> <p>Desde el men\u00fa ACL de red, vamos a modificar las reglas de entrada y salida y realizar las siguientes pruebas:</p> <ul> <li>A\u00f1adir regla de entrada ICMP. Desde la regla NACL, en la pesta\u00f1a Reglas de Entrada, Editamos las reglas de entrada:</li> </ul> <p></p> <p>A\u00f1adimos una nueva regla de entrada, con n\u00famero 100 (se recomiendan incrementos de 10 o 100), permitiendo el tr\u00e1fico ICMP desde cualquier origen:</p> <p></p> <p>Y ahora ya nos aparece la nueva regla:</p> <p></p> <p>Como  hemos  comentado  anteriormente,  las  reglas  se  eval\u00faan  con  una  prioridad ascendente, y en cuanto se satisface, ya no se comprueban las de menor prioridad.</p> <p>Comprobamos que el ping NO funciona:</p> <p></p> <ul> <li>Ahora a\u00f1adiremos la regla de salida ICMP en la correspondiente regla de salida NACL, para despu\u00e9s comprobar que el ping SI funciona:</li> </ul> <p></p> <p></p>"},{"location":"ud03/redpractica03.html#reglas-encadenadas-en-grupos-de-seguridad","title":"Reglas encadenadas en grupos de seguridad","text":"<p>Las reglas que regulan el tr\u00e1fico de red en los grupos de seguridad se pueden encadenar, de manera que podemos restringir el tr\u00e1fico permiti\u00e9ndolo \u00fanicamente cuando proviene de un grupo de seguridad determinado.</p> <p>Para probar este concepto, lo que vamos a hacer es crear un nuevo grupo de seguridad (con el nombre \u2018gs-encadenado\u2019, por ejemplo) y a\u00f1adir una nueva regla de entrada que permitir\u00e1 el tr\u00e1fico ICMP, asign\u00e1ndole como origen el grupo de seguridad que tiene asociado la instancia que tenemos lanzada:</p> <p></p> <p>A continuaci\u00f3n, lanzamos una nueva instancia EC2 en la misma subred que la primera, y le  asignamos el nuevo grupo de seguridad \u2018encadenado\u2019, en lugar de crear un nuevo grupo de seguridad:</p> <p>Y cuando queramos por ejemplo hacer un ping desde la m\u00e1quina local, veremos que no lo permite:</p> <p></p> <p>Sin embargo, si nos conectamos a la primera instancia por ssh y hacemos un ping a la direcci\u00f3n IP privada de la segunda instancia, comprobaremos que s\u00ed hay respuesta al ping:</p> <p></p> <p>En definitiva, combinando reglas encadenadas de grupos de seguridad y NACLs, es posible controlar de manera exhaustiva todo el tr\u00e1fico que entra y sale en nuestra VPC y los recursos desplegados en ella.</p>"},{"location":"ud03/redpractica04.html","title":"Pr\u00e1ctica 3. Creaci\u00f3n de VPC con CLI","text":""},{"location":"ud03/redpractica04.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear la misma VPC que en ejercicios anteriores pero utilizando CLI. Se adjunta un script de ejemplo en el cual se realizan las acciones:</p> <ul> <li>Creaci\u00f3n de una VPC.</li> <li>Habilitar DNS en la VPC.</li> <li>Creaci\u00f3n de una subred.</li> <li>Creaci\u00f3n de un grupo de seguridad y apertura de un puerto.</li> <li>Creaci\u00f3n de una instancia EC2.</li> <li>Creaci\u00f3n Internet Gateway y guardado de ID.</li> <li>Se adjunta el IGW a la VPC.</li> <li>Se crear tablas de rutas y se guardan sus ID.</li> <li>Se agregan una ruta para salida a internet.</li> <li>Se asocia la tabla de rutas a la subred.</li> </ul>"},{"location":"ud03/redpractica04.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":"<p>Tienes que descargar el siguiente script:</p> LinuxWindows <p>script Creaci\u00f3n VPC para Linux</p> <p>script Creaci\u00f3n VPC para Windows</p>"},{"location":"ud03/redpractica04.html#parte-1-modificacion-del-script-de-creacion-de-la-vpc-y-la-ec2","title":"Parte 1. Modificaci\u00f3n del script de creaci\u00f3n de la VPC y la EC2","text":"<p>La pr\u00e1ctica consiste en modificar el script para que la VPC la cree con la direcci\u00f3n <code>192.168.0.0/16</code> y la subred que hay dentro de ella la cree con la direcci\u00f3n <code>192.168.3.0/24</code>.</p> <p>Atenci\u00f3n</p> <p>F\u00edjate que la instancia EC2 del script de ejemplo se crea con una IP fija dentro de la subred.</p> <p>Ejecuta el script. Para poder ejecutarlo tendr\u00e1s que autenticarte primero con la informaci\u00f3n de la sesi\u00f3n actual de tu laboratorio. Comprueba que se crean los elementos indicados anteriormente.</p>"},{"location":"ud03/redpractica04.html#parte-2-creacion-de-una-subred-y-otra-maquina-ec2","title":"Parte 2. Creaci\u00f3n de una subred y otra m\u00e1quina EC2","text":"<p>Esta parte se hace desde la consola gr\u00e1fica de AWS</p> <p>Debes crear una instancia EC2 en otra subred de nombre \u201csubred-tunombre\u201d y hacer un ping de una m\u00e1quina a otra.</p> <p>Para comprobar el ping, primero deber\u00e1s conectarte por ssh a la primera m\u00e1quina y hacer un ping a la segunda m\u00e1quina de manera local (el ping funciona).</p> <p>Deber\u00e1s modificar el grupo de seguridad creado y permitir el protocolo ICMP. Normalmente las instancias tienen grupos de seguridad diferentes, pero en este caso como la configuraci\u00f3n es muy sencilla, en la nueva m\u00e1quina EC2 puedes reutilizar el grupo de seguridad y permitir el ping.</p> <p>Atenci\u00f3n</p> <p>F\u00edjate que cuando cambias de sesi\u00f3n el token del cli tambi\u00e9n te cambia, es decir, debes cambiar las credentials tal como hiciste en la pr\u00e1ctica  La interfaz de Linea de comandos . </p> <p>Captura las pantallas</p> <p>Resultado de la ejcuci\u00f3n del script</p> <p>Mapa de recursos de la vpc creada</p> <p>Direcciones ip privadas de las instancias</p> <p>Ping de una instancia a la otra</p>"},{"location":"ud03/vpc.html","title":"Creaci\u00f3n de un entorno de red","text":""},{"location":"ud03/vpc.html#es-necesaria-una-arquitectura-de-red-en-la-nube-de-aws","title":"\u00bfEs necesaria una arquitectura de red en la nube de AWS?","text":"<p>La necesidad de una arquitectura de red en AWS no es una cuesti\u00f3n secundaria, sino una decisi\u00f3n estrat\u00e9gica fundamental. Esta arquitectura impacta directamente en el rendimiento, la seguridad y la capacidad de crecimiento de cualquier soluci\u00f3n tecnol\u00f3gica desplegada en la nube. Los siguientes pilares justifican claramente su implementaci\u00f3n</p>"},{"location":"ud03/vpc.html#escalabilidad","title":"Escalabilidad","text":"<p>Una arquitectura de red bien dise\u00f1ada en AWS permite escalar los recursos de forma autom\u00e1tica y seg\u00fan la demanda, sin comprometer la continuidad operativa.</p> <p>Servicios como Amazon VPC, Auto Scaling, Elastic Load Balancing y Route 53 permiten distribuir el tr\u00e1fico de manera eficiente y agregar ecursos de computaci\u00f3n sin redise\u00f1ar toda la infraestructura. Elementos como Elastic IPs, subredes en m\u00faltiples zonas de disponibilidad y recursos el\u00e1sticos garantizan disponibilidad incluso ante aumentos s\u00fabitos de tr\u00e1fico.</p> <p>Adem\u00e1s, esta arquitectura permite escalar horizontalmente (a\u00f1adiendo m\u00e1s instancias) o verticalmente (potenciando las existentes) sin nterrumpir los servicios en producci\u00f3n.</p>"},{"location":"ud03/vpc.html#seguridad","title":"Seguridad","text":"<p>AWS permite implementar una estrategia de seguridad multicapa, desde el nivel de red hasta el de la aplicaci\u00f3n. A trav\u00e9s de VPCs configurables, subredes segmentadas, grupos de seguridad y listas de control de acceso (NACLs), es posible definir reglas precisas para controlar el tr\u00e1fico. Adem\u00e1s posee servicios que protegen frente a amenazas externas y ataques DDoS.</p> <p>La infraestructura puede reforzarse mediante conexiones cifradas (VPN, Direct Connect), lo que asegura la confidencialidad de la nformaci\u00f3n en tr\u00e1nsito.</p>"},{"location":"ud03/vpc.html#conectividad","title":"Conectividad","text":"<p>La arquitectura de red en AWS facilita la integraci\u00f3n fluida entre distintos recursos, ya sea en la nube o en entornos h\u00edbridos.</p> <p>Soluciones como VPC Peering, Transit Gateway y PrivateLink permiten conectar instancias, bases de datos, contenedores y otros servicios sin fricci\u00f3n. Tambi\u00e9n es posible establecer conectividad h\u00edbrida mediante t\u00faneles VPN cifrados o AWS Direct Connect.</p> <p>Por otro lado, servicios como AWS Global Accelerator optimizan la velocidad de acceso para usuarios distribuidos geogr\u00e1ficamente, mejorando la experiencia del cliente final.</p> <p>Dise\u00f1ar una arquitectura de red s\u00f3lida en AWS no es una opci\u00f3n, sino un requisito. Esta arquitectura constituye el cimiento que permite que las soluciones cloud sean escalables, seguras y conectadas. De su planificaci\u00f3n depende en gran medida la disponibilidad del servicio, la protecci\u00f3n de los datos y la agilidad de la organizaci\u00f3n para adaptarse a nuevos desaf\u00edos.</p>"},{"location":"ud03/vpc.html#los-servicios-que-ofrece-aws-para-gestionar-las-redes-son","title":"Los servicios que ofrece AWS para gestionar las redes son:","text":"<p>Amazon Virtual Private Cloud (Amazon VPC): permite aprovisionar secciones aisladas de forma l\u00f3gica de la nube de AWS.</p> <p>Elastic Load Balancing: distribuye autom\u00e1ticamente el tr\u00e1fico entrante de las aplicaciones en varios destinos, tales como instancias de Amazon EC2, contenedores, direcciones IP y funciones Lambda.</p> <p>Amazon CloudFront: servicio r\u00e1pido de red de entrega de contenido (CDN) que suministra datos, videos, aplicaciones y APIs de manera segura a clientes de  todo el mundo, con baja latencia y altas velocidades de transferencia.</p> <p>AWS Transit Gateway: servicio que permite a los clientes conectar sus nubes privadas virtuales de Amazon (VPC) y sus redes en las instalaciones ( on-premise ) a un \u00fanico gateway .</p> <p>Amazon Route 53: servicio web de DNS escalable y en la nube dise\u00f1ado para direccionar a los usuarios finales a las aplicaciones de Internet de    una forma confiable.</p> <p>AWS Global Accelerator: utiliza las ubicaciones de borde para encontrar la ruta \u00f3ptima a la regi\u00f3n donde reside nuestra aplicaci\u00f3n (haciendo uso tanto de protocolos HTTP como TCP/UDP).</p> <p>AWS Direct Connect: ofrece una manera de establecer una conexi\u00f3n de red privada dedicada desde un centro de datos u oficina a AWS, lo que puede reducir los costes de red y aumentar el rendimiento del ancho de  banda.</p> <p>AWS VPN: proporciona un t\u00fanel privado seguro desde una red o dispositivo a la red global de AWS.</p> <p>Haciendo usos de esos servicios se puede mostrar una soluci\u00f3n sencilla:</p> <p></p>"},{"location":"ud03/vpc.html#redes-en-aws","title":"Redes en AWS","text":"<p>Suponemos que los conceptos de red, subred y direcci\u00f3n IP y el modelo de la OSI est\u00e1n claros.</p> <p>Dentro de AWS se utiliza el m\u00e9todo CIDR para describir redes, por ejemplo,\u00a0<code>192.0.2.0/24</code>\u00a0(los primeros 24 bits son est\u00e1ticos, y los \u00faltimos 8 flexibles). </p> <p>Nota</p> <p>Cabe destacar que AWS reserva las primeras cuatro direcciones IP y la \u00faltima direcci\u00f3n IP de cada subred para fines de redes internas. </p> <p>Por ejemplo, una subred <code>/28</code> tendr\u00eda 16 direcciones IP disponibles. De ah\u00ed hay que restar las 5 IP reservadas por AWS, obteniendo 11 direcciones IP para nuestro uso dentro de la subred.</p> <p>Muchos de los conceptos de redes f\u00edsicas son v\u00e1lidos para las redes  cloud, con la ventaja que en la nube nos ahorraremos gran parte de la complejidad.</p>"},{"location":"ud03/vpc.html#amazon-vpc","title":"Amazon VPC","text":"<p>AWS utiliza las VPC (AmazonVirtual Private Cloud ) como redes privadas virtuales donde est\u00e1n conectados todos los recursos con los que trabajamos, de manera que el acceso queda aislado de otros usuarios. Dicho de otro modo, Amazon VPC permite lanzar recursos de AWS en la red virtual que definamos. Esta red virtual se asemeja en gran medida a una red tradicional que ejecutar\u00edamos en nuestro propio centro de datos, con los beneficios de utilizar la infraestructura escalable de AWS, pudiendo crear una VPC que abarque varias AZ.</p> <p>Al definir la red virtual podemos seleccionar nuestro propio intervalo de direcciones IP, crear subredes y configurar las tablas de enrutamiento y gateways de red. Tambi\u00e9n podemos colocar el\u00a0backend\u00a0(servidores de aplicaciones o de bases de datos) en una subred privada sin acceso a Internet p\u00fablico. Finalmente, podemos a\u00f1adir varias capas de seguridad, como grupos de seguridad y listas de control de acceso a la red (ACL de red), para ayudar a controlar el acceso a las instancias de EC2 en cada subred.</p> <p>Sin entrar en mayor detalle, vamos a repasar algunos de los componentes m\u00e1s importantes:</p>"},{"location":"ud03/vpc.html#gateway-de-internet-igw","title":"Gateway de Internet\u00a0(IGW)","text":"<p>Un\u00a0gateway de Internet\u00a0(Internet Gateway, IGW) es un componente de la VPC que permite la comunicaci\u00f3n entre instancias de la VPC e Internet. </p> <p>Un caso espec\u00edfico es un Gateway NAT(o Nat Gateway), que se utiliza para proporcionar conectividad a Internet a instancias EC2 en las subredes privadas.</p> <p>Despu\u00e9s de crear una VPC, podemos agregar subredes. Cada\u00a0subred\u00a0est\u00e1 ubicada por completo dentro de una zona de disponibilidad y no puede abarcar otras zonas. </p> <p>Si el tr\u00e1fico de una subred se direcciona a un Internet Gateway, la subred recibe el nombre de subred   p\u00fablica. Si una subred no dispone de una ruta al\u00a0Internet Gateway, recibe el nombre de subred privada.</p> <p>Para que las subredes privadas puedan conectarse a Internet dirigiendo el tr\u00e1fico al\u00a0NAT Gateway hemos de configurar las tablas enrutamiento.</p>"},{"location":"ud03/vpc.html#tabla-de-enrutamiento","title":"Tabla de enrutamiento","text":"<p>Una\u00a0tabla de enrutamientocontiene un conjunto de reglas, llamadas rutas, que se utilizan para   determinar el destino del tr\u00e1fico de red. Cada subred de una VPC debe estar asociada a una tabla de enrutamiento, que es la que controla el direccionamiento de la subred. Las reglas de las tablas de enrutamiento se colocan de m\u00e1s a menos restrictivas. Tienen una ruta local integrada, la cual no se puede eliminar. Las rutas adicionales se agregan a la tabla.</p>"},{"location":"ud03/vpc.html#grupo-de-seguridad","title":"Grupo de seguridad","text":"<p>Las VPC utilizan un grupo de seguridad que act\u00faa como un\u00a0firewall\u00a0virtual.</p> <p>Cuando se lanza una instancia, se asocia uno o varios grupos de seguridad a ella. Los grupos de seguridad tienen reglas que controlan el tr\u00e1fico de entrada y de salida de las instancias, las  cuales podemos modificar. </p> <p>Atenci\u00f3n</p> <p>Los grupos de seguridad predeterminados deniegan todo el tr\u00e1fico de entrada y permiten todo el tr\u00e1fico de salida.</p> <p>A continuaci\u00f3n veremos algunas pr\u00e1cticas de creaci\u00f3n de VPC que nos ayudar\u00e1n a entender y afianzar estos conceptos.</p>"},{"location":"ud04/practica1.html","title":"Pr\u00e1ctica 1. Creaci\u00f3n de un bucket en Amazon S3","text":"<p>Creaci\u00f3n y gesti\u00f3n de un bucket en Amazon S3: subida de objetos, control de permisos y versiones.</p> <p></p>"},{"location":"ud04/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento de Amazon S3 como servicio de almacenamiento de objetos.</li> <li>Aprender a crear y configurar un bucket en una regi\u00f3n determinada.</li> <li>Subir archivos y gestionar su acceso mediante ACLs.</li> <li>Acceder a un objeto p\u00fablico a trav\u00e9s de su URL en el navegador.</li> <li>Activar el control de versiones y comprobar c\u00f3mo mantiene distintas versiones de un mismo archivo.</li> </ul>"},{"location":"ud04/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud04/practica1.html#creacion-del-bucket","title":"Creaci\u00f3n del bucket","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio S3.</p> <ul> <li>Pulsa en \u201cCrear bucket\u201d.</li> <li> <p>Especifica:</p> <ul> <li>Tipo de bucket: Uso general.</li> <li>Nombre del bucket: debe ser \u00fanico en todo el mundo (por ejemplo: <code>practica-s3-nombrealumno</code>).</li> </ul> </li> <li> <p>Deja todos los dem\u00e1s campos por defecto.</p> </li> <li>Crea el bucket pulsando \u201cCrear bucket\u201d.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#subida-de-objetos","title":"Subida de objetos","text":"<p>2.- Entra en el bucket reci\u00e9n creado para a\u00f1adir contenidos:</p> <ul> <li>Pulsa \u201cCargar\u201d \u2192 \u201cA\u00f1adir archivos\u201d y selecciona 2 o 3 im\u00e1genes en formato jpg de tu equipo. Por ejemplo <code>foto1.jpg</code> y <code>foto2.jpg</code></li> <li>Haz clic en \u201cCargar\u201d para subirlas.</li> <li>Prueba a cargar tambi\u00e9n una carpeta con archivos dentro.</li> <li>Comprueba que aparecen en la lista de objetos.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#acceso-mediante-url","title":"Acceso mediante URL","text":"<p>3.- Vamos a acceder a uno de los objetos reci\u00e9n subidos, por ejemplo <code>foto1.jpg</code>, desde un navegador especificicando su url:</p> <ul> <li>Ve a la pesta\u00f1a \u201cPropiedades\u201d del objeto <code>foto1.jpg</code></li> <li>Copia la URL del objeto (por ejemplo:    <code>https://practica-s3-nombrealumno.s3.us-east-1.amazonaws.com/foto1.jpg</code>)</li> </ul> <p></p> <ul> <li>Abre un navegador web y pega la URL.</li> <li>Comprueba que la imagen no se muestra correctamente al no disponer de permisos.</li> </ul> <p></p>"},{"location":"ud04/practica1.html#desbloquear-el-acceso-publico","title":"Desbloquear el acceso p\u00fablico","text":"<p>4.- Vamos ahora a desbloquear la restricci\u00f3n de acceso p\u00fablico al bucket. Lo podr\u00edamos haber hecho en el momento de creaci\u00f3n. Para ello, en la pantalla del bucket accedemos a la pesta\u00f1a Permisos y editamos la opci\u00f3n de Bloquear acceso p\u00fablico.</p> <p></p> <p>Desmarcamos todas las opciones. Nos pide que confirmemos.</p> <p></p> <p>Atenci\u00f3n</p> <p>En entornos reales no se deben dejar objetos p\u00fablicos.</p> <p>Si accedemos de nuevo desde un navegador a la url del objeto veremos que continuamos sin poder acceder al objeto, a pesar de haber hecho p\u00fablico el bucket. A\u00fan nos falta un paso m\u00e1s.</p>"},{"location":"ud04/practica1.html#cambio-de-permisos-mediante-acl","title":"Cambio de permisos mediante ACL","text":"<p>5.- Las pol\u00edticas de acceso a los objetos se pueden controlar de varias maneras (ACLs, Pol\u00edticas, Roles). Vamos a hacerlo por una opci\u00f3n m\u00e1s sencilla pero que AWS no recomienda: mediante ACLs (listas de control de acceso). Para ello el primer paso ser\u00e1 habilitar las ACLs que por defecto aparecen deshabilitadas. Este paso tambi\u00e9n podr\u00edamos haberlo hecho al crear el bucket.</p> <ul> <li>Vuelve a seleccionar el bucket en S3.</li> <li>En la pesta\u00f1a \u201cPermisos\u201d, busca la secci\u00f3n \u201cPropiedades de los objetos\u201d.</li> <li>Pulsa en \u201cEditar\u201d y habilita las ACLs.</li> </ul> <p></p> <p>6.- Una vez habilitadas las ACL, vamoa a hacer p\u00fablico el objeto en particular:</p> <ul> <li>Seleccionam el objeto <code>foto1.jpg</code> </li> <li>En el men\u00fa Acciones selecciona Hacer p\u00fablico mediante ACL.</li> <li>Comprueba que ya puedes acceder desde el navegador a la url p\u00fablica del objeto.</li> </ul> <p></p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el acceso desde el navegador a la imagen. Debe verse la url del objeto y la fotograf\u00eda mostrada dentro del navegador.</p>"},{"location":"ud04/practica1.html#activar-el-control-de-versiones","title":"Activar el control de versiones","text":"<p>Amazon S3 incorpora una funcionalidad que permite mantener m\u00faltiples versiones de un objeto en el mismo bucket, protegiendo contra eliminaciones o modificaciones no deseadas. Cuando se habilita, S3 conserva una versi\u00f3n anterior del objeto cada vez que se modifica o elimina. Esto permite recuperar y restaurar f\u00e1cilmente versiones anteriores de un objeto en cualquier momento</p> <ul> <li>Regresa a la vista principal del bucket.</li> <li>En la pesta\u00f1a \u201cPropiedades\u201d, busca la secci\u00f3n \u201cControl de versiones\u201d.</li> <li>Pulsa \u201cEditar\u201d \u2192 activa el control de versiones \u2192 Guardar cambios.</li> </ul>"},{"location":"ud04/practica1.html#probar-el-control-de-versiones","title":"Probar el control de versiones","text":"<ul> <li>Sube de nuevo una imagen con el mismo nombre que una ya existente (por ejemplo <code>foto1.jpg</code>).</li> <li>S3 no reemplazar\u00e1 la imagen anterior, sino que guardar\u00e1 una nueva versi\u00f3n.</li> <li>Ve al objeto y selecciona la pesta\u00f1a \u201cVersiones\u201d para ver las distintas versiones almacenadas.</li> <li>Prueba a descargar o restaurar la versi\u00f3n anterior.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestren las distintas versiones del archivo.</p>"},{"location":"ud04/practica2.html","title":"Pr\u00e1ctica 2. Publicaci\u00f3n de una web est\u00e1tica en S3","text":"<p>Publicaci\u00f3n de un sitio web est\u00e1tico en Amazon S3 con control de acceso mediante pol\u00edticas de bucket.</p>"},{"location":"ud04/practica2.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del alojamiento web est\u00e1tico en Amazon S3.</li> <li>Aprender a crear un bucket, subir un sitio web y habilitar su acceso p\u00fablico mediante una pol\u00edtica de bucket.</li> <li>Configurar S3 para que sirva p\u00e1ginas web (HTML, CSS, im\u00e1genes, etc.) directamente.</li> <li>Comprobar el acceso al sitio web a trav\u00e9s de una URL p\u00fablica de S3.</li> </ul>"},{"location":"ud04/practica2.html#preparacion-del-material","title":"Preparaci\u00f3n del material","text":"<p>1.- En primer lugar vamos a descargar desde GitHub un repositorio con una web de muestra. Lo haremos en un fichero <code>.zip</code> el cual habr\u00e1 que descomprimir:</p> <ul> <li>Accede al repositorio de GitHub que contiene una web de muestra:    <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> <li>Descarga el repositorio en formato ZIP pulsando en Code \u2192 Download ZIP.</li> <li>Descomprime el archivo ZIP en tu equipo local. Deber\u00edas tener una carpeta con archivos como <code>index.html</code>, <code>assets/</code>, etc.</li> </ul>"},{"location":"ud04/practica2.html#creacion-del-bucket","title":"Creaci\u00f3n del bucket","text":"<p>2.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio S3. Crea un bucket:</p> <ul> <li>Que el bucket sea de uso general.</li> <li>Pon un nombre del bucket \u00fanico, por ejemplo, <code>web-estatica-nombrealumno</code>.</li> <li>Deja deshabilitadas las ACL.</li> <li>Haz que el acceso al bucket sea p\u00fablico, desmarca la casilla \u201cBloquear todo el acceso p\u00fablico\u201d.</li> </ul> <p>Atenci\u00f3n</p> <p>Ya sabemos que hacer el bucket p\u00fablico es una pr\u00e1ctica peligrosa, pero en este caso no tenemos elecci\u00f3n.</p>"},{"location":"ud04/practica2.html#subir-los-archivos-de-la-web","title":"Subir los archivos de la web","text":"<p>3.- Entra en el bucket creado y carga los archivos descomprimidos.</p> <p>Atenci\u00f3n</p> <p>A la hora de subir el contenido no subas directamente la carpeta <code>hello-cloud-main</code> sino \u00fanicamente los ficheros y carpetas que hay en su interior, asegur\u00e1ndote que el fichero <code>index.html</code> y el resto de archivos y carpetas de ese nivel quedan en la ra\u00edz del bucket.</p>"},{"location":"ud04/practica2.html#activar-el-alojamiento-web-estatico","title":"Activar el alojamiento web est\u00e1tico","text":"<p>4.- Con el contenido ya cargado, vamos a activar el alojamiento web est\u00e1tico. Para ello, en la vista del bucket, ve a la pesta\u00f1a \u201cPropiedades\u201d:</p> <ul> <li>En la secci\u00f3n \u201cAlojamiento de sitio web est\u00e1tico\u201d haz clic en \u201cEditar\u201d \u2192 selecciona \u201cHabilitar\u201d.</li> <li>En Documento de \u00edndice escribe: <code>index.html</code></li> <li>Copia la URL del sitio web que aparece (por ejemplo: <code>http://web-estatica-nombrealumno.s3-website-eu-west-1.amazonaws.com</code>).</li> </ul>"},{"location":"ud04/practica2.html#configurar-la-politica-del-bucket","title":"Configurar la pol\u00edtica del bucket","text":"<p>5.- Si intentamos acceder a la url de la p\u00e1gina web est\u00e1tica nos dar\u00e1 un error de permisos, pues no es suficiente con hacer p\u00fablico el bucket. Es necesario que adem\u00e1s concedamos permisos. En la pr\u00e1ctica anterior vimo c\u00f3mo cambiar estos permisos mediante ACLs, pero AWS nos recomienda que lo hagamos por pol\u00edticas. En esta pr\u00e1ctica vamos a cambiar los permisos mediante pol\u00edticas:</p> <ul> <li>Accede a la pesta\u00f1a Permisos del bucket.</li> <li>Localiza Pol\u00edtica de bucket y pulsa Editar.</li> <li>Pega la siguiente pol\u00edtica en formato JSON, sustituyendo el nombre del bucket por el tuyo:</li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"PublicReadGetObject\",\n      \"Effect\": \"Allow\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:GetObject\",\n      \"Resource\": \"arn:aws:s3:::web-estatica-nombrealumno/*\"\n    }\n  ]\n}\n</code></pre> <p>Esta pol\u00edtica <code>s3:GetObject</code> junto con la opci\u00f3n <code>Allow</code> permite que cualquiera (<code>*</code>) pueda leer los archivos del bucket, pero no modificarlos ni borrarlos.</p> <p>El recurso <code>\"Resource\": \"arn:aws:s3:::web-estatica-nombrealumno/*\"</code> indica el arn del bucket seguido de <code>/*</code>, que significa cualquier objeto dentro del bucket.</p> <p>El arn es el Amazon Resource Name, es decir, un identificador \u00fanico que AWS usa para referirse a cualquier recurso dentro de su infraestructura: un bucket S3, una instancia EC2, una funci\u00f3n Lambda, una pol\u00edtica IAM, etc.</p>"},{"location":"ud04/practica2.html#comprobar-el-funcionamiento","title":"Comprobar el funcionamiento","text":"<ul> <li>Abre la URL del sitio web.</li> <li>Si todo est\u00e1 correcto, la p\u00e1gina <code>index.html</code> y el resto del contenido se mostrar\u00e1 p\u00fablicamente.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que ha funcionado el aaceso desde el navegador a la web. Debe verse la url y el contenido de la p\u00e1gina web.</p>"},{"location":"ud04/practica3.html","title":"Pr\u00e1ctica 3. Gesti\u00f3n de vol\u00famenes EBS","text":"<p>Creaci\u00f3n de un volumen EBS y montaje en varias instancias EC2.</p> <p>Recuerda</p> <ul> <li>Los vol\u00famenes EBS equivalen a los discos duros virtuales que utilizan las instancias EC2.</li> <li>Un volumen s\u00f3lo puede estar conectado a una instancia simult\u00e1neamente.</li> <li>Pero una instancia puede conectar varios vol\u00fames EBS simult\u00e1neamente.</li> </ul>"},{"location":"ud04/practica3.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del almacenamiento EBS (Elastic Block Store).</li> <li>Crear y asociar un volumen EBS a una instancia EC2.</li> <li>Formatear, montar y usar un volumen EBS desde Linux.</li> <li>Desasociar y reutilizar un volumen en otra instancia.</li> <li>Crear y restaurar una instant\u00e1nea (snapshot) de un volumen.</li> </ul>"},{"location":"ud04/practica3.html#creacion-de-una-instancia-ec2","title":"Creaci\u00f3n de una instancia EC2","text":"<p>1.- Vamos a crear una instancia EC2 sobre la que montaremos el volumen EBS. Configura:</p> <ul> <li>Nombre: <code>Servidor-A</code></li> <li>AMI: Ubuntu</li> <li>Instance type: <code>t2.micro</code></li> <li>Key pair: selecciona o crea uno nuevo</li> <li>Network settings: deja la VPC y subred por defecto</li> <li>Storage: deja el volumen ra\u00edz predeterminado (8 GB)</li> </ul> <p>Importante</p> <p>Recuerda la zona de disponibilidad en la que se ha creado la m\u00e1quina. El volumen EBS que crearemos debe estar necesariamente en la misma AZ que la EC2.</p> <p>2.- Lanza la instancia y espera a que el estado sea Running.</p> <p>3.- Podemos conectarnos por ssh, pero esta vez lo vamos a hacer desde el propio navegador:</p> <ul> <li>Selecciona la instancia <code>Servidor-A</code> y pulsa sobre el bot\u00f3n Conectar</li> <li>En la pesta\u00f1a Conexi\u00f3n de la instancia EC2 pulsa Conectar</li> <li>Nos aparecer\u00e1 una consola de terminal en el navegador conectada a la instancia <code>Servidor-A</code>.</li> </ul> <p></p> <p></p>"},{"location":"ud04/practica3.html#crear-y-adjuntar-un-volumen-ebs","title":"Crear y adjuntar un volumen EBS","text":"<p>4.- Estando en la pantalla de las instancia de EC2, en el panel lateral aparece un men\u00fa Elastic Block Store \u2192 Vol\u00famenes. Accede a \u00e9l y selecciona:</p> <ul> <li>Crear volumen</li> <li>Tipo: gp3</li> <li>Tama\u00f1o: 20 GiB</li> <li>Availability Zone: la misma que tu EC2</li> <li>Deja los valores por defecto que te propone para las IOPS y el Rendimiento.</li> <li>No marques la opci\u00f3n de cifrado</li> </ul> <p>5.- Una vez creado, selecciona el volumen y pulsa sobre Acciones \u2192 Asociar volumen</p> <ul> <li>Instancia: elige la instancia <code>Servidor-A</code></li> <li>Nombre de dispositivo: selecciona uno de la lista, por ejemplo <code>/dev/sdf</code></li> </ul>"},{"location":"ud04/practica3.html#formatear-y-montar-el-volumen","title":"Formatear y montar el volumen","text":"<p>6.- Accede al terminal de la m\u00e1quina EC2 y verifica desde la instancia que se haya detectado el nuevo disco (puedes verificar que el n\u00famero de serie coincide con el de la consola de EBS):</p> <pre><code>lsblk -o NAME,SIZE,SERIAL,TYPE,MOUNTPOINTS\n</code></pre> <p>Atenci\u00f3n</p> <p>Es posible que la m\u00e1quina EC2 no le asigne el nombre <code>/dev/sdf</code> que hemos seleccionado y en su lugar utilice la nomenclatura <code>/dev/nvmeXnY</code> que corresponde a los discos NVME.</p> <p>7.- Formatea el volumen (sustituye por el nombre de dispositivo que te haya asignado):</p> <pre><code>sudo mkfs -t ext4 /dev/nvme1n1\n</code></pre> <p>F\u00edjate que no hemos creado ninguna partici\u00f3n en el disco, sino que hemos creado el sistema de ficheros directamente sobre todo el disco. Esto puede ser peligroso, pero en el caso de los discos EBS no hay problema de hacerlo as\u00ed.</p> <p>8.- Crea un punto de montaje:</p> <p><pre><code>sudo mkdir /datos\n</code></pre> 9.- Monta el volumen:</p> <p><pre><code>sudo mount /dev/nvme1n1 /datos\n</code></pre> 10.- Comprueba:</p> <p><pre><code>df -h\n</code></pre> 11.- Crea un archivo de prueba:</p> <pre><code>echo \"Prueba EBS\" | sudo tee /datos/info.txt\n</code></pre> <p>12.- Muestra el contenido del archivo creado:</p> <pre><code>echo cat /datos/info.txt\n</code></pre>"},{"location":"ud04/practica3.html#desmontar-y-conectar-el-volumen-a-otra-ec2","title":"Desmontar y conectar el volumen a otra EC2","text":"<p>13.- Vamos ahora a desmontar el volumen en <code>Servidor-A</code> para dejarlo disponible para ser utilizado por otra instancia:</p> <pre><code>sudo umount /datos\n</code></pre> <p>14.- En la consola AWS:</p> <ul> <li>Selecciona el volumen EBS y pulsa sobre Desasociar el volumen desde el men\u00fa de acciones.</li> </ul> <p>15.- Crea una segunda instancia EC2 de Ubuntu:</p> <ul> <li>Nombre: <code>Servidor-B</code></li> <li>Importante: Misma AZ que el <code>Servidor-A</code></li> </ul> <p>16.- Una vez en ejecuci\u00f3n, desde el panel de Acciones de EBS, Asociar volumen \u2192 selecciona el mismo volumen EBS creado anteriormente y lo asocias a <code>Servidor-B</code>.</p> <p>17.- Con\u00e9ctate a <code>Servidor-B</code> y monta el volumen:</p> <pre><code>sudo mkdir /datos\n</code></pre> <pre><code>sudo mount /dev/nvme1n1 /datos\n</code></pre> <pre><code>cat /datos/info.txt\n</code></pre> <p>Ver\u00e1s el contenido creado en la otra m\u00e1quina:</p> <pre><code>Prueba EBS\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que han funcionado todos los comandos ejecutados en <code>Servidor-B</code></p>"},{"location":"ud04/practica3.html#crear-y-restaurar-una-instantanea-snapshot","title":"Crear y restaurar una instant\u00e1nea (snapshot)","text":"<p>18.- Desde la consola EBS \u2192 Volumenes, selecciona tu volumen y pulsa Crear instant\u00e1nea dentro del men\u00fa Acciones.</p> <ul> <li>Descripci\u00f3n: \u201cSnapshot de prueba del volumen EBS\u201d</li> </ul> <p>19.- Espera a que el estado del snapshot sea Completed.</p> <p>20.- Ahora, vamos a crear un nuevo volumen a partir de la instant\u00e1nea creada. Para ello accedemos al panel lateral Elastic Block Store \u2192 Instant\u00e1neas:</p> <ul> <li>Seleccionamos la instant\u00e1nea que acabamos de crear.</li> <li> <p>En el men\u00fa Acciones pulsamos sobre Crear volumen a partir de una instant\u00e1nea:</p> <ul> <li>Seleccionamos el mismo tipo y AZ que el volumen anterior.</li> <li>Dejamos es resto de los valores por defecto.</li> </ul> </li> </ul> <p>21.- Con\u00e9ctalo a cualquiera de las instancias y verifica que el archivo <code>/datos/info.txt</code> sigue existiendo.</p>"},{"location":"ud04/practica3.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Finaliza las instancias pero no las elimines (nos har\u00e1n falta para la siguiente pr\u00e1ctica).</li> <li>Elimina los vol\u00famenes EBS creados.</li> </ul>"},{"location":"ud04/practica4.html","title":"Pr\u00e1ctica 4. Uso compartido de almacenamiento con Amazon EFS","text":"<p>Recuerda</p> <ul> <li>Amazon EFS equivale a montar sistemas de ficheros compatibles con NFS.</li> <li>Se comporta como si fuera un NAS.</li> <li>M\u00faltiples instancias EC2 pueden montar un mismo EFS simult\u00e1neamente.</li> </ul>"},{"location":"ud04/practica4.html#objetivos-de-la-practica","title":"Objetivos de la pr\u00e1ctica","text":"<ul> <li>Comprender el funcionamiento del servicio Amazon EFS (Elastic File System).</li> <li>Crear un sistema de archivos compartido entre varias instancias EC2.</li> <li>Montar el sistema de archivos en Linux mediante el cliente NFS.</li> <li>Verificar que los cambios realizados desde una instancia se reflejan en la otra.</li> </ul> <p>Atenci\u00f3n</p> <p>Para poder montar el sistema de archivos EFS en una m\u00e1quina EC2 necesitamos instalar unas utilidades en dicha m\u00e1quina. Tenemos 2 opciones:</p> <ul> <li>Instalar el paquete <code>amazon-efs-utils</code>, pero los binarios s\u00f3lo est\u00e1n disponiblen para las AMI de Amazon-Linux</li> <li>Instalar las utilidades de NFS (en Ubuntu son las <code>nfs-common</code>), pero es necesario abrir el puerto 2049 (NFS) en el grupo de seguridad correspondiente.</li> </ul> <p>Elegiremos la segunda opci\u00f3n en esta pr\u00e1ctica.</p>"},{"location":"ud04/practica4.html#crear-el-sistema-de-archivos-efs","title":"Crear el sistema de archivos EFS","text":"<p>1.- En la consola de AWS, ve a EFS \u2192 Crear un sistema de archivos. Configura:</p> <ul> <li>Nombre: <code>efs-practica</code></li> <li>VPC: selecciona la misma VPC donde est\u00e1n tus instancias EC2.</li> <li>No hace falta personalizar el resto de par\u00e1metros. Los dejaremos todos con los valores por defecto.</li> </ul> <p>2.-Una vez creado el sistema de archivos efs, accede a \u00e9l y entra para ver sus propiedades. En la pesta\u00f1a de red:</p> <ul> <li>Aseg\u00farate de que exista un destino de montaje (mount target) en la misma subred o AZ de tus instancias. Por defecto se crea uno en cada subred.</li> <li>F\u00edjate bien en el grupo de seguridad asociado a cada destino de montaje porque habr\u00e1 que modificar las reglas de ese grupo de seguridad.</li> </ul> <p>Apunta el grupo de seguridad asociado al destino de montaje. Nos har\u00e1 falta saberlo m\u00e1s adelante.</p> <p>3.- Copia el nombre de DNS asignado al sistema de ficheros. Debe ser algo as\u00ed: <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code></p>"},{"location":"ud04/practica4.html#crea-las-instancias-de-ec2","title":"Crea las instancias de EC2","text":"<p>4.- Crea 2 m\u00e1quinas EC2 o reutiliza las de la pr\u00e1ctica anterior si a\u00fan las conservas (<code>Servidor-A</code> y <code>Servidor-B</code>).</p> <p>5.- Puesto que vamos a utilizar las m\u00e1quinas Ubuntu y no podemos descargar de los repositorios el paquete <code>amazon-efs-utils</code> vamos a optar por utilizar la opci\u00f3n de conectarnos con los paquetes NFS edt\u00e1ndar (<code>nfs-common</code>) y por tanto ser\u00e1 necesario abrir el puerto. Lo haremos m\u00e1s adelante.</p> <p>Para ello Apunta el grupo de seguridad asociado a las instancias EC2. Nos har\u00e1 falta saberlo en el siguiente punto.</p>"},{"location":"ud04/practica4.html#abrir-el-puerto-2049-en-el-grupo-de-seguridad","title":"Abrir el puerto 2049 en el grupo de seguridad","text":"<p>6.- Accede al grupo de seguridad asociado al EFS y crea una nueva regla de entrada para permitir el tr\u00e1fico por el puerto NFS (2049) desde el grupo de seguridad de las instancias EC2.</p> <p></p>"},{"location":"ud04/practica4.html#configurar-las-instancias-ec2","title":"Configurar las instancias EC2","text":"<p>7.- Con\u00e9ctate a la primera instancia EC2 (<code>Servidor-A</code>) e instala el cliente NFS:</p> <p><pre><code>sudo apt update\nsudo apt install -y nfs-common\n</code></pre> 8.- Crea un punto de montaje local:</p> <p><pre><code>sudo mkdir /mnt/efs\n</code></pre> 9.- Monta el sistema de archivos EFS (pega el ID copiado desde la consola en el paso 3, por ejemplo <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code>):</p> <p><pre><code>sudo mount -t nfs4 -o nfsvers=4.1 fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com:/ /mnt/efs\n</code></pre> 10.- Verifica que el montaje fue correcto:</p> <p><pre><code>df -h\n</code></pre> 11.- Crea un archivo de prueba:</p> <pre><code>echo \"Archivo creado desde Servidor-A\" | sudo tee /mnt/efs/prueba.txt\n</code></pre>"},{"location":"ud04/practica4.html#montar-el-mismo-efs-en-otra-instancia","title":"Montar el mismo EFS en otra instancia","text":"<p>12.- Con\u00e9ctate a la segunda instancia EC2 (<code>Servidor-B</code>) e instala tambi\u00e9n el cliente NFS:</p> <p><pre><code>sudo apt update\nsudo apt install -y nfs-common\n</code></pre> 13.- Crea el mismo punto de montaje local:</p> <p><pre><code>sudo mkdir /mnt/efs\n</code></pre> 14.- Monta el sistema de archivos EFS (pega el ID copiado desde la consola en el paso 3, por ejemplo <code>fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com</code>):</p> <pre><code>sudo mount -t nfs4 -o nfsvers=4.1 fs-0a5162c49f76a0c1e.efs.us-east-1.amazonaws.com:/ /mnt/efs\n</code></pre> <p>15.- Comprueba que puedes ver el archivo creado desde el otro servidor:</p> <pre><code>cat /mnt/efs/prueba.txt\n</code></pre> <p>Deber\u00edas ver:</p> <pre><code>Archivo creado desde Servidor-A\n</code></pre> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se muestre que han funcionado todos los comandos ejecutados en <code>Servidor-B</code></p> <p>16.- Ahora crea otro archivo desde el <code>Servidor-B</code>:</p> <pre><code>echo \"Creado desde Servidor-B\" | sudo tee mnt/efs/otro.txt\n</code></pre> <p>17.- Comprueba desde el <code>Servidor-A</code> que aparece el nuevo archivo:</p> <pre><code>ls /mnt/efs\ncat /mnt/efs/otro.txt\n</code></pre>"},{"location":"ud04/practica4.html#liberacion-de-recursos","title":"Liberaci\u00f3n de recursos","text":"<p>Una vez finalizada la pr\u00e1ctica hay que eliminar los recursos creados para que no nos consuman cr\u00e9dito:</p> <ul> <li>Finaliza y elimina las instancias.</li> <li>Elimina el sistema de archivos EFS creado.</li> </ul>"},{"location":"ud04/practica5.html","title":"Pr\u00e1ctica 5. CI/CD de una web est\u00e1tica en S3 mediante GitHub Actions","text":"<p>Implementaci\u00f3n Continua/Despliegue Continuo de un sitio web est\u00e1tico en Amazon S3 mediante GitHub Actions.</p>"},{"location":"ud04/practica5.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>CI/CD significa Integraci\u00f3n Continua (Continuous Integration) y Entrega/Despliegue Continuo (Continuous Delivery/Deployment).</p> <p>Es un conjunto de pr\u00e1cticas que automatizan la integraci\u00f3n de c\u00f3digo, las pruebas y el despliegue de aplicaciones para entregar software de forma r\u00e1pida y fiable.</p> <p>GitHub Actions es una herramienta de automatizaci\u00f3n integrada en GitHub que permite ejecutar flujos de trabajo en respuesta a eventos del repositorio, como push, pull request o merge.</p> <p>Se utiliza para implementar CI/CD dentro de GitHub, ya que permite automatizar la integraci\u00f3n, las pruebas y el despliegue del c\u00f3digo directamente desde el repositorio, sin necesidad de usar servicios externos.</p> <p>En esta pr\u00e1ctica utilizaremos GitHub Actions para automatizar la copia del repositorio a un Bucket S3 cada vez que se haga un commit en dicho repositorio. Esto implicar\u00e1 que cada vez que se haga un cambio de c\u00f3digo, se suba autom\u00e1ticamente a AWS para estar disponible en la web.</p>"},{"location":"ud04/practica5.html#preparacion-del-material","title":"Preparaci\u00f3n del material","text":"<p>1.- En primer lugar vamos a hacer un fork a nuestra cuenta de GitHub del repositorio que utilizamos en la pr\u00e1ctica 2 que contiene una web de muestra. Lo haremos pulsanso sobre el bot\u00f3n <code>Fork</code> del repositorio.</p> <ul> <li>Val\u00eddate con tus credenciales en GitHub.</li> <li>Accede al repositorio de GitHub que contiene la web de muestra:    <code>https://github.com/ies-camp-de-morvedre/hello-cloud</code>.</li> <li>Pulsa en el bot\u00f3n Fork.</li> <li>Ya tienes en tu cuenta un repositorio con el mismo contenido.</li> </ul>"},{"location":"ud04/practica5.html#creacion-del-bucket","title":"Creaci\u00f3n del Bucket","text":"<p>2.- Crea un bucket en Amazon S3:</p> <ul> <li>Servir\u00e1 para Alojar un sitio web est\u00e1tico.</li> <li>Por tanto deber\u00e1s hacerlo p\u00fablico y asignar los permisos correspondientes mediante ACLs o pol\u00edticas (t\u00fa decides, pero se recomienda hacerlo por pol\u00edticas).</li> <li>Recuerda poner que la p\u00e1gina de inicio del sitio web ser\u00e1 <code>index.html</code>.</li> <li>No cargues ning\u00fan dato.</li> <li>Copia la url del bucket y \u00e1brela en un navegador (te dar\u00e1 error 404 de fichero no encontrado).</li> <li>Copia el nombre del bucket. Debe ser algo as\u00ed: <code>s3://demo-bucket-jrpm</code></li> </ul>"},{"location":"ud04/practica5.html#creacion-del-github-action","title":"Creaci\u00f3n del GitHub Action","text":"<p>3.- Volvemos a nuestro repositorio de GitHub y vamos a crear una Action para que cada vez que se haga un commit en el repositorio, se copie todo el contenido al bucket que acabamos de crear.</p> <ul> <li>Para ello, en el repositorio, ve a la opci\u00f3n Actions</li> <li>Pulsa sobre <code>set up a workflow yourself</code></li> <li>En el editor de texto pega el siguiente c\u00f3digo yaml sustituyendo el nombre del bucket de la \u00faltima l\u00ednea por el nuestro que hemos copiado:</li> </ul> <pre><code>name: deploy static website to AWS-S3 - V2\n\non:\n  push:\n\nenv:\n  AWS_REGION: us-east-1\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}\n          aws-region: ${{env.AWS_REGION}}\n\n      - name: Deploy to AWS S3\n        run: aws s3 sync . s3://demo-bucket-jrpm --delete\n</code></pre> <p>Hacemos commit y comprobamos que se nos ha creado un nuevo directorio en el repositorio con el fichero yaml, el cual describe la acci\u00f3n a ralizar cuando hay un commit.</p>"},{"location":"ud04/practica5.html#configuracion-de-los-secretos","title":"Configuraci\u00f3n de los secretos","text":"<p>4.- Si analizamos el c\u00f3digo yaml que hemos copiado veremos que, para que GitHub se conecte al bucket, es necesario pasarle las credenciales de conexi\u00f3n que usamos para la CLI.</p> <p>Estas credenciales no se ponen directamente en el c\u00f3digo pues estar\u00edan visibles para todo el p\u00fablico. En su lugar se hace uso de los secretos:</p> <pre><code>aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\naws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\naws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}\naws-region: ${{env.AWS_REGION}}\n</code></pre> <p>Para configurar los secretos nos vamos a la opci\u00f3n de configuraci\u00f3n del repositorio y creamos los 4 secretos que nos hacen falta: </p> <ul> <li>Settings --&gt; Secrets and Variables --&gt; Actions</li> <li>New repository secret</li> <li>Hay que hacer el proceso para 4 secretos, cuyos nombres y contenidos ser\u00e1n:</li> </ul> Name Secret AWS_ACCESS_KEY_ID El campo <code>aws_access_key_id</code> de los detalles del laboratorio AWS CLI AWS_SECRET_ACCESS_KEY El campo <code>aws_secret_access_key_id</code> del mismo lugar AWS_SESSION_TOKEN El campo <code>aws_session_token</code> del mismo lugar AWS_REGION La regi\u00f3n que estemos utilizando, en nuestro caso <code>us-east-1</code>"},{"location":"ud04/practica5.html#commit-y-prueba-de-despliegue-automatico","title":"Commit y prueba de despliegue autom\u00e1tico","text":"<p>5.- Si todo ha ido bien, podemos entrar en el repositorio y modificar el fichero <code>index.html</code> para que autom\u00e1ticamente se haga el despliegue en el bucket S3 y as\u00ed poder acceder a la url p\u00fablica:</p> <ul> <li>Estando en el c\u00f3digo del repositorio (<code>&lt;&gt; Code</code>) pulsa la tecla <code>.</code> (punto) para que se abra el editor web de GitHub.</li> <li>Modifica el fichero <code>index.html</code> para que donde ponga IES Camp de Morvedre ponga tu nombre.</li> <li>En la barra de tareas de la izquierda pulsa sobre el bot\u00f3n de Control de C\u00f3digo Fuente (el tercero) y haz un commit indicando un mensaje.</li> <li>Al cabo de unos minutos se habr\u00e1 actualizado el bucket.</li> <li>Accede con un navegador a la url del bucket. Debe verse la web con el cambio realizado.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla Actions del repositorio en la que se muestre que ha funcionado el workflow.</p> <p></p>"},{"location":"ud04/ud04.html","title":"Tema 4. Almacenamiento en AWS","text":""},{"location":"ud04/ud04.html#almacenamiento-en-la-nube","title":"Almacenamiento en la nube","text":"<p>El almacenamiento en la nube suele ser m\u00e1s fiable, escalable y seguro que los tradicionales sistemas de almacenamiento en las instalaciones. El almacenamiento en la nube es un componente fundamental del c\u00f3mputo en la nube, pues contiene la informaci\u00f3n que utilizan las aplicaciones. El an\u00e1lisis de big data, los almacenes de datos, el Internet de las cosas (IoT), las bases de datos y las aplicaciones de copias de seguridad y archivado dependen de alg\u00fan tipo de arquitectura de almacenamiento de datos. </p>"},{"location":"ud04/ud04.html#almacenamiento-a-nivel-de-bloque-fichero-y-objeto","title":"Almacenamiento a nivel de Bloque, Fichero y Objeto","text":"<p>Una diferencia clave entre algunos tipos de almacenamiento es saber si ofrecen almacenamiento en el nivel de bloque, a nivel de fichero o a nivel de objeto. </p> <p></p> <p>Esta diferencia tiene un gran impacto en el rendimiento, la latencia y el costo de la soluci\u00f3n de almacenamiento. Las soluciones de almacenamiento en bloque suelen ser m\u00e1s r\u00e1pidas y utilizan menos ancho de banda, pero pueden costar m\u00e1s que el almacenamiento en el nivel de objeto. Pero muchas veces la elecci\u00f3n vendr\u00e1 condicionada por el tipo de uso que deseamos hacer.</p> <p>Almacenamiento en bloque (Block Storage)</p> <ul> <li>Los datos se dividen en bloques de tama\u00f1o fijo (por ejemplo, 512 B o 4 KB).</li> <li>Cada bloque tiene una direcci\u00f3n, pero no contiene metadatos.</li> <li>El sistema operativo o la aplicaci\u00f3n se encarga de organizar los bloques (por ejemplo, mediante un sistema de archivos).</li> <li>Ejemplo t\u00edpico: Discos duros, SSD, vol\u00famenes de m\u00e1quinas virtuales (como los archivos .vdi de VirtualBox o como Amazon EBS).</li> </ul> <p>Almacenamiento de ficheros (File Storage)</p> <ul> <li>Los datos se organizan en un sistema de archivos jer\u00e1rquico (carpetas y subcarpetas).</li> <li>Los usuarios acceden a los archivos mediante rutas (por ejemplo, <code>/documentos/informe.pdf</code>).</li> <li>Se usa un protocolo de red como NFS (Linux/Unix) o SMB/CIFS (Windows) o Amazon EFS.</li> <li>Ejemplo t\u00edpico: Servidores NAS, carpetas compartidas en red.</li> </ul> <p>Almacenamiento de objetos (Object Storage)</p> <ul> <li>Los datos se almacenan como objetos completos, cada uno con:<ul> <li>El dato (contenido del archivo),</li> <li>Un identificador \u00fanico (ID o hash),</li> <li>Y metadatos personalizados.</li> </ul> </li> <li>No hay estructura jer\u00e1rquica: los objetos se guardan en \u201cbuckets\u201d (contenedores).</li> <li>Se accede normalmente mediante API HTTP/HTTPS (REST).</li> <li>Ejemplo t\u00edpico: Amazon S3, Azure Blob Storage, Google Cloud Storage.</li> </ul> <p></p> Caracter\u00edstica Bloques Ficheros Objetos Organizaci\u00f3n Bloques con direcci\u00f3n \u00c1rbol de carpetas y archivos Objetos con metadatos Acceso Bajo nivel (E/S directa) Ruta de archivo API o URL Protocolos comunes iSCSI, Fibre Channel NFS, SMB/CIFS HTTP/HTTPS (REST, S3 API) Usos t\u00edpicos Bases de datos, discos VM Servidores NAS, uso compartido Backups, multimedia, big data Ejemplos en AWS Amazon EBS Amazon EFS Amazon S3 <p>En este tema veremos los siguientes servicios de AWS:</p> <ul> <li>Amazon Simple Storage Service (Amazon S3) --&gt; Almacenamiento a nivel de Objetos</li> <li>Amazon Elastic Block Store (Amazon EBS) --&gt; Almacenamiento a nivel de Bloques</li> <li>Amazon Elastic File System (Amazon EFS) --&gt; Almacenamiento a nivel de Ficheros</li> <li>Amazon Simple Storage Service Glacier --&gt; Almacenamiento a nivel de Objetos</li> </ul>"},{"location":"ud04/ud04.html#amazon-s3","title":"Amazon S3","text":"<p>Amazon S3 (Simple Storage Service) es un servicio administrado de almacenamiento a nivel de objetos en la nube de AWS.</p> <p>Est\u00e1 dise\u00f1ado para ofrecer una alta durabilidad (11 nueves: 99,999999999%), escalabilidad autom\u00e1tica y baja latencia en el acceso a los datos.</p> <p>Sus caracter\u00edsticas principales son:</p> <ul> <li>Permite almacenar y gestionar objetos (archivos) de hasta 5 TB.</li> <li>Los objetos se guardan dentro de buckets, cuyos nombres deben ser \u00fanicos en todo Amazon S3.</li> <li>Por defecto, los datos se almacenan de forma redundante en m\u00faltiples instalaciones y dispositivos, sin que el usuario tenga que administrar servidores.</li> </ul> <p>Se puede almacenar cualquier tipo de archivo: im\u00e1genes, v\u00eddeos, registros, copias de seguridad o instant\u00e1neas de bases de datos.</p>"},{"location":"ud04/ud04.html#conceptos-basicos-de-amazon-s3","title":"Conceptos b\u00e1sicos de Amazon S3","text":"<p>Para utilizar Amazon S3, es importante entender algunos conceptos fundamentales:</p> <p>Buckets:</p> <ul> <li>Son contenedores l\u00f3gicos donde se almacenan los objetos (archivos).</li> <li>Cada bucket debe tener un nombre \u00fanico a nivel mundial.</li> <li>Se puede elegir la regi\u00f3n de AWS donde se almacenar\u00e1 el bucket (por ejemplo <code>us-east-1</code>).</li> <li>Se puede controlar el acceso a cada bucket (qui\u00e9n puede crear, eliminar o listar objetos).</li> <li>Permiten ver registros de acceso al bucket y a los objetos que contiene.</li> </ul> <p>Objetos:</p> <ul> <li>Los archivos almacenados en S3 se llaman objetos.</li> <li> <p>Un objeto est\u00e1 formado por:</p> <ul> <li>Datos (el contenido del archivo).</li> <li>Metadatos (informaci\u00f3n que lo describe, como permisos o URL).</li> </ul> </li> <li> <p>Se puede almacenar cualquier cantidad de objetos dentro de un bucket.</p> </li> <li>Al cargar un archivo, se pueden definir permisos y metadatos personalizados.</li> </ul> <p></p> <p>Cada bucket y objeto tiene una URL \u00fanica, aunque hay dos estilos de URL que pueden usarse para acceder a los objetos.</p> <p>Ejemplo: un archivo <code>video.mp4</code> dentro de un bucket tendr\u00e1 una URL con el nombre del bucket y del objeto.</p> <p></p>"},{"location":"ud04/ud04.html#situaciones-tipicas-de-uso-de-s3","title":"Situaciones t\u00edpicas de uso de S3","text":"<p>Aunque se puede almacenar cualquier tipo de dato, los casos de uso t\u00edpico de S3 suelen ser:</p> <ul> <li> <p>Copia de seguridad y almacenamiento: Se utiliza para guardar copias de seguridad y ofrecer servicios de almacenamiento de datos a terceros.</p> </li> <li> <p>Alojamiento de aplicaciones: Permite implementar, instalar y administrar aplicaciones web directamente desde la nube.</p> </li> <li> <p>Alojamiento multimedia: Ideal para crear infraestructuras redundantes, escalables y de alta disponibilidad que gestionen la carga y descarga de v\u00eddeos, im\u00e1genes o m\u00fasica.</p> </li> <li> <p>Entrega de software: Facilita el alojamiento de aplicaciones o instaladores para que los usuarios puedan descargarlos f\u00e1cilmente.</p> </li> </ul> <p></p>"},{"location":"ud04/ud04.html#control-de-acceso-en-amazon-s3","title":"Control de acceso en Amazon S3","text":"<p>Por defecto, todos los buckets de Amazon S3 son privados, y solo los usuarios con permisos expl\u00edcitos pueden acceder a ellos.</p> <p>Es fundamental gestionar correctamente los permisos y la seguridad de los datos almacenados. Para ello disponemos de varias herramientas de control de acceso. Las m\u00e1s importantes que utilizaremos ser\u00e1n:</p> <p>1. Bloqueo del acceso p\u00fablico:</p> <ul> <li>Impide que los buckets o los objetos sean accesibles p\u00fablicamente.</li> <li>Tiene prioridad sobre otras pol\u00edticas o permisos.</li> <li>Recomendado para evitar exposiciones accidentales de datos.</li> </ul> <p>2. Pol\u00edticas de IAM (Identity and Access Management):</p> <ul> <li>Permiten definir qu\u00e9 usuarios o roles pueden acceder a determinados buckets u objetos.</li> </ul> <p>3. Pol\u00edticas de bucket:</p> <ul> <li>Definen permisos espec\u00edficos sobre un bucket o sus objetos.</li> <li>\u00datiles cuando no se usa autenticaci\u00f3n mediante IAM.</li> <li>Pueden permitir acceso entre cuentas o incluso p\u00fablico/an\u00f3nimo, por lo que deben configurarse con cuidado.</li> <li>Pueden incluir enunciados de denegaci\u00f3n para restringir el acceso incluso si otros permisos lo permiten.</li> </ul> <p>4. Listas de control de acceso (ACL):</p> <ul> <li>M\u00e9todo antiguo, anterior a IAM.</li> <li>Se recomienda usarlo solo cuando sea necesario y evitando configuraciones demasiado permisivas.</li> </ul> <p></p> <p>La situaci\u00f3n del medio muestra una ocasi\u00f3n en que se ha desactivado la configuraci\u00f3n de seguridad de S3 y cualquiera puede acceder p\u00fablicamente a los objetos almacenados en el bucket, por ejemplo cuando alojamos un sitio web est\u00e1tico en un bucket S3. </p> <p>Atenci\u00f3n</p> <p>Usar un bucket de Amazon S3 para alojar un sitio web est\u00e1tico es una forma r\u00e1pida de configurar una arquitectura en AWS, pero en la mayor\u00eda de los casos no se recomienda otorgar acceso p\u00fablico. Normalmente, S3 se utiliza para almacenar datos que son accedidos por aplicaciones externas o para guardar informaci\u00f3n confidencial y copias de seguridad, por lo que los buckets deben mantenerse privados para garantizar la seguridad de los datos.</p>"},{"location":"ud04/ud04.html#amazon-ebs","title":"Amazon EBS","text":"<p>Amazon EBS ofrece vol\u00famenes de almacenamiento persistente en bloque para instancias de Amazon EC2, lo que significa que los datos se conservan incluso despu\u00e9s de apagar el sistema. </p> <p>Cada volumen se replica autom\u00e1ticamente dentro de una zona de disponibilidad, garantizando alta disponibilidad y durabilidad. Permite ajustar la capacidad r\u00e1pidamente (aumentar o reducir el tama\u00f1o en cuesti\u00f3n de minutos) y pagar solo por el almacenamiento aprovisionado.</p> <p>Los beneficios adicionales de EBS son la replicaci\u00f3n en la misma zona de disponibilidad, el cifrado f\u00e1cil y transparente, los vol\u00famenes el\u00e1sticos y las copias de seguridad mediante instant\u00e1neas.</p> <p>Importante</p> <ul> <li>Los vol\u00famenes EBS equivalen a los discos duros virtuales que utilizan las instancias EC2.</li> <li>Un volumen s\u00f3lo puede estar conectado a una instancia simult\u00e1neamente.</li> <li>Pero una instancia puede conectar varios vol\u00fames EBS simult\u00e1neamente.</li> </ul> <p></p> <p>Amazon EBS ofrece tres tipos de vol\u00famenes: </p> <ul> <li>SSD de uso general: Son unidades de estado s\u00f3lido (SSD) optimizadas para cargas de trabajo de transacciones que implican operaciones de lectura/escritura frecuentes de peque\u00f1o tama\u00f1o de E/S. Proporciona un equilibrio entre precio y rendimiento, y es el tipo recomendado para la mayor\u00eda de las cargas de trabajo. Los tipos existentes son gp3 (1.000 MiB/s) y gp2 (128-250 MiB/s) ambas con un m\u00e1ximo de 16.000 IOPS.</li> <li>SSD de IOPS provisionadas: proporciona un rendimiento elevado con cargas de trabajo cr\u00edticas, baja latencia o alto rendimiento. Los tipos existentes con io2 Block Express (4.000 MiB/s con un m\u00e1ximo 246.000 IOPS) e io2 (1.000 MiB/s con 64.000 IOPS).</li> <li>Magn\u00e9ticos (HDD): Son unidades de disco duro (HDD) optimizadas para grandes cargas de trabajo de streaming. Los tipos existentes con st1 (con 500 MiB/s y 500 IOPS) y sc1 (con 250 MiB/s y 250 IOPS).</li> </ul> <p>IOPS</p> <p>El t\u00e9rmino IOPS (operaciones de entrada y salida por segundo) representa una medida de rendimiento frecuente que se utiliza para comparar dispositivos de almacenamiento.  Cuantas m\u00e1s IOPS, mayor velocidad de acceso a los datos. En t\u00e9rminos habituales, un disco HDD ofrece entre 100 y 200 IOPS, un SSD SATA entre 5.000 y 100.000 IOPS, y un SSD NVMe puede superar el mill\u00f3n de IOPS. Estas cifras var\u00edan seg\u00fan el tipo de carga (lectura/escritura y secuencial/aleatoria).</p>"},{"location":"ud04/ud04.html#instantaneas","title":"Instant\u00e1neas","text":"<p>Para proporcionar un nivel a\u00fan mayor de durabilidad de los datos, Amazon EBS permite crear instant\u00e1neas a un momento dado de nuestros vol\u00famenes y volver a crear un volumen nuevo a partir de una instant\u00e1nea en cualquier momento.</p> <p>La primera instant\u00e1nea se denomina instant\u00e1nea de referencia. Cualquier otra instant\u00e1nea posterior a la de referencia captura solo lo que sea diferente de la instant\u00e1nea anterior.</p> <p>Las instant\u00e1neas se almacenan como objetos de Amazon S3.</p>"},{"location":"ud04/ud04.html#amazon-efs","title":"Amazon EFS","text":"<p>Amazon EFS (Elastic File System) es un servicio de almacenamiento de archivos compartido y el\u00e1stico ofrecido por AWS que funciona de manera similar a un NAS (Network Area Storage).</p> <p>Proporciona un sistema de archivos NFS (Network File System) accesible de forma simult\u00e1nea por m\u00faltiples instancias EC2 u otros servicios.</p> <p></p> <p>Sus caracter\u00edsticas principales son:</p> <ul> <li>Escalado autom\u00e1tico: ajusta su capacidad de almacenamiento autom\u00e1ticamente al a\u00f1adir o eliminar archivos.</li> <li>Alta disponibilidad y durabilidad: los datos se replican en varias zonas de disponibilidad (AZ) dentro de una regi\u00f3n.</li> <li>Acceso concurrente: permite que muchas instancias EC2 monten el mismo sistema de archivos al mismo tiempo.</li> <li>Compatibilidad con NFS v4/v4.1, lo que facilita la integraci\u00f3n con sistemas Linux.</li> <li>Pago por uso: se factura solo por la cantidad de datos almacenados (coste mayor por GB que EBS en algunos casos).</li> </ul> <p>Atenci\u00f3n</p> <p>EFS no se puede montar directamente en Windows (solo es compatible con NFS).</p>"},{"location":"ud04/ud04.html#ejemplos-de-uso-de-amazon-efs","title":"Ejemplos de uso de Amazon EFS","text":"<p>Servidores web con contenido compartido:</p> <p>Varios servidores Apache o Nginx montan el mismo EFS para compartir los archivos del sitio web:</p> <ul> <li>Ideal para configuraciones con balanceadores de carga (Elastic Load Balancer).</li> <li>Garantiza que todos los servidores sirvan el mismo contenido actualizado.</li> </ul> <p></p> <p>Almacenamiento de copias de seguridad:</p> <p>Centralizar copias de seguridad de varias instancias EC2 o contenedores.</p> <p>Permite mantener las copias accesibles desde cualquier servidor de la VPC.</p> <p></p> <p>Directorio de usuarios o home compartido:</p> <p>Los usuarios del sistema pueden tener sus directorios personales en EFS, accesibles desde varias m\u00e1quinas Linux.</p> <p></p> <p>Aplicaciones distribuidas:</p> <p>Aplicaciones que necesitan acceso simult\u00e1neo a los mismos archivos, por ejemplo:</p> <ul> <li>Procesamiento de im\u00e1genes o v\u00eddeos.</li> <li>Generaci\u00f3n de informes o resultados de c\u00e1lculo.</li> <li>Sistemas de gesti\u00f3n documental.</li> </ul> <p></p> <p>Almacenamiento para an\u00e1lisis o procesamiento de datos:</p> <p>Conjuntos de datos grandes que son procesados por m\u00faltiples nodos (Hadoop, Spark, etc.).</p> <p>EFS sirve como repositorio central para datos de entrada o resultados temporales.</p> <p></p> <p>Logs centralizados:</p> <p>Varias instancias EC2 pueden escribir sus archivos de logs en un mismo EFS.</p> <p>Facilita el an\u00e1lisis centralizado sin necesidad de configurar un servidor de logs. Ejemplo: <code>/mnt/efs/logs/app1/</code>, <code>/mnt/efs/logs/app2/</code></p> <p></p> <p>Compartir scripts, configuraciones o paquetes:</p> <p>Carpeta EFS con scripts comunes (bash, python, etc.) accesible por todos los servidores.</p> <p>Permite mantener entornos de despliegue uniformes.</p>"},{"location":"ud04/ud04.html#amazon-s3-glacier","title":"Amazon S3 Glacier","text":"<p>Amazon S3 Glacier es un servicio de almacenamiento en la nube de bajo coste dise\u00f1ado para archivar datos y realizar copias de seguridad a largo plazo. Forma parte de Amazon S3 y est\u00e1 pensado para informaci\u00f3n que no se necesita consultar con frecuencia, pero que debe conservarse de forma segura y duradera.</p> <p>Las caracter\u00edticas principales de este servicio son:</p> <ul> <li>Bajo coste: es mucho m\u00e1s econ\u00f3mico que las clases de almacenamiento est\u00e1ndar de S3, ideal para datos que se acceden rara vez.</li> <li>Alta durabilidad: ofrece los mismos once nueves (99,999999999%) de durabilidad que el resto de S3.</li> <li>Seguridad: admite cifrado autom\u00e1tico y control de acceso mediante pol\u00edticas de IAM y de bucket.</li> <li> <p>Recuperaci\u00f3n flexible: los datos pueden recuperarse en diferentes velocidades seg\u00fan la urgencia:</p> <ul> <li>Expedited (r\u00e1pida): segundos o minutos.</li> <li>Standard: unas pocas horas.</li> <li>Bulk (masiva): varias horas, m\u00e1s econ\u00f3mica.</li> </ul> </li> </ul>"},{"location":"ud04/ud04.html#versiones-o-clases-de-s3-glacier","title":"Versiones o clases de S3 Glacier","text":"<p>Amazon S3 incluye tres clases de almacenamiento Glacier, adaptadas a distintos usos:</p> <ol> <li>S3 Glacier Instant Retrieval: acceso casi inmediato (segundos), \u00fatil para archivos que se consultan ocasionalmente pero requieren un acceso instant\u00e1neo. Por ejemplo, historias m\u00e9dicas, archivos multimedia o documentos que se consultan espor\u00e1dicamente.</li> <li>S3 Glacier Flexible Retrieval (antes S3 Glacier): equilibrio entre coste y tiempo de recuperaci\u00f3n (minutos u horas). \u00datil para copias de seguridad, versiones antiguas de proyectos, o datos empresariales que se consultan solo en auditor\u00edas o revisiones anuales.</li> <li>S3 Glacier Deep Archive: la opci\u00f3n m\u00e1s barata, pensada para conservaci\u00f3n de datos a largo plazo (a\u00f1os), con tiempos de recuperaci\u00f3n de 12 a 48 horas. \u00datil en, por ejemplo, almacenamiento de facturas antiguas, archivos legales que han de guardarse durante a\u00f1os, copias de seguridad hist\u00f3ricas o registros que rara vez se necesitan.</li> </ol>"},{"location":"ud05/bdpractica01.html","title":"Bases de Datos RDS con acceso p\u00fablico","text":""},{"location":"ud05/bdpractica01.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica crearemos un servicio de BBDD totalmente gestionado sobre un motor MySQL al que accederemos directamente desde Internet.</p> <p>Peligro</p> <p>El acceso p\u00fablico a una BBDD est\u00e1 totalmente desaconsejado. Es una pr\u00e1ctica muy peligrosa permitir el acceso p\u00fablico a una base de datos, pero en esta pr\u00e1ctica lo haremos para poder conectarnos remotamente desde un cliente de base de datos. </p>"},{"location":"ud05/bdpractica01.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud05/bdpractica01.html#practica-a-realizar","title":"Pr\u00e1ctica a Realizar","text":""},{"location":"ud05/bdpractica01.html#creacion-de-la-base-de-datos-rds","title":"Creaci\u00f3n de la Base de Datos RDS","text":"<p>1.-  Accedemos a la consola, dentro de la categor\u00eda Bases de Datos, seleccionamos el recurso Aurora and RDS.</p> <p>Nota</p> <p>RDS permite hasta 6 motores de BBDD distintos. En esta pr\u00e1ctica, el servicio gestionado de BBDD que vamos a utilizar es RDS basado en MySQL, que permite ejecutar bases de datos MySQL.</p> <p></p> <p>2.- Creamos una Base de Datos:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos MySQL.</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Entorno de pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Disponibilidad Implementaci\u00f3n de una instanciade base de datos de zona de disponibilidad \u00fanica (1 instancia)</li> <li>Ponemos un nombre de servidor que debe ser \u00fanico en nuestra cuenta de AWS. Introduce uno que lleve tu nombre o iniciales.</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a.</li> <li>Dejamos las opciones por defecto del tama\u00f1o de la instancia y el almacenamiento.</li> <li>No vamos a conectar nuestra BBDD a ninguna instancia EC2, y dejamos la BBDD en la VPC por defecto (Default VPC).</li> <li>Importante: Permitimos el Acceso P\u00fablico a nuestra BBDD. Esto generar\u00e1 una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Creamos un nuevo grupo de seguridad, por ejemplo bbdd-sg</li> <li>Los dem\u00e1s campos los dejamos por defecto.</li> </ul> <p></p> <p>Nota</p> <p>Podr\u00edamos haber seleccionado el m\u00e9todo de creaci\u00f3n r\u00e1pida, que nos pide muchos menos par\u00e1metros para crear la BBDD, pero nos habr\u00eda dejado la opci\u00f3n de Permitir Acceso P\u00fablico como NO. Ello implica que nos tocar\u00eda acceder a modificar los par\u00e1metros una vez creada la BBDD para permitir ese acceso p\u00fablico, y adem\u00e1s deber\u00edamos permitir la regla de entrada correspondiente en el grupo de seguridad.  </p> <p>Atenci\u00f3n</p> <p>Cuando hemos creado el grupo de seguridad, si no modificamos nada, por defecto AWS permite el acceso a la BBDD desde una \u00fanica IP. Esto es importante tenerlo en cuenta. Si luego intentamos acceder desde otro equipo, o desde el mismo pero en otra red (cambia nuestra IP P\u00fablica), no podremos conectarnos.</p> <p></p> <p>3.- Una vez creado el recurso accedemos a \u00e9l y en el apartado Conectividad y seguridad comprobamos el endpoint y el puerto por al cual accederemos. Copiamos el punto de enlace en el portapapeles.</p> <p>Comprobamos tambi\u00e9n que se nos ha asociado el nuevo grupo de seguridad que hemos creado.</p> <p></p> <p> </p> <p>4.- En el apartado de Configuraci\u00f3n nos aparecen los datos de la configuraci\u00f3n de la m\u00e1quina virtual sobre la que est\u00e1 corriendo nuestro SGBD, as\u00ed como la versi\u00f3n de MySQL instalada y el nombre del usuario administrador.</p> <p></p> <p>5.- Volvemos al apartado de Conectividad y seguridad y accedemos al grupo de seguridad bbdd-sg que se nos ha creado para ver las reglas de firewall que nos ha puesto por defecto. En las reglas de entrada comprobamos que se ha creado la regla para permitir conexiones desde nuestra IP local a la BBDD por el puerto de MySQL (3306).</p> <p></p> <p> </p>"},{"location":"ud05/bdpractica01.html#conexion-a-la-bbdd","title":"Conexi\u00f3n a la BBDD","text":"<p>6.- En nuestra m\u00e1quina local establacemos una conexi\u00f3n mediante un cliente de MySQL de l\u00ednea de comandos, indicando la cadena de conexi\u00f3n y el usuario que hemos definido como administrador. En el par\u00e1metro host <code>-h</code> ponemos el nombre del servidor (endpoint que hemos copiado en el portapapeles) y en el par\u00e1metro de usuario <code>-u</code> el nombre del usuario. Para que nos solicite el password indicamos el par\u00e1metro <code>-p</code>.</p> <p><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p</code></p> <p>Una vez comprobada la conexi\u00f3n, cerramos la sesi\u00f3n:</p> <p><code>exit;</code></p> <p>Atenci\u00f3n</p> <p>Si hemos dejado la opci\u00f3n de Permitir Acceso P\u00fablico como NO o no aparece la regla de seguridad del firewall (grupo de seguridad) no podremos conectarnos.</p> <p></p> <p>7.- Vamos a crear una base de datos con una tabla. Lo vamos a hacer mediante un script de sentencias sql. Para ello comenzamos con la descarga del fichero de creaci\u00f3n de la base de datos.</p> <p>Descarga fichero sql</p> <p>8.- Ejecutamos las instrucciones SQL que hay en el contenido del fichero descargado. Basta con redireccionar la entrada del comando <code>mysql</code> con el fichero descargado de nombre <code>asir.sql</code>.</p> <pre><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p &lt; asir.sql\n</code></pre> <p></p> <p>9.- Comprobamos que se ha ejecutado correctamente y se ha creado la base de datos y la tabla correspondiente. Para ello volvemos a iniciar una conexi\u00f3n en el servidor MySQL y ejecutamos la consulta correspondiente:</p> <pre><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p\n</code></pre> <pre><code>use webasir;\nselect * from clientes;\nexit;\n</code></pre> <p></p> <p>Captura las pantallas</p> <p>Captura la pantalla de establecimiento de conexi\u00f3n a la base de datos.</p> <p>Captura la pantalla resultado de hacer la select de clientes.</p> <p>10.- Podemos establacer conexi\u00f3n remota tambi\u00e9n mediante clientes GUI como DBeaver, HeidiSQL, MySQL Workbench, ...</p> <p></p>"},{"location":"ud05/bdpractica01.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>11.- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. No crees ninguna instant\u00e1nea final ni conserves las copias de seguridad.</p> <p>Atenci\u00f3n</p> <p>Si detenemos un servidor de BBDD (sin eliminarlo), AWS lo iniciar\u00e1 autom\u00e1ticamente a los 7 d\u00edas (si no lo hemos levantado nosotros de manera manual antes). Esto es peligroso, pues si olvidamos eliminar un recurso de BBDD que no utilizamos, se pondr\u00e1 en marcha autom\u00e1ticamente a los 7 d\u00edas de haberlo detenido, con el consiguiente consumo de cr\u00e9dito.</p> <p></p>"},{"location":"ud05/bdpractica02.html","title":"Bases de Datos RDS sin acceso p\u00fablico","text":""},{"location":"ud05/bdpractica02.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En esta pr\u00e1ctica vamos a crear una base de datos RDS similar a la anterior, pero la vamos a ubicar en una subred privada de manera que no sea accesible desde Internet.</p> <p>En una subred p\u00fablica de la VPC crearemos una m\u00e1quina virtual accesible desde Internet y que s\u00ed que podr\u00e1 acceder a la base de datos. Este ser\u00eda un modelo t\u00edpico en el que tenemos un servidor (por ejemplo un servidor web) accesible desde Internet que ataca a una base de datos no accesible desde el exterior, aumentando as\u00ed la seguridad de nuestros datos necesarios para la aplicaci\u00f3n web.</p>"},{"location":"ud05/bdpractica02.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud05/bdpractica02.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud05/bdpractica02.html#creacion-de-la-vpc-y-la-maquina-ec2","title":"Creaci\u00f3n de la VPC y la m\u00e1quina EC2","text":"<p>1.- Creamos una nueva VPC con la siguientes caracter\u00edsticas:</p> <ul> <li>El bloque de CIDR ser\u00e1 10.0.0.0/16</li> <li>Debe tener 2 AZs.</li> <li>2 Subredes p\u00fablicas (10.0.1.0/24 y 10.0.2.0/24) cada una en una AZ.</li> <li>2 Subredes privadas (10.0.3.0/24 y 10.0.4.0/24) cada una en una AZ.</li> <li>No es necesario un Gateway NAT ni un Gateway de S3</li> </ul> <p>Nota</p> <p>Aunque no usemos Multi-AZ, AWS requiere al menos dos subredes privadas en diferentes AZ para RDS. Esto mejora la flexibilidad y disponibilidad, aunque la configuraci\u00f3n inicial sea simple.</p> <p></p> <p>2-  Vamos a crear una instancia EC2 en la primera subred p\u00fablica:</p> <ul> <li>La imagen ser\u00e1 la AMI de Ubuntu.</li> <li>El tama\u00f1o ser\u00e1 suficiente con un tipo de instancia t2.micro.</li> <li>El par de claves utilizaremos el del laboratorio (vockey).</li> <li>La ubicamos en la primera subred p\u00fablica (subnet-public1).</li> <li>Le asignamos una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Nos aseguramos que se crea una regla de firewall para permitir las conexiones por el puerto SSH (22).</li> <li>Para hacer que durante el primer lanzamiento de la instrancia se instale el cliente de MySQL ponemos las siguientes l\u00edneas en el apartado de Datos de usuario:</li> </ul> <pre><code>#!/bin/bash\napt update\napt install -y  mysql-client-core-8.0\n</code></pre> <p></p> <p>3-  Una vez creada la instancia EC2 comprobamos su IP p\u00fablica y nos conectamos por ssh desde nuestra m\u00e1quina local para comprobar que todo funciona.</p> <p></p>"},{"location":"ud05/bdpractica02.html#creacion-de-la-base-de-datos","title":"Creaci\u00f3n de la Base de Datos","text":"<p>El primer requisito para crear una base de datos RDS es definir un grupo de subredes de bases de datos en nuestra VPC.</p> <p>Info</p> <p>Un grupo de subredes de bases de datos es una colecci\u00f3n de subredes dentro de una VPC que RDS utiliza para desplegar instancias de bases de datos. Permite especificar en qu\u00e9 subredes y zonas de disponibilidad se pueden alojar las bases de datos. Es necesario que al menos contenga 2 AZ, por eso la necesidad de crear nuestra VPC con al menos 2 zonas de disponibilidad, aunque solamente utilicemos una.</p> <p>4-  Accedemos a la consola Aurora and RDS y creamos grupo de subredes con las 2 subredes privadas:</p> <ul> <li>Seleccionamos las 2 zonas de disponibilidad de nuestra VPC (en principio ser\u00e1n us-east-1a y us-east-1b).</li> <li>Seleccionamos las 2 subredes privadas (subnet-private1 y subnet-private2), puesto que deseamos crear nuestra base de datos dentro de una de las subredes privadas.</li> </ul> <p></p> <p></p> <p>5.- Ahora s\u00ed creamos una Base de Datos RDS:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos MySQL.</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Entorno de pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Ponemos un nombre para la instancia de base de datos que debe ser \u00fanico en nuestra cuenta de AWS. Pon el nombre bbddapellido, sustituye apellido por el tuyo</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a.</li> <li>Dejamos las opciones por defecto del tama\u00f1o de la instancia y el almacenamiento.</li> <li>En el apartado Conectividad:<ul> <li>Indicamos que vamos a conectar nuestra base de datos a una instancia EC2 y la seleccionamos en el desplegable.</li> <li>En el Grupo de subredes elegimos la existente que hemos creado en el punto anterior.</li> <li>NO permitimos el Acceso P\u00fablico a nuestra BBDD.</li> <li>Elegimos como grupo de seguridad, el existente por defecto. Nos informa que adem\u00e1s se crear\u00e1 un nuevo grupo de seguridad para conectar la instancia EC2 con la RDS.</li> </ul> </li> <li>Los dem\u00e1s campos los dejamos por defecto.</li> </ul> <p></p>"},{"location":"ud05/bdpractica02.html#conexion-a-la-base-de-datos-desde-la-maquina-ec2","title":"Conexi\u00f3n a la Base de Datos desde la m\u00e1quina EC2","text":"<p>6.- Iniciamos sesi\u00f3n desde la m\u00e1quina ubuntu y comprobamos que podemos conectarnos a la instancia MySQL, indicando la cadena de conexi\u00f3n y el usuario que hemos definido como administrador. En el par\u00e1metro host <code>-h</code> ponemos el nombre del servidor y en el par\u00e1metro de usuario <code>-u</code> el nombre del usuario. Para que nos solicite el password indicamos el par\u00e1metro <code>-p</code>.</p> <p><code>mysql -h bbddtema5p2.cwhda7oxrrck.us-east-1.rds.amazonaws.com -u admin -p</code></p> <p>Puedes encontrar el par\u00e1metro <code>-h</code> en la pesta\u00f1a de conectividad y seguridadde la base de datos.</p> <p></p> <p></p> <p>Captura las pantallas</p> <p>Captura la pantalla resumen de la base de datos que muestra el punto de enlace de la conexi\u00f3n.</p> <p>Captura la pantalla de establecimiento de conexi\u00f3n a la base de datos desde la m\u00e1quina ubuntu. </p> <p></p>"},{"location":"ud05/bdpractica02.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>Una vez comprobada la conexi\u00f3n, para finalizar la pr\u00e1ctica eliminamos los recursos creados.</p> <p>7- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. No crees ninguna instant\u00e1nea final ni conserves las copias de seguridad.</p> <p>Atenci\u00f3n</p> <p>Si detenemos un servidor de BBDD (sin eliminarlo), AWS lo iniciar\u00e1 autom\u00e1ticamente a los 7 d\u00edas (si no lo hemos levantado nosotros de manera manual antes). Esto es peligroso, pues si olvidamos eliminar un recurso de BBDD que no utilizamos, se pondr\u00e1 en marcha autom\u00e1ticamente a los 7 d\u00edas de haberlo detenido, con el consiguiente consumo de cr\u00e9dito.</p> <p></p> <p></p> <p>8- Desde la consola de AWS, elimina la instancia EC2.</p> <p></p> <p>9.- Desde la consola de AWS, elimina la VPC.</p>"},{"location":"ud05/bdpractica03.html","title":"Despliegue de un Cl\u00faster de Aurora","text":""},{"location":"ud05/bdpractica03.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>Vamos a crear un cl\u00faster de BBDD con Aurora en el que tendremos varias instancias: una primaria (escritora) y una o varias secundarias (lectoras). Esto nos dar\u00e1 una alta disponibilidad y un alto rendimiento.</p> <ul> <li>Alta disponibilidad: Al tener varias instancias y el almacenamiento compartido, implica que si uno de los nodos falla (incluso el principal) los dem\u00e1s siguen funcionando y dando servicio.</li> <li>Alto rendimiento: Al trabajar con varias instancias lectoras, las cargas de trabajo de las operaciones de lectura sobre la base de datos se reparte entre todas las instancias, trabajando en paralelo y mejorando el rendimiento.</li> </ul>"},{"location":"ud05/bdpractica03.html#elementos-principales-de-un-cluster-aurora","title":"Elementos principales de un cl\u00faster Aurora","text":"<p>1.- Almacenamiento compartido (Cluster Volume)</p> <ul> <li>Los datos no se guardan en cada instancia de la base de datos, sino en un volumen distribuido y replicado autom\u00e1ticamente en 3 AZs distintas dentro de la regi\u00f3n.</li> <li>Esto da alta disponibilidad y durabilidad (copias redundantes).</li> </ul> <p>2.- Instancia primaria (Writer)</p> <ul> <li>Es la que puede escribir en la base de datos.</li> <li>Maneja todas las operaciones de lectura y escritura.</li> </ul> <p>3.- Instancias de solo lectura (Readers)</p> <ul> <li>Opcionales, pero muy \u00fatiles.</li> <li>Solo aceptan lecturas, y puedes a\u00f1adir varias para escalar el rendimiento.</li> <li>El tr\u00e1fico de lectura se reparte con un endpoint de lecturas.</li> </ul> <p>4.- Endpoints del cl\u00faster</p> <ul> <li>Cluster endpoint (writer endpoint): apunta siempre a la instancia primaria.</li> <li>Reader endpoint: balancea las conexiones entre las r\u00e9plicas de lectura.</li> </ul> <p></p>"},{"location":"ud05/bdpractica03.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud05/bdpractica03.html#creacion-de-la-base-de-datos-aurora","title":"Creaci\u00f3n de la Base de Datos Aurora","text":"<p>1.-  Accedemos a la consola, dentro de la categor\u00eda Bases de Datos, seleccionamos el recurso Aurora and RDS.</p> <p>Nota</p> <p>Aurora permite hasta 2 motores de BBDD distintos: MySQL y PostgrSQL. En esta pr\u00e1ctica, utilizaremos el compatible con MySQL.</p> <p></p> <p>2.- Creamos una Base de Datos:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos Aurora (MySQL Compatible).</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Desarrollo y pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Ponemos un nombre de servidor que debe ser \u00fanico en nuestra cuenta de AWS. Introduce uno que lleve tu nombre o iniciales.</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a (Credenciales Autoadministrado).</li> <li>El Almacenamiento del cl\u00faster lo configuramos como Aurora Est\u00e1ndar.</li> <li>En la configuraci\u00f3n de la instancia seleccionamos Clases ampliables (incluye calses t), pues con el de Clases optimizadas para memoria no tendremos permisos de creaci\u00f3n en el laboratorio.</li> </ul> <p>Serverless</p> <p>La opci\u00f3n de crear un cluster Sin servidor (Serverless) ser\u00eda apropiada para los siguientes casos:</p> <ul> <li>Aplicaciones con carga variable o impredecible.</li> <li>Entornos de desarrollo o testing, donde la base de datos no est\u00e1 en uso todo el tiempo.</li> <li>APIs y microservicios que no necesitan una base de datos activa 24/7.</li> </ul> <p>Esta pr\u00e1ctica entrar\u00eda en uno de estos casos, pero en el laboratorio no tenemos permisos para crear este tipo de cl\u00fasters.</p> <ul> <li>Elegimos un tama\u00f1o de instancia db.t3.medium.</li> <li>En disponibilidad y durabilidad seleccionamos la opci\u00f3n de creaci\u00f3n de un nodo de lectura en una AZ diferente. De esta manera, haremos un despliegue MultiAZ. Tendremos una instancia de lectura en otra zona de disponibilidad (AZ), lo cual nos permite tener alta disponibilidad y una conmutaci\u00f3n por error alta. Es decir, si falla la instancia principal, esta r\u00e9plica ocupar\u00e1 su lugar en un tiempo reducido.</li> <li>Por simplificar, en conectividad selecionamos que No se conecte a una EC2. Ya sabemos que esto no es lo recomendable, pues no es seguro dejar expuesto el accedo a la base de datos desde Internet.</li> <li>Activamos la opci\u00f3n S\u00ed de Acceso P\u00fablico (insistimos en la peligrosidad de esta opci\u00f3n) y le ponemos nombre al nuevo grupo de seguridad: grupo-seguridad-acceso-aurora</li> <li>Desactivamos la Monitorizaci\u00f3n mejorada (por tema de permisos tambi\u00e9n).</li> <li>Creamos la base de datos.</li> <li>Ignoramos el mensaje de instalar Complementos sugeridos y esperamos a que se cree nuestro cl\u00faster Aurora.</li> </ul> <p>Atenci\u00f3n</p> <p>Cuando hemos creado el grupo de seguridad, si no modificamos nada, por defecto AWS permite el acceso a la BBDD desde una \u00fanica IP. Esto es importante tenerlo en cuenta. Si luego intentamos acceder desde otro equipo, o desde el mismo pero en otra red (cambia nuestra IP P\u00fablica), no podremos conectarnos.</p> <p></p>"},{"location":"ud05/bdpractica03.html#comprobacion-del-cluster","title":"Comprobaci\u00f3n del cl\u00faster","text":"<p>2.-  Una vez creado el cl\u00faster, comprobamos que se nos ha creado con 2 nodos (uno pricipal, escritor) y uno secundario (la r\u00e9plica lectora).</p> <ul> <li> <p>Accedemos al cl\u00faster y vemos que se nos han creado varios endpoints:</p> <ul> <li> <p>Dos endpoints al cl\u00faster:</p> <ul> <li>Writer Endpoint: Apunta siempre a la instancia primaria.</li> <li>Reader Endpoint: balancea las conexiones entre las r\u00e9plicas de lectura.</li> </ul> </li> <li> <p>Dos endpoints, uno por cada instancia:</p> <ul> <li>Endpoint a la instancia escritora.</li> <li>Endpoint a la instancia lectora.</li> </ul> </li> </ul> </li> </ul> <p>Tip</p> <p>Lo normal ser\u00e1 acceder a los endpoints del cluster, y no al de una instancia en concreto. </p> <p>Utilizaremos el Writer endpoint del cl\u00faster para operaciones de escritura y el Reader endpoint del cl\u00faster para operaciones de lectura, sin importarnos en qu\u00e9 instancia accederemos.</p> <p></p> <p></p>"},{"location":"ud05/bdpractica03.html#acceso-a-la-base-de-datos","title":"Acceso a la Base de Datos","text":"<p>3.- Copia el endpoint escritor del cluster y accede a \u00e9l desde tu m\u00e1quina local mediante <code>mysql</code>.</p> <pre><code>mysql -h database-jrpm.cluster-c5gac0s6ydn6.us-east-1.rds.amazonaws.com -u admin -p\n</code></pre> <p>Comprueba que puedes crear una base de datos:</p> <pre><code>create database pruebas;\n</code></pre> <p>4.- Cierra la sesi\u00f3n y con\u00e9ctate ahora utilizando el endpoint de lectura.</p> <ul> <li>Con\u00e9ctate al cl\u00faster para operaci\u00f3n de lecturas.</li> <li>Teclea <code>use pruebas;</code> y comprueba que podemos acceder sin problemas a la BBDD creada anteriormente.</li> <li>Prueba a crear una nueva BBDD usando el comando <code>create database</code>.</li> </ul> <p>Captura las pantallas</p> <p>Captura la pantalla en la que se vea la conexi\u00f3n al endpoint de lecturas, el acceso a la BBDD <code>pruebas</code> creada y el error al intentar crear una nueva BBDD.</p> <p></p>"},{"location":"ud05/bdpractica03.html#escalado-del-cluster","title":"Escalado del cl\u00faster","text":"<p>Sabemos que hay 2 tipos de escalado para las instancias en general: Vertical y Horizontal. En Aurora podemos escalar del mismo modo:</p> <ul> <li>Escalado Vertical: consiste en incrementar o decrementar la \u201cpotencia\u201d de la instancia (de la m\u00e1quina). Para escalar verticalmente una instancia de Amazon Aurora, tendr\u00edamos que seleccionarla y pulsar el bot\u00f3n Modificar. En la clase instancia seleccionar\u00edamos una de mayor (o de menor) capacidad.</li> <li>Escalado Horizontal: consiste en incrementar o decrementar el n\u00famero de r\u00e9plicas de lectura. Con un aumento de las instancias, conseguir\u00edamos una menor latencia debido al balanceo de la carga.</li> </ul> <p>5.- Vamos a a\u00f1adir una r\u00e9plica de lectura a nuestro cl\u00faster (escalado horizontal). Seleccionamos el cl\u00faster y en Acciones pulsamos sobre Agregar lector.</p> <ul> <li>Le ponemos un nombre y dejamos todas las dem\u00e1s opciones con su valor por defecto.</li> </ul> <p>Una vez creado el nuevo nodo (le cuesta unos minutos), veremos que nuestro cl\u00faster tiene una nueva instancia lectora sobre la que balancear las cargas de peticiones de lectura.</p> <p>Captura las pantallas</p> <p>Captura la pantalla en la que se vea el nuevo nodo de lectura en el cl\u00faster.</p> <p></p>"},{"location":"ud05/bdpractica03.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>Para finalizar la pr\u00e1ctica eliminamos los recursos creados.</p> <p>Peligro</p> <p>Este servicio consume mucho cr\u00e9dito. Aseg\u00farate de eliminarlo, pues incluso con el laboratorio apagado y la BBDD parada, sigue consumiendo cr\u00e9dito.</p> <p>8- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. </p> <p>Atenci\u00f3n</p> <p>Para eliminar la BBDD hay que eliminar primero las instancias que componen el cl\u00faster.</p> <p>Info</p> <p>Podemos optar por resetear el laboratorio (proceso costoso, pero s\u00f3lo hay que darle a un bot\u00f3n). Este proceso deja el laboratorio \"de f\u00e1brica\" pero no nos restablece el saldo.</p>"},{"location":"ud05/bdpractica04.html","title":"Bases de Datos NoSQL","text":""},{"location":"ud05/bdpractica04.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<p>En este ejercicio trabajar\u00e1s con una base de datos NoSQL</p>"},{"location":"ud05/bdpractica04.html#preparacion-cli","title":"PREPARACI\u00d3N CLI","text":"<p>Para comenzar esta pr\u00e1ctica, previamente es necesario tener instalada y configurada la interfaz de l\u00ednea de comandos de AWS</p> <p>A continuaci\u00f3n, se debe configurar la AWS CLI con las credenciales del AWS Academy Learner Lab. Para ello, desde la  consola del laboratorio, seleccionamos la opci\u00f3n AWS Details y a continuaci\u00f3n presionamos el bot\u00f3n Show en el apartado correspondiente a la AWS CLI.</p> <p>Como ya sabemos copiamos las credenciales al archivo credentials de aws</p>"},{"location":"ud05/bdpractica04.html#creacion-de-la-tabla-de-amazon-dynamo-db","title":"CREACI\u00d3N DE LA TABLA DE AMAZON DYNAMO DB","text":"<p>Para crear la tabla de Amazon DynamoDB de esta pr\u00e1ctica, accederemos a la consola de Amazon DynamoDB y, desde la opci\u00f3n Tables del men\u00fa lateral, presionamos el bot\u00f3n Create table:</p> <p></p> <p>(Mediante la consola de Administraci\u00f3n de AWS) En el asistente que aparece a continuaci\u00f3n, introduciremos el nombre de la tabla y los atributos que componen la clave primaria y sus correspondientes descriptores de tipos de datos, tal y como se indica a continuaci\u00f3n:</p> <ul> <li>Table name: curso</li> <li>Partition key: modulo (String)</li> <li>Sort key: alumno (String)</li> </ul> <p>El resto de las opciones las dejamos en sus valores por defecto y presionamos el bot\u00f3n Create table</p> <p></p> <p>Tras el proceso de creaci\u00f3n, podremos comprobar en la Consola de Administraci\u00f3n del servicio Amazon DynamoDB que nuestra tabla se ha creado correctamente</p> <p>Por \u00faltimo, vamos a poblar nuestra tabla de Amazon DynamoDB. Para ello ejecutamos el script que realizar\u00e1 tal funci\u00f3n:</p> <p>Descarga el scrip cargar-datos.sh y el archivo .json con los items</p> <p>Descargar cargar datos </p> <p>Descargar items</p> <p>Ahora ejecuta el script que poblar\u00e1 la base de datos de aws con la informaci\u00f3n que tiene en el archivo items-1.json</p> <p><code>./cargar-datos.sh</code></p> <p>Tras esta operaci\u00f3n, podremos volver a la Consola de Administraci\u00f3n del servicio Amazon DynamoDB y, entrando en la tabla curso podremos acceder al enlace del men\u00fa lateral Explorar elementos, seleccionar la tabla curso. Aparecer\u00e1n todos los elementos a\u00f1adidos por el script lanzado:</p> <p></p> <p>La tabla creada contiene informaci\u00f3n simulada de calificaciones de alumnos en diferentes asignaturas.</p>"},{"location":"ud05/bdpractica04.html#manipulacion-de-amazon-dynamo-db","title":"MANIPULACI\u00d3N DE AMAZON DYNAMO DB","text":"<p>Amazon DynamoDB dispone de las siguientes operaciones para manipular los datos de una tabla:</p> <ul> <li>GetItem. Permite recuperar un \u00fanico elemento en una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>PutItem. Permite introducir un \u00fanico elemento en una tabla de Amazon DynamoDB, identificado por los atributos clave, o su sobreescritura si ya exist\u00eda.</li> <li>DeleteItem. Permite eliminar un \u00fanico elemento de una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>UpdateItem. Permite actualizar un \u00fanico elemento de una tabla de Amazon DynamoDB, identificado por los atributos clave.</li> <li>Query. Permite recuperar un conjunto de elementos que tengan el mismo valor en su campo clave de partici\u00f3n (o clave hash) de una tabla de Amazon DynamoDB</li> <li>Scan. Permite recuperar un conjunto de elementos de todas las particiones de una tabla de   Amazon DynamoDB</li> </ul> <p>Ahora vamos a realizar alg\u00fan ejemplo de manipulaci\u00f3n de datos sobre esta base de datos mediante aws cli</p>"},{"location":"ud05/bdpractica04.html#operacion-1-obtener-las-calificaciones-del-alumno-paco-pandereta-en-el-modulo-de-historia","title":"Operaci\u00f3n 1: Obtener las calificaciones del alumno Paco Pandereta en el m\u00f3dulo de Historia","text":"<p>Para saber el dato correspondiente al alumno, es necesario indicar en un documento JSON la informaci\u00f3n con los datos de la clave del alumno que se desea obtener, crearemos un documento json de nombre operacion1.json e insertaremos en \u00e9l el siguiente c\u00f3digo:</p> <pre><code>{\n\"modulo\": { \"S\": \"Historia\" },\n\"alumno\": { \"S\": \"Paco Pandereta\" }\n}\n</code></pre> <p>Para ejecutar la consulta desde la AWS CLI introducimos el siguiente comando:</p> <pre><code>aws dynamodb get-item --table-name curso --key file://operacion1.json --projection-expression \"nota\"\n</code></pre> <p>En el comando anterior, se ejecuta una orden GetItem, indic\u00e1ndose los siguientes par\u00e1metros: --table-name: Nombre de nuestra tabla, en este caso curso --key: Fichero donde se encuentra el documento JSON con la informaci\u00f3n de los atributos clave del elemento que se obtendr\u00e1 --projection-expression: Indica los atributos del elemento obtenido que se proyectar\u00e1n en el resultado de la consulta</p> <p>Como resultado, se obtendr\u00e1 un documento JSON con los datos solicitados:</p> <p></p>"},{"location":"ud05/bdpractica04.html#operacion-2-introducir-un-nuevo-elemento-en-la-tabla-para-un-alumno-llamado-miguel-cervantes-saavedra-que-cursa-el-modulo-de-programacion-y-ha-obtenido-un-10-de-nota","title":"Operaci\u00f3n 2: Introducir un nuevo elemento en la tabla para un alumno llamado Miguel Cervantes Saavedra, que cursa el m\u00f3dulo de Programaci\u00f3n y ha obtenido un 10 de nota","text":"<p>Para introducir el elemento correspondiente al alumno, es necesario indicar en un documento JSON que llamaremos operacion2 la siguiente informaci\u00f3n</p> <pre><code>{\n  \"modulo\": { \"S\": \"Programaci\u00f3n\" },\n  \"alumno\": { \"S\": \"Miguel Cervantes Saavedra\" },\n  \"nota\": { \"N\": \"10\" }\n}\n</code></pre> <p>y despu\u00e9s ejecutar el comando</p> <pre><code>aws dynamodb put-item --table-name curso --item file://operacion2.json\n</code></pre> <p></p>"},{"location":"ud05/bdpractica04.html#las-siguientes-operaciones-realizalas-tu","title":"Las siguientes operaciones realizalas t\u00fa:","text":"<p>Operaci\u00f3n 3: Eliminar el elemento correspondiente al alumno de nombre Rosa Mosqueta Lledo que cursa el m\u00f3dulo de Historia Operaci\u00f3n 4: Actualiza el elemento correspondiente de la tabla, asumiendo que el alumno Rafa Raqueta hay que cambiarle la nota vamos a ponerle un 9 Operaci\u00f3n 5: Obtener las notas y nombres de los alumnos que cursan el m\u00f3dulo de Deportes <code>&lt;br&gt;</code></p> <p>Entrega</p> <p>Contenido del .json y comando ejecutado para realizar las operaciones 3, 4 y 5 Captura las pantallas con el resultado de realizar cada una de las operaciones</p>"},{"location":"ud05/ud5.html","title":"Tema 5. Bases de Datos en AWS","text":""},{"location":"ud05/ud5.html#introduccion","title":"Introducci\u00f3n","text":"<p>Las bases de datos son el coraz\u00f3n de casi cualquier aplicaci\u00f3n moderna. Permiten almacenar, organizar y recuperar informaci\u00f3n de forma estructurada y segura, y ser\u00e1n por tanto un elemento importante de cualquier infraestructura inform\u00e1tica.</p> <p>Para trabajar con una base de datos en AWS podemos optar por 2 modelos diferenciados seg\u00fan sean IaaS o PaaS:</p> <ul> <li>En el primer caso, en un modelo de Infraestructura como Servicio, contratar\u00edamos la m\u00e1quina virtual, en una red virtual e instalar\u00edamos el SGBD que consider\u00e1ramos oportuno (MySQL, SQL Server, PostgrsSQL, \u2026). En este modelo gestionar\u00edamos nosotros toda la infraestructura.</li> <li>En el caso de optar por un modelo de Plataforma como Servicio, contratar\u00edamos directamente el servicio de base de datos, sin preocuparnos por gestionar la infraestructura que hay por debajo (m\u00e1quina, red, sistema operativo y sistema gestor de base de datos). Es lo que se conoce como un servicio gestionado. Las bases de datos gestionadas son servicios de base de datos en la nube en los que el proveedor se encarga de toda la administraci\u00f3n y mantenimiento, desde la instalaci\u00f3n y configuraci\u00f3n inicial hasta la escalabilidad, seguridad, copias de seguridad y actualizaciones.</li> </ul> <p>Servicios BBDD en AWS</p> <p>AWS ofrece varios servicios gestionados de Bases de Datos. Los m\u00e1s populares son:</p> <ul> <li>RDS: Es una base de datos relacional gestionada basada en MySQL, PostrgreSQL, MariaDB, Oracle, Aurora o Microsoft SQL Server.</li> <li>Amazon Aurora: Es un SGBD propio de AWS compatible con MySQL y PostgrSQL que ofrece mejores prestaciones que RDS.</li> <li>Amazon DynamoDB: En este caso se trata de una base de datos NoSQL que soporta modelos de datos clave-valor y documentos.</li> <li>Amazon Neptune: Base de datos de grafos.</li> <li>Amazon Redshift: Base de datos relacional para almacenes de datos de Big Data.</li> </ul> <p>En este tema nos vamos a centrar en los 3 primeros: RDS, Aurora y DynamoDB.</p>"},{"location":"ud05/ud5.html#tipos-de-bases-de-datos","title":"Tipos de bases de datos","text":""},{"location":"ud05/ud5.html#bases-de-datos-relacionales-sql","title":"Bases de datos relacionales (SQL)","text":"<p>Las bases de datos relacionales organizan la informaci\u00f3n en tablas compuestas por filas y columnas, donde los datos se relacionan entre s\u00ed mediante claves primarias y externa. Ejemplos de bases de datos relacionales son MySQL, PostgreSQL, MariaDB, Oracle o SQL Server.</p> <p>En AWS, el servicio que gestiona este tipo de bases de datos es Amazon RDS (Relational Database Service).</p>"},{"location":"ud05/ud5.html#bases-de-datos-nosql","title":"Bases de datos NoSQL","text":"<p>Cuando los datos no siguen un esquema fijo (por ejemplo, registros de usuarios, logs o cat\u00e1logos de productos con diferentes atributos), las bases de datos NoSQL ofrecen mayor flexibilidad y rendimiento.</p> <p>Una base de datos NoSQL es un sistema de almacenamiento de datos que no utiliza el modelo relacional tradicional. En lugar de tablas con filas y columnas, organiza la informaci\u00f3n en estructuras m\u00e1s flexibles como documentos, pares clave-valor, grafos o columnas. Est\u00e1 pensada para manejar grandes vol\u00famenes de datos, alta velocidad de acceso y escalabilidad horizontal, lo que la hace ideal para aplicaciones web, big data y tiempo real.</p> <p>En el caso concreto de DynamoDB, la base de datos NoSQL de AWS, se utiliza un esquema de par clave-valor. </p>"},{"location":"ud05/ud5.html#rds","title":"RDS","text":"<p>Amazon RDS (Relational Database Service) es un servicio administrado que configura y opera una base de datos relacional en la nube.</p> <p>El componente de creaci\u00f3n b\u00e1sico de Amazon RDS es la instancia de base de datos. Una instancia de base de datos es un entorno de base de datos aislado que puede contener varias bases de datos creadas por el usuario. Se puede acceder a ella mediante las mismas herramientas y aplicaciones que se utilizan con una instancia de base de datos independiente.</p> <p>Las instancias de base de datos y el almacenamiento difieren en cuanto a caracter\u00edsticas de rendimiento y precio, lo que le permite personalizar el rendimiento y el costo seg\u00fan las necesidades de la base de datos. Al crear una instancia de base de datos, primero se debe especificar qu\u00e9 motor de base de datos se va a ejecutar. </p> <p>Amazon RDS admite actualmente seis bases de datos: </p> Motor Caracter\u00edsticas Casos de uso MariaDB Open source, compatible con MySQL, alto rendimiento Aplicaciones web, CMS como WordPress MySQL Amplio soporte y comunidad, ideal para proyectos peque\u00f1os y medianos Aplicaciones de comercio electr\u00f3nico o SaaS PostgreSQL Robusto, con soporte para JSON, funciones avanzadas Aplicaciones empresariales y anal\u00edticas Amazon Aurora Compatible con MySQL y PostgreSQL, optimizado por AWS Aplicaciones cr\u00edticas que requieren alta disponibilidad Otros (Oracle, SQL Server) Integraci\u00f3n empresarial, soporte para procedimientos almacenados ERP, CRM, entornos corporativos"},{"location":"ud05/ud5.html#caso-tipico-de-rds-en-una-vpc","title":"Caso t\u00edpico de RDS en una VPC","text":"<p>Un caso sencillo de uso de una instancia RDS es el ubicarla en una subred de nuestra VPC para que sea accesible \u00fanicamente por servicios de nuestra propia VPC (por ejemplo, una instancia EC2 con un servidor web) y no accesible directamente desde el exterior.</p> <p></p>"},{"location":"ud05/ud5.html#alta-disponibilidad","title":"Alta disponibilidad","text":"<p>Una de las funciones m\u00e1s potentes de Amazon RDS es la posibilidad de configurar la instancia de base de datos para una alta disponibilidad con un despliegue Multi-AZ. Amazon RDS genera autom\u00e1ticamente una copia en espera de la instancia de base de datos en otra zona de disponibilidad de la misma VPC. Tras propagar la copia de la base de datos, las transacciones se replican de forma s\u00edncrona en la copia en espera.</p> <p>Replicaci\u00f3n s\u00edncrona y as\u00edncrona</p> <p>Replicaci\u00f3n s\u00edncrona:</p> <ul> <li>La escritura se confirma solo cuando los datos se guardan en todas las zonas.</li> <li>Garantiza que todas las r\u00e9plicas est\u00e9n actualizadas al instante.</li> <li>Ventaja: m\u00e1xima consistencia de datos.</li> <li>Inconveniente: puede tener m\u00e1s latencia porque espera la confirmaci\u00f3n de la r\u00e9plica.</li> </ul> <p>Replicaci\u00f3n as\u00edncrona: </p> <ul> <li>La escritura se confirma solo en la zona principal, y las r\u00e9plicas se actualizan despu\u00e9s.</li> <li>Ventaja: mejor rendimiento y menor latencia.</li> <li>Inconveniente: si falla la zona principal, las r\u00e9plicas pueden quedar ligeramente desactualizadas.</li> </ul> <p>Esta configuraci\u00f3n protege las bases de datos contra errores de la instancia de base de datos e interrupciones de la zona de disponibilidad. </p> <p></p> <p>Si la instancia de base de datos principal falla en un despliegue Multi-AZ, Amazon RDS pone en l\u00ednea autom\u00e1ticamente la instancia de base de datos en espera como nueva instancia principal. Dado que las aplicaciones hacen referencia a la base de datos por su nombre mediante el punto de enlace del sistema de nombres de dominio (DNS), no es necesario cambiar nada en el c\u00f3digo de la aplicaci\u00f3n para utilizar la copia en espera para la conmutaci\u00f3n por error.</p>"},{"location":"ud05/ud5.html#replicas-de-lectura","title":"R\u00e9plicas de lectura","text":"<p>Amazon RDS tambi\u00e9n soporta la creaci\u00f3n de r\u00e9plicas de lectura. Las actualizaciones realizadas en la instancia de base de datos fuente se copian de forma as\u00edncrona en la instancia de r\u00e9plica de lectura. </p> <p>Se puede reducir la carga sobre la instancia de base de datos de origen por medio del enrutamiento de las consultas de lectura desde las aplicaciones a la r\u00e9plica de lectura. </p> <p>Las r\u00e9plicas de lectura permiten escalar horizontalmente y tambi\u00e9n por encima de las restricciones de capacidad de una instancia de base de datos \u00fanica para las cargas de trabajo de las bases de datos con operaciones intensivas de lectura. </p> <p>Las r\u00e9plicas de lectura tambi\u00e9n pueden promoverse para convertirse en la instancia de base de datos primaria, pero esto requiere una acci\u00f3n manual debido a la replicaci\u00f3n as\u00edncrona.</p> <p></p>"},{"location":"ud05/ud5.html#aurora","title":"Aurora","text":"<p>Amazon Aurora es un motor de base de datos relacional administrado, totalmente compatible con MySQL y PostgreSQL. Ofrece el rendimiento y la disponibilidad de las bases de datos comerciales (como Oracle o SQL Server), pero con un coste m\u00e1s reducido y la simplicidad de las bases de datos de c\u00f3digo abierto.</p> <p>Al estar desarrollado de forma nativa por Amazon, est\u00e1 dise\u00f1ado espec\u00edficamente para la nube y se adapta mejor en coste, rendimiento y alta disponibilidad. Est\u00e1 pensado como un subsistema de almacenamiento distribuido de alto rendimiento y tolerante a fallos:</p> <ul> <li>Los datos se replican autom\u00e1ticamente en tres zonas de disponibilidad (Multi-AZ), con hasta seis copias de cada bloque de datos.</li> <li>Esta replicaci\u00f3n es s\u00edncrona entre las zonas, garantizando alta consistencia y recuperaci\u00f3n autom\u00e1tica ante fallos.</li> <li>Adem\u00e1s, permite r\u00e9plicas de lectura (hasta 15) para escalar el rendimiento en aplicaciones con muchas consultas.</li> </ul> <p>Ofrece dos modelos, el cl\u00e1sico basado en instancias y un modelo serverless. </p> <p>Aurora Serverless es una modalidad muy interesante, ya que elimina la necesidad de aprovisionar capacidad de forma fija:</p> <ul> <li>Escala autom\u00e1ticamente el n\u00famero de recursos de c\u00f3mputo (CPU y memoria) seg\u00fan la carga de trabajo.</li> <li>Si no hay actividad, puede detenerse por completo, lo que reduce costes.</li> <li>Cuando vuelve a recibir peticiones, se reactiva autom\u00e1ticamente en pocos segundos.</li> <li>Es ideal para aplicaciones con uso intermitente, entornos de desarrollo o pruebas, y cargas variables o impredecibles.</li> </ul> <p>Aurora tambi\u00e9n realiza copias de seguridad continuas en Amazon S3, sin impacto en el rendimiento, y permite restaurar la base de datos a cualquier punto en el tiempo.</p>"},{"location":"ud05/ud5.html#dynamodb","title":"DynamoDB","text":"<p>DynamoDB es un servicio administrado de base de datos NoSQL muy r\u00e1pido y flexible:</p> <ul> <li>Base de datos NoSQL totalmente gestionada.</li> <li>Almacena datos en formato clave-valor o documento.</li> <li>Escala autom\u00e1ticamente en funci\u00f3n de la carga.</li> <li>Latencia baja (milisegundos) ideal para aplicaciones m\u00f3viles o IoT.</li> <li>Es muy flexible y sin estructura fija (los elementos pueden tener atributos diferentes).</li> </ul> <p>Ejemplo de uso</p> <p>Una aplicaci\u00f3n de videojuegos que almacena estad\u00edsticas de jugadores en tiempo real. DynamoDB gestiona millones de solicitudes sin necesidad de administrar servidores.</p> <p>En el caso concreto de DynamoDB, se utiliza un esquema de par clave-valor. Las bases de datos clave-valor funcionan como un gran diccionario o mapa asociativo, cada dato se guarda con una clave \u00fanica que sirve para identificarlo y recuperarlo:</p> <ul> <li>La clave act\u00faa como un identificador (por ejemplo, un n\u00famero o un nombre).</li> <li>El valor es el dato asociado (que puede ser texto, un objeto, un JSON, etc.).</li> </ul> <p>El acceso es muy r\u00e1pido porque el sistema busca directamente la clave sin recorrer estructuras complejas.</p> <p>Los componentes principales son:</p> <ul> <li>las tablas: son conjuntos de datos, formada por los elementos.</li> <li>los elementos: grupo de atributos que pueden identificar de forma exclusiva a un registro.</li> <li>los atributos: elementos de datos fundamental que no es preciso seguir dividiendo.</li> </ul> <p>DynamoDB soporta dos tipos de claves principales:</p> <ul> <li>La clave de partici\u00f3n es una clave principal simple.</li> <li>La clave de partici\u00f3n y de ordenamiento, tambi\u00e9n conocidas como clave principal compuesta, ya que est\u00e1 formada por dos atributos.</li> </ul> <p></p> <p>Ejemplo de una tabla denominada usuario:</p> Partition Key (clave primaria) Valor (atributos) <code>user_001</code> <code>{ \"nombre\": \"Ana\", \"email\": \"ana@example.com\", \"puntos\": 150 }</code> <code>user_002</code> <code>{ \"nombre\": \"Luis\", \"puntos\": 80 }</code> <code>user_003</code> <code>{ \"nombre\": \"Mar\u00eda\", \"email\": \"maria@example.com\", \"pais\": \"Espa\u00f1a\", \"suscripcion\": \"premium\" }</code> <code>user_004</code> <code>{ \"nombre\": \"Carlos\" }</code> <p>En este ejemplo todos los \u00edtems tienen una clave primaria \u00fanica (<code>user_001</code>, <code>user_002</code>, etc.).</p> <p>No todos los \u00edtems tienen los mismos campos. DynamoDB permite esto porque no requiere un esquema fijo, a diferencia de las bases de datos relacionales.</p> <p>Si hici\u00e9ramos una consulta sobre un item, se nos devolver\u00eda la siguiente informaci\u00f3n en formato json:</p> <pre><code>{\n  \"Item\": {\n    \"user_id\": {\"S\": \"user_003\"},\n    \"nombre\": {\"S\": \"Mar\u00eda\"},\n    \"email\": {\"S\": \"maria@example.com\"},\n    \"pais\": {\"S\": \"Espa\u00f1a\"},\n    \"suscripcion\": {\"S\": \"premium\"}\n  }\n}\n</code></pre>"},{"location":"ud05/ud5.html#seleccion-de-tecnologias-de-almacenamiento","title":"Selecci\u00f3n de tecnolog\u00edas de almacenamiento","text":"<p>La elecci\u00f3n del servicio adecuado depende de varios factores:</p> Requisito Servicio recomendado Motivo Aplicaci\u00f3n web tradicional RDS (MySQL o Aurora) Relacional, consistente, soporta SQL Aplicaci\u00f3n de IoT o juegos DynamoDB Escalabilidad y baja latencia Alta disponibilidad cr\u00edtica Aurora Multi-AZ R\u00e9plicas autom\u00e1ticas, resiliencia Coste bajo y simplicidad RDS con instancias peque\u00f1as Configuraci\u00f3n r\u00e1pida y gesti\u00f3n m\u00ednima"},{"location":"ud06/practica1.html","title":"Pr\u00e1ctica 1. Hello Lambda!","text":"<p>Creaci\u00f3n de una funci\u00f3n Lambda b\u00e1sica.</p>"},{"location":"ud06/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una funci\u00f3n Lambda desde cero y desplegarla.</li> <li>Conocer los dos objetos relacionados con las funciones: el objeto de evento y el objeto de contexto. </li> <li>Probar una funci\u00f3n.</li> <li>Ver los logs del resultado de la ejecuci\u00f3n de la funci\u00f3n.</li> <li>Crear un evento desencadenador de la funci\u00f3n.</li> </ul>"},{"location":"ud06/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica1.html#creacion-de-la-funcion-lambda","title":"Creaci\u00f3n de la funci\u00f3n lambda","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio Lambda.</p> <ul> <li>Pulsa en \u201cCrear funci\u00f3n.</li> <li> <p>Especifica:</p> <ul> <li>Crear desde cero.</li> <li>Nombre de la funci\u00f3n: debe ser \u00fanico en la regi\u00f3n (por ejemplo: <code>lambda-tusiniciales</code>).</li> <li>Versi\u00f3n ejecutable: especificamos el lenguaje de programaci\u00f3n que vamos a usar (Python 3.14)</li> <li>Rol de ejecuci\u00f3n predeterminado: Usar un rol existente (LabRole)</li> </ul> </li> <li> <p>Deja todos los dem\u00e1s campos por defecto.</p> </li> <li>Crea la funci\u00f3n pulsando \u201cCrear funci\u00f3n\u201d.</li> </ul>"},{"location":"ud06/practica1.html#modificacion-del-codigo-de-la-funcion","title":"Modificaci\u00f3n del c\u00f3digo de la funci\u00f3n","text":"<p>Una vez creada la funci\u00f3n, se nos muestra una consola en la que vemos, entre otras cosas:</p> <ul> <li>Un Diagrama (de momento est\u00e1 \u00fanicamente la funci\u00f3n, sin ning\u00fan desencadenador ni destino).</li> <li>Una pesta\u00f1a de C\u00f3digo: donde introduciremos el c\u00f3digo a ejecutar por nuestra funci\u00f3n.</li> <li>Una pesta\u00f1a de Probar el c\u00f3digo pas\u00e1ndole par\u00e1metros a la funci\u00f3n.</li> <li>Una pesta\u00f1a de Monitorear desde la que podremos acceder a la consola de CloudWacht para ver los logs de ejecuci\u00f3n.</li> </ul> <p></p> <p>2.- Sustituye el c\u00f3digo que aparece en el editor por el siguiente:</p> <pre><code>def lambda_handler(event, context):\n    print(\"Hola Lambda!\")\n    return \"Finalizado OK\"\n</code></pre> <p></p> <p>Estas 3 l\u00edneas significan lo siguiente:</p> <pre><code>def lambda_handler(event, context):\n</code></pre> <p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Define la funci\u00f3n principal que ejecutar\u00e1 AWS Lambda. Lambda siempre busca una funci\u00f3n con ese nombre.</p> <p> event: contiene los datos que llegan a la funci\u00f3n (por ejemplo, del API Gateway, S3, DynamoDB, etc.).</p> <p> context:contiene informaci\u00f3n sobre la ejecuci\u00f3n (tiempo restante, nombre de la funci\u00f3n, etc.).</p> <p></p> <pre><code>print(\"Hola Lambda!\")\n</code></pre> <p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Escribe un mensaje en los logs de CloudWatch. (Es \u00fatil para depurar.)</p> <p></p> <pre><code>return \"Finalizado OK\"\n</code></pre> <p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Devuelve una respuesta. Ese valor se env\u00eda al cliente (si la Lambda est\u00e1 detr\u00e1s de una API) o al servicio que la invoc\u00f3.</p> <p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0En este caso, devolver\u00e1 simplemente el texto \"Finalizado OK\".</p> <p>Nota</p> <p>El objeto event proporciona informaci\u00f3n acerca del evento que desencaden\u00f3 la funci\u00f3n de Lambda.</p> <p>El contenido del objeto de evento incluye todos los datos y metadatos que la funci\u00f3n de Lambda necesita. El contenido y la estructura del objeto de evento difieren seg\u00fan la fuente del evento que lo haya creado. Por ejemplo, un evento que crea API\u00a0Gateway tendr\u00e1 detalles relacionados con la solicitud HTTPS que realiz\u00f3 el cliente, como la ruta, la cadena de consulta y el cuerpo de la solicitud. Sin embargo, un evento creado por Amazon S3 incluye detalles sobre el bucket y el nuevo objeto.</p>"},{"location":"ud06/practica1.html#despliegue-de-la-funcion","title":"Despliegue de la funci\u00f3n","text":"<p>3.- Una vez hemos modificado el c\u00f3digo pulsamos sobre el bot\u00f3n Deploy para su despliegue. Desplegar no significa ejecutar, sino dejarlo listo para su ejecuci\u00f3n.</p> <p></p>"},{"location":"ud06/practica1.html#prueba-de-la-funcion","title":"Prueba de la funci\u00f3n","text":"<p>Es hora de probar nuestra funci\u00f3n. Para ejecutarla de prueba tenemos 2 opciones, pulsar sobre el bot\u00f3n Test (nos pedir\u00e1 un evento de test que a\u00fan no hemos creado) o ir a la pesta\u00f1a Probar desde donde podremos crear el evento de test y ejecutarlo.</p> <p>4.- Vamos a la pesta\u00f1a Probar que se encuentra entre C\u00f3digo y Monitorear.</p> <p>5.- Crea un evento de prueba nuevo. Ponle un nombre y deja los edm\u00e1s valores por defecto. </p> <p>Nos ha dejado unos valores por defecto en formato json para pas\u00e1rselos por par\u00e1metro. No los vamos a tocar. Lo veremos en la siguiente pr\u00e1ctica.</p> <p>6.- Pulsamos sobre el bot\u00f3n Probar</p> <p></p>"},{"location":"ud06/practica1.html#depuracion-de-la-funcion","title":"Depuraci\u00f3n de la funci\u00f3n","text":"<p>7.- Para ver el resultado de la ejecuci\u00f3n tenemos muchas opciones:</p> <ul> <li>Visualizar los detalles del mensaje emergente con el resultado de la ejecuci\u00f3n.</li> <li>Acceder a los registros de CloudWatch.</li> <li>Acceder a la pesta\u00f1a de Monitorear, que tambi\u00e9n nos lleva a Cloudwatch.</li> <li>Acceder de nuevo a la pesta\u00f1a de C\u00f3digo y ver el resultado de la salida (Output) justo debajo del c\u00f3digo.</li> </ul> <p>Nos interesa ver el valor devuelto por la funci\u00f3n: <code>Finalizado OK</code></p> <p>Y el mensaje de log que hemos introducido: <code>Hola Lambda!</code></p> <p></p> <p>Captura la pantalla</p> <p>Captura la pantalla como la del ejemplo en la que se vea el nombre de la funci\u00f3n, el valor devuelto y el mensaje en el log.</p>"},{"location":"ud06/practica2.html","title":"Pr\u00e1ctica 2. Funci\u00f3n Lambda con url de activaci\u00f3n","text":"<p>Creaci\u00f3n  de una funci\u00f3n Lambda y activaci\u00f3n mediante la invocaci\u00f3n de una url</p>"},{"location":"ud06/practica2.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una fnci\u00f3n Lambda desde cero.</li> <li>Activaci\u00f3n de la funci\u00f3n desde una url.</li> <li>Comprobaci\u00f3n de los logs de ejecuci\u00f3n.</li> </ul>"},{"location":"ud06/practica2.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica2.html#creacion-de-la-funcion","title":"Creaci\u00f3n de la funci\u00f3n","text":"<p>1.- Crea una nueva funci\u00f3n Lambda desde cero.</p> <ul> <li>Asigna un nombre de funci\u00f3n que contenga tus iniciales.</li> <li>El lenguaje de programaci\u00f3n ser\u00e1 Python 3.14</li> <li>El Rol de ejecuci\u00f3n ser\u00e1 LabRole.</li> <li>Deja los dem\u00e1s valores por defecto. <p>Podr\u00edamos asignar una url de activaci\u00f3n desde el apartado Configuraciones adicionales pero lo vamos a hacer una vez creada la funci\u00f3n.</p> </li> </ul>"},{"location":"ud06/practica2.html#modificacion-del-codigo-de-la-funcion","title":"Modificaci\u00f3n del c\u00f3digo de la funci\u00f3n","text":"<p>2.- Vamos a dejar el c\u00f3digo que nos propone por defecto pero modificando el mensaje de retorno de <code>\"Hello from Lambda!\"</code> por uno en el que aparezca tu nombre.</p> <pre><code>import json\n\ndef lambda_handler(event, context):\n    # TODO implement\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n</code></pre> <p>Esta funci\u00f3n \u00fanicamente devuelve un valor mediante el comando <code>return</code>. El valor que devuelve es un dicionario Python que contiene 2 claves:</p> <ul> <li><code>satusCode</code>: Un valor en el que se le puede indicar al evento que invoc\u00f3 la funci\u00f3n un c\u00f3digo de finalizaci\u00f3n de correcto o con error.</li> <li><code>body</code>: Un cuerpo que en este caso devuelve un texto (<code>Hello from Lambda!</code>) en formato json.</li> </ul> <p>3.- Haz un Deploy del c\u00f3digo para que est\u00e9 lista la funci\u00f3n para ser invocada.</p>"},{"location":"ud06/practica2.html#creacion-de-una-url-de-funcion","title":"Creaci\u00f3n de una url de funci\u00f3n","text":"<p>4.- Ve a la pesta\u00f1a de configuraci\u00f3n.</p> <p>5.- En el men\u00fa del panel lateral accede a URL de la funci\u00f3n.</p> <p>6.- Crea una nueva url de funci\u00f3n:</p> <ul> <li>El tipo de auorizaci\u00f3n ser\u00e1 NONE.</li> <li>Los dem\u00e1s campos por defecto.</li> </ul>"},{"location":"ud06/practica2.html#ejecucion-de-la-funcion","title":"Ejecuci\u00f3n de la funci\u00f3n","text":"<p>7.- Una vez creada la url asociada a la funci\u00f3n, \u00e1brela en un navegador y ver\u00e1s que se ejecuta y te muestra la respuesta devuelta por la funci\u00f3n en el comando <code>return</code>.</p> <p>8.- Si refrescas el navegador o vuelves a pinchar en el enlace, se volver\u00e1 a ejecutar la funci\u00f3n.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea en el navegador la url y el mensaje devuelto por tu funci\u00f3n.</p>"},{"location":"ud06/practica2.html#comprobacion-de-los-logs","title":"Comprobaci\u00f3n de los logs","text":"<p>9.- Ve a la pesta\u00f1a de Monitorear de la funci\u00f3n lambda.</p> <p>10.- Pulsa sobre Ver registros en CloudWatch.</p> <p>11.- Te aparecer\u00e1 un Flujo de registros por cada vez que se modifique la funci\u00f3n. Si entramos a examinarlos veremos que aparecen los logs de cada una de las veces que se ha ejecutado la funci\u00f3n Lambda. </p> <p>Nota</p> <p>Si hubi\u00e9ramos puesto alg\u00fan comando <code>print</code> en la funci\u00f3n, podr\u00edamos ver su salida en estos logs.</p>"},{"location":"ud06/practica3.html","title":"Pr\u00e1ctica 3. Funci\u00f3n Lambda con desencadenador","text":"<p>Creaci\u00f3n de una funci\u00f3n Lambda y activaci\u00f3n mediante un desencadenador.</p>"},{"location":"ud06/practica3.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear un desencadenador para una funci\u00f3n lambda para que se ejeucte cada minuto.</li> <li>Comprobaci\u00f3n de la ejecuci\u00f3n autom\u00e1tica de la funci\u00f3n.</li> </ul> <p>Desencadenadores</p> <p>Un desencadenador Lambda (o trigger) es un evento o servicio de AWS que autom\u00e1ticamente invoca una funci\u00f3n Lambda para ejecutar su c\u00f3digo. Este evento pueder ser una petici\u00f3n HTTP, una subida a S3, o un cambio en una base de datos DynamoDB o incluso una programaci\u00f3n de cron o planificaci\u00f3n temporal.</p>"},{"location":"ud06/practica3.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica3.html#creacion-del-desencadenador","title":"Creaci\u00f3n del desencadenador","text":"<p>1.- Vamos a utilizar la funci\u00f3n Lambda creada en la pr\u00e1ctica anterior. Accede a ella y en el Diagrama pulsa sobre Agregar desecandenador.</p> <ul> <li>En la configuraci\u00f3n del desencadenador eleccionamos el origen EventBridge (ColudWatch Events)</li> <li>Creamos una nueva regla:<ul> <li>Nombre: CadaMinuto</li> <li>Descripci\u00f3n: Evento a ejecutar cada minuto.</li> <li>Expresi\u00f3n de programaci\u00f3n: <code>rate(1 minute)</code></li> </ul> </li> </ul> <p>Info</p> <p>En la expresi\u00f3n de programaci\u00f3n se pueden utilizar expresiones de cron o expresiones de frecuencia (rate expression). Consulta la documentaci\u00f3n para ver c\u00f3mo utilizarla.</p> <p>A partir de este momento la funci\u00f3n ya se ejecutar\u00e1 autom\u00e1ticamente cada minuto.</p> <p></p>"},{"location":"ud06/practica3.html#comprobacion-de-los-logs","title":"Comprobaci\u00f3n de los logs","text":"<p>2.- Accede a los registros de CloudWatch para comprobar que la funci\u00f3n se est\u00e1 ejecutando cada minuto.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea en el diagrama de la funci\u00f3n que se ha a\u00f1adido un desencadenador de EventBridge.</p> <p></p>"},{"location":"ud06/practica3.html#eliminacion-del-desencadenador","title":"Eliminaci\u00f3n del desencadenador","text":"<p>3.- Para evitar que la funci\u00f3n est\u00e9 continuamente ejecut\u00e1ndose, accede a la pesta\u00f1a de Configuraci\u00f3n y en el panel lateral accede a Desencadenadores</p> <p>4.- Elimina el desencadenador.</p> <p>Atenci\u00f3n</p> <p>Es posible que no nos deje eliminar el desencadenador o que tras eliminarlo siga apareciendo en la consola. Es necesario elimnar tambi\u00e9n un permiso (Panel lateral --&gt; Permisos) asociado a una entidad principal llamada events.amazonaws.com para que deje de aparecer el desencadenador.</p>"},{"location":"ud06/practica4.html","title":"Pr\u00e1ctica 4. Funci\u00f3n Lambda con par\u00e1metros","text":"<p>Creaci\u00f3n de una funci\u00f3n Lambda que recibe par\u00e1metros en formato json.</p>"},{"location":"ud06/practica4.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una fnci\u00f3n Lambda desde cero que trabaje con par\u00e1metros recibidos.</li> <li>Paso de par\u00e1metros a la funci\u00f3n durante la llamada.</li> <li>Comprobaci\u00f3n de los logs de ejecuci\u00f3n.</li> </ul>"},{"location":"ud06/practica4.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica4.html#creacion-de-la-funcion","title":"Creaci\u00f3n de la funci\u00f3n","text":"<p>1.- Crea una nueva funci\u00f3n Lambda desde cero.</p> <ul> <li>Asigna un nombre de funci\u00f3n que contenga tus iniciales.</li> <li>El lenguaje de programaci\u00f3n ser\u00e1 Python 3.14</li> <li>El Rol de ejecuci\u00f3n ser\u00e1 LabRole.</li> <li>Deja los dem\u00e1s valores por defecto.</li> </ul>"},{"location":"ud06/practica4.html#modificacion-del-codigo-de-la-funcion","title":"Modificaci\u00f3n del c\u00f3digo de la funci\u00f3n","text":"<p>2.- Vamos a modificar el c\u00f3digo que nos propone por defecto por el siguiente:</p> <pre><code>import json\n\ndef lambda_handler(event, context):\n    # Imprimimos en la consola de logs el event recibido\n    print(\"Event recibido: \" + json.dumps(event, indent=2))\n\n    # Recuperamos los par\u00e1metros recibidos y los almacenamos en variables\n    nombre = event['key1']\n    apellido1 = event['key2']\n    apellido2 = event['key3']\n\n    # Imprimimos en la consola de logs los 3 par\u00e1metros recibidos\n    print(\"Nombre = \" + nombre)\n    print(\"Apellido 1 = \" + apellido1)\n    print(\"Apellido 2 = \" + apellido2)\n\n    # Construimos el valor a devolver como resultado de concatenarlos\n    resultado = f\"{apellido1} {apellido2}, {nombre}\"\n\n    # Devolvemos el string\n    return resultado\n</code></pre> <p>Esta funci\u00f3n imprime por la consola de logs los tres par\u00e1metros recibidos y devuelve mediante el comando <code>return</code> un nuevo campo con los 3 par\u00e1metros combinados. </p> <p>3.- Haz un Deploy del c\u00f3digo para que est\u00e9 lista la funci\u00f3n para ser invocada.</p>"},{"location":"ud06/practica4.html#prueba-de-la-funcion","title":"Prueba de la funci\u00f3n","text":"<p>4.- Ve a la pesta\u00f1a Probar y crea un evento de prueba:</p> <ul> <li>Pon el nombre que quieras.</li> <li>Utiliza la plantilla de Hello World</li> </ul> <p>Esta plantilla de test crea 3 par\u00e1metros llamados <code>key1</code>, <code>key2</code> y <code>key3</code> dentro de una cadena json.</p> <p>5.- Sustituye los valores por tu Nombre, Apellido 1 y Apellido 2.</p> <p>6.- Pulsa sobre Probar.</p>"},{"location":"ud06/practica4.html#comprobacion-de-los-logs","title":"Comprobaci\u00f3n de los logs","text":"<p>7.- Ve a la pesta\u00f1a de Monitorear de la funci\u00f3n lambda.</p> <p>8.- Pulsa sobre Ver registros en CloudWatch.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vean los mensajes que hemos mandado por la consola con <code>print</code> (objeto event y par\u00e1metros) al ejecutar la funci\u00f3n con el evento de prueba.</p>"},{"location":"ud06/practica5.html","title":"Pr\u00e1ctica 5. Funci\u00f3n Lambda con API Gateway","text":"<p>Creaci\u00f3n de una funci\u00f3n Lambda que recibe par\u00e1metros en formato json meidante la llamada a una API Gateway.</p>"},{"location":"ud06/practica5.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una fnci\u00f3n Lambda desde cero que trabaje con par\u00e1metros recibidos.</li> <li>Crear un API Gateway como desencadenador.</li> <li>Llamar a la funci\u00f3n desde una m\u00e1quina remota utilizando la llamada a la API.</li> <li>Comprobaci\u00f3n de los resultados devueltos por la funci\u00f3n.</li> </ul> <p>Descarga del software necesario</p> <p>Para probar el funcionamiento de la API es recomendable utilizar alg\u00fan software para depurar y probar APIs como puede ser Insomnia, Postman u otros similares. Puedes descargar Insomnia en https://insomnia.rest/ v\u00e1lido para Windows, Linux y Mac.</p>"},{"location":"ud06/practica5.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica5.html#modificacion-del-codigo","title":"Modificaci\u00f3n del c\u00f3digo","text":"<p>1.- Vamos a utilizar la funci\u00f3n Lambda creada en la pr\u00e1ctica anterior, pero vamos a modificar ligeramente el c\u00f3digo para obtener los par\u00e1metros, pues la forma de recibirlos cambiar\u00e1 al utilizar el API Gateway.</p> <pre><code>import json\n\ndef lambda_handler(event, context):\n    # Imprimimos en la consola de logs el event recibido\n    print(\"Event recibido: \" + json.dumps(event, indent=2))\n\n    # Recuperamos los par\u00e1metros recibidos y los almacenamos en variables\n    nombre = event['queryStringParameters']['key1']\n    apellido1 = event['queryStringParameters']['key2']\n    apellido2 = event['queryStringParameters']['key3']\n\n    # Imprimimos en la consola de logs los 3 par\u00e1metros recibidos\n    print(\"Nombre = \" + nombre)\n    print(\"Apellido 1 = \" + apellido1)\n    print(\"Apellido 2 = \" + apellido2)\n\n    # Construimos el valor a devolver como resultado de concatenarlos\n    resultado = f\"{apellido1} {apellido2}, {nombre}\"\n\n    # Devolvemos el string\n    return resultado\n</code></pre> <p>2.- Haz un Deploy</p>"},{"location":"ud06/practica5.html#creacion-del-desencadenador","title":"Creaci\u00f3n del desencadenador","text":"<p>3.- En el Diagrama pulsa sobre Agregar desecandenador.</p> <ul> <li>En la configuraci\u00f3n del desencadenador eleccionamos el origen API Gateway:<ul> <li>Crear una API Nueva.</li> <li>Tipo de API: API HTTP.</li> <li>Seguridad: Abrir.</li> </ul> </li> </ul> <p>Esto nos ha creado un nuevo servicio de API Gateway que podemos configurar sus rutas, permisos, controlar los logs, etc. No vamos a tocar nada.</p>"},{"location":"ud06/practica5.html#comprobacion-del-endpoint","title":"Comprobaci\u00f3n del endpoint","text":"<p>4.- Ve a la pesta\u00f1a Configurar y accede a la opci\u00f3n Desencadenadores,o pulsa directamente sobre API Gateway del Diagrama.</p> <p>5.- Copia el endpoint (punto de enlace) que aparece asociado a la API.</p>"},{"location":"ud06/practica5.html#ejecucion-de-la-api","title":"Ejecuci\u00f3n de la API","text":"<p>6.- Abre el programa Insomnia.</p> <p>7.- Pega la url del endpoint junto al comando GET que aparece. Si puls\u00e1ramos sobre el bot\u00f3n Send para invocar a la API nos devolver\u00eda un error puesto que nuestra funci\u00f3n est\u00e1 esperando unos par\u00e1metros que no le hemos pasado.</p> <p>8.- En el apartado de Query Parameters asigna 3 nuevos par\u00e1metros que se llamen como los que espera la funci\u00f3n: <code>key1</code>, <code>key2</code>, <code>key3</code>. Sus valores ser\u00e1n tu nombre, apellido1 y apellido2 respectivamente.</p> <p>9.- Pulsa ahora sobre el bot\u00f3n Send y comprueba que se ha ejecutado bien y el valor devuelto es el esperado.</p> <p>Captura la pantalla</p> <p>Captura la pantalla de Insomnia en la que se vea el paso de los par\u00e1metros y el resultado devuelto por la funci\u00f3n.</p>"},{"location":"ud06/practica6.html","title":"Pr\u00e1ctica 6. Funci\u00f3n Lambda con API Gateway y DynamoDB","text":"<p>Creaci\u00f3n de una API que hace operaciones de lectura y escritura en una Base de Datos DynamoDB.</p>"},{"location":"ud06/practica6.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una fnci\u00f3n Lambda que trabaje con par\u00e1metros recibidos y act\u00fae sobre una base de datos.</li> <li>Crear un API Gateway como desencadenador.</li> <li>Llamar a la funci\u00f3n desde una m\u00e1quina remota utilizando la llamada a la API.</li> <li>Hacer operaciones de lectura y escritura en una BBDD DynamoDB</li> </ul>"},{"location":"ud06/practica6.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud06/practica6.html#creacion-de-la-base-de-datos","title":"Creaci\u00f3n de la Base de Datos","text":"<p>1.- Accedemos al servicio DynamoDB y Creamos una tabla:</p> <ul> <li>El nombre de la tabla: meteo</li> <li>Clave de partici\u00f3n: sensor de tipo cadena</li> <li>Clave de ordenaci\u00f3n: timestamp de tipo cadena</li> </ul> <p>2.- Una vez creada la tabla, accedemos a ella y pulsamos sobre Explorar elementos.</p> <p>3.- Vamos a a\u00f1adir elementos de forma manual a la tabla. Para ello pulsamos sobre crear elementos e introducimos los siguientes elementos (agregando los atributos temperatura y humedad, ambos como tipo num\u00e9rico):</p> sensor (cadena) timestamp (cadena) temperatura (n\u00famero) humedad (n\u00famero) sensor01 2025-12-12T12:00:00+01:00 23.7 75 sensor02 2025-12-12T12:00:00+01:00 24.1 76 sensor01 2025-12-12T12:05:00+01:00 23.8 74 <p>Se pueden introducir los valores mediante cadenas json. El equivalente del primer registro ser\u00eda lo siguiente:</p> <pre><code>{\n  \"sensor\": {\n    \"S\": \"sensor01\"\n  },\n  \"timestamp\": {\n    \"S\": \"2025-12-12T12:00:00+01:00\"\n  },\n  \"temperatura\": {\n    \"N\": \"23.7\"\n  },\n  \"humedad\": {\n    \"N\": \"75\"\n  }\n}\n</code></pre>"},{"location":"ud06/practica6.html#creacion-de-la-funcion","title":"Creaci\u00f3n de la funci\u00f3n","text":"<p>4.- Crea una nueva funci\u00f3n Lambda, pero esta vez vamos a usar una plantilla predefinida. Para ello, pulsa sobre Usar un esquema.</p> <ul> <li>El esquema a utilizar ser\u00e1 Create a microservice that interacts with a DDB table usando como lenguaje python 3.12</li> <li>Asigna un nombre de funci\u00f3n que contenga tus iniciales.</li> <li>El Rol de ejecuci\u00f3n ser\u00e1 LabRole.</li> <li>Deja el c\u00f3digo sin modificar nada.</li> <li>Como desencadenador de API Gateway selecciona Crear una API nueva:<ul> <li>El tipo de API selecciona API de REST (la \u00faltima).</li> <li>Seguridad: Abrir</li> </ul> </li> </ul> <p>REST APIs vs HTTP APIs</p> <p>En esta ocasi\u00f3n vamos a utilizar un API Gateway de tipo REST API, que es m\u00e1s completo que la HTTP API. Est\u00e1 basada en la arquitectura RESTful y funciona con m\u00e9todos HTTP est\u00e1ndar: GET, POST, PUT, DELETE. </p>"},{"location":"ud06/practica6.html#despliegue-de-la-funcion","title":"Despliegue de la funci\u00f3n","text":"<p>5.- Vamos a dejar \u00edntegramente el c\u00f3digo que nos propone por defecto, sin modificar absolutamente nada. Este sencillo c\u00f3digo est\u00e1 optimizado para extraer el cuerpo del evento que recibe, y en base al m\u00e9todo que se le especifique en la llamada de la API (GET, POST, DELETE, PUT) hacer una operaci\u00f3n u otra sobre la tabla DynamoDB que se le pase.</p> <p>6.- Haz un Deploy (no es necesario).</p>"},{"location":"ud06/practica6.html#visualizacion-del-endpoint-de-la-api","title":"Visualizaci\u00f3n del endpoint de la API","text":"<p>7.- Accede al API Gateway y copia la url del endpoint.</p>"},{"location":"ud06/practica6.html#ejecucion-de-la-api-mediante-el-metodo-get","title":"Ejecuci\u00f3n de la API mediante el m\u00e9todo GET","text":"<p>Vamos a hacer una consulta a la tabla DynamoDB mediante la invocaci\u00f3n de nuestra funci\u00f3n Lambda. Para ello, hay que pasarle al c\u00f3digo de la funci\u00f3n que vamos a utilizar el m\u00e9todo GET y como par\u00e1metro el nombre de la tabla DynamoDb que hemos creado y sobre la que queremos hacer la consulta.</p> <p>8.- Abre el programa Insomnia.</p> <p>9.- Pega la url del endpoint junto al comando GET que aparece.</p> <p>10.- En el apartado de Parameters pon el siguiente par\u00e1metro:</p> <ul> <li>name: TableName</li> <li>value: meteo (nombre de la tabla DynamoDB)</li> </ul> <p>11.- Pulsa ahora sobre el bot\u00f3n Send y comprueba que se ha ejecutado la API y nos devuelve todos los valores introducidos en la tabla.</p>"},{"location":"ud06/practica6.html#ejecucion-de-la-api-mediante-el-metodo-post","title":"Ejecuci\u00f3n de la API mediante el m\u00e9todo POST","text":"<p>Vamos a hacer una inserci\u00f3n de elemento a la tabla DynamoDB mediante la invocaci\u00f3n de nuestra funci\u00f3n Lambda. Para ello, hay que pasarle al c\u00f3digo de la funci\u00f3n que vamos a utilizar el m\u00e9todo POST y en el cuerpo (body) del evento el nombre de la tabla DynamoDb que hemos creado y los datos del elemento que queremos insertar en formato json.</p> <p>12.- Selecciona ahora como m\u00e9todo de invocaci\u00f3n el m\u00e9todo POST</p> <p>13.- En el apartado de Parameters d\u00e9jalo en blanco, elimina el valor introducido anteriormente.</p> <p>14.- En el apartado Body selecciona que vamos a intriducir los datos en formato json y pega el siguiente c\u00f3digo que contiene el elemento a insertar y el nombre de la tabla:</p> <pre><code>{\n  \"TableName\": \"meteo\",\n  \"Item\": {\n    \"sensor\": { \"S\": \"sensor01\" },\n    \"temperatura\": { \"N\": \"24.9\" },\n    \"humedad\": { \"N\": \"78\" },\n    \"timestamp\": { \"S\": \"2025-12-12T12:10:00+01:00\" }\n  }\n}\n</code></pre> <p>15.- Env\u00eda el m\u00e9todo POST a nuestra API.</p> <p>Captura la pantalla</p> <p>Captura la pantalla de Insomnia en la que se vea el body y el status <code>200 OK</code> devuelto por la funci\u00f3n despu\u00e9s de insertar el elemento en la tabla de DynamoDB.</p>"},{"location":"ud06/ud06.html","title":"Tema 6. Microservicios y arquitecturas sin servidor","text":""},{"location":"ud06/ud06.html#arquitectura-de-microservicios","title":"Arquitectura de Microservicios","text":"<p>Los microservicios son un enfoque de arquitectura y organizaci\u00f3n para el desarrollo de software en el que las aplicaciones se componen de servicios independientes que se comunican mediante interfaces de programaci\u00f3n de aplicaciones (API) bien definidas. </p> <p>Se podr\u00eda decir que un microservicio es una peque\u00f1a aplicaci\u00f3n independiente, especializada en una \u00fanica funci\u00f3n del sistema (por ejemplo: autenticaci\u00f3n, pagos, notificaciones\u2026).</p> <p>Cada microservicio puede desarrollarse, desplegarse y escalarse de manera aut\u00f3noma.</p> <p></p>"},{"location":"ud06/ud06.html#caracteristicas-de-los-microservicios","title":"Caracter\u00edsticas de los microservicios","text":"<ul> <li>Desacoplamiento: Cada servicio funciona y evoluciona por separado.</li> <li>Especializaci\u00f3n: Cada uno cumple un prop\u00f3sito concreto.</li> <li>Mensajer\u00eda: Se comunican por APIs normalmente REST, WebSockets o colas.</li> <li>Escalabilidad independiente: Si un servicio recibe m\u00e1s carga, solo ese escala.</li> <li>Fallas aisladas: Un fallo en un servicio no debe tumbar a toda la aplicaci\u00f3n.</li> </ul>"},{"location":"ud06/ud06.html#como-implementar-microservicios-en-aws","title":"C\u00f3mo implementar microservicios en AWS","text":"<p>AWS ofrece varias herramientas para crear microservicios:</p> Servicio AWS Funci\u00f3n AWS Lambda Ejecuta c\u00f3digo sin servidor. Amazon ECS Ejecuta microservicios en contenedores (Docker). Amazon EKS Kubernetes gestionado para orquestaci\u00f3n compleja. AWS Fargate Ejecuta contenedores sin gestionar servidores. Amazon API Gateway Exponer APIs REST/HTTP/WS para los microservicios. <p>Nota</p> <p>En este tema nos vamos a centrar en el servicio AWS Lambda y veremos c\u00f3mo enlazarlo con API Gateway para crear mircroservicios.</p>"},{"location":"ud06/ud06.html#arquitectura-serverless","title":"Arquitectura Serverless","text":"<p>Aunque se conoce como arquitectura sin servidor, Serverless no significa que no haya servidores, sino que el desarrollador no gestiona la infraestructura.</p> <p>AWS se encarga de escalar, mantener y ejecutar el servicio bajo demanda.Por ejemplo, en el caso de AWS Lambda (ejecuci\u00f3n de funciones sin servidor), el usuario s\u00f3lo debe subir el c\u00f3digo y paga \u00fanicamente por ejecuci\u00f3n, no por servidores encendidos.</p>"},{"location":"ud06/ud06.html#componentes-tipicos-en-aws","title":"Componentes t\u00edpicos en AWS","text":"<p>Entre los servicios serverless m\u00e1s utilizados en AWS se encuentran:</p> Servicio AWS Uso AWS Lambda Ejecuta funciones bajo demanda sin servidores. Amazon API Gateway Exponer endpoints HTTP/REST/WS para ejecutar Lambdas. Amazon DynamoDB Base de datos NoSQL totalmente serverless. AWS S3 Almacenamiento serverless de objetos. <p>Pero no son los \u00fanicos, AWS tiene una gran cantidad de componentes que funcionan o pueden funcionar en modo serverless:</p> <p></p>"},{"location":"ud06/ud06.html#ventajas-y-desventajas-del-serverless","title":"Ventajas y desventajas del serverless","text":"<p>Entre las ventajas que encontramos al contratar servicios serverless tenemos:</p> <ul> <li>Cero administraci\u00f3n de servidores.</li> <li>Escalabilidad autom\u00e1tica.</li> <li>Pago por uso real (milisegundos).</li> <li>Alta disponibilidad por defecto.</li> <li>Despliegues m\u00e1s r\u00e1pidos y sencillos.</li> </ul> <p>Y como desventajas:</p> <ul> <li>Cold start en algunos lenguajes (tiempo para \u201cdespertar\u201d la funci\u00f3n).</li> <li>Sin control total sobre la infraestructura.</li> <li>Dependencia del proveedor.</li> <li>L\u00edmites en tiempo de ejecuci\u00f3n y memoria.</li> </ul>"},{"location":"ud06/ud06.html#aws-lambda","title":"AWS Lambda","text":"<p>AWS Lambda es un servicio serverless que permite ejecutar c\u00f3digo sin tener que gestionar servidores.</p> <p>Solo pagamos por el tiempo de ejecuci\u00f3n de nuestro c\u00f3digo, no por tener servidores encendidos y es ideal para tareas activadas por eventos.</p>"},{"location":"ud06/ud06.html#caracteristicas-principales","title":"Caracter\u00edsticas principales","text":"<ul> <li>Compatible con varios lenguajes: Python, Node.js, Java, C#, Go, etc.</li> <li>Escalado autom\u00e1tico: Si se reciben muchas solicitudes, Lambda crea instancias autom\u00e1ticamente.</li> <li>Basado en eventos: Puede ejecutarse al ocurrir eventos (S3, API Gateway, DynamoDB\u2026).</li> <li>Stateless: Cada ejecuci\u00f3n es independiente.</li> </ul>"},{"location":"ud06/ud06.html#funcionamiento-tipico","title":"Funcionamiento t\u00edpico","text":"<ol> <li>Evento disparador: Algo sucede (subida a S3, petici\u00f3n a API, cambio en DynamoDB\u2026).</li> <li>Lambda se ejecuta: Procesa el evento seg\u00fan el c\u00f3digo subido.</li> <li>Resultado: Puede guardar datos en DynamoDB, enviar un email, generar un archivo, un log \u2026</li> </ol>"},{"location":"ud06/ud06.html#ejemplos-de-uso","title":"Ejemplos de uso","text":"Ejemplo Disparador Acci\u00f3n de Lambda Procesar im\u00e1genes Archivo subido a S3 Redimensionar imagen y guardar versi\u00f3n miniatura API RESTful Petici\u00f3n POST a API Gateway Guardar datos en DynamoDB Notificaciones Evento de DynamoDB Enviar email con SNS Automatizaci\u00f3n de backups Evento programado (CloudWatch) Copiar archivos de un bucket a otro Logs en tiempo real Streams de CloudWatch Filtrar y enviar logs cr\u00edticos a Slack o S3"},{"location":"ud06/ud06.html#amazon-api-gateway","title":"Amazon API Gateway","text":"<p>Amazon API Gateway y AWS Lambda forman uno de los t\u00e1ndems m\u00e1s usados en AWS, especialmente en arquitecturas serverless.</p> <p>Se complementan para ofrecer APIs sin servidores, con escalado autom\u00e1tico y muy bajo coste.</p> <p>Pero, \u00bfqu\u00e9 es una API?</p> <p>Una API es un conjunto de reglas y protocolos que permite que diferentes aplicaciones o sistemas se comuniquen entre s\u00ed. Permite intercambiar datos o ejecutar funciones de otra aplicaci\u00f3n sin conocer su c\u00f3digo interno.</p> <p>Act\u00faa como un puente entre sistemas, ocultando la complejidad interna.</p> <p>Dependiendo de su uso, las APIs pueden ser:</p> <ul> <li>P\u00fablica / Abierta: Disponible para cualquier desarrollador. Ejemplos: API de Twitter, Google Maps</li> <li>Privada / Interna: Solo para uso interno de la empresa. Ejemplos: API interna de gesti\u00f3n de inventario</li> </ul> <p>Ejemplos de uso de APIs:</p> <ul> <li>Programamos una p\u00e1qina web en la que queremos mostrar informaci\u00f3n de pel\u00edculas  \u2192 llama a la API de OMDB pas\u00e1ndole el t\u00edtulo de la pel\u00edcula\u2192 recibe datos en JSON \u2192 muestra la informaci\u00f3n al usuario.</li> <li>App de m\u00f3vil quiere mostrar el clima \u2192 llama a la API de OpenWeather pas\u00e1ndole la ubicaci\u00f3n \u2192 recibe datos en JSON \u2192 muestra la informaci\u00f3n al usuario.</li> <li>App de m\u00f3vil quieresaber la latitud/longitud de una direcci\u00f3n \u2192 llama a la API de Google Maps pas\u00e1ndole la direcci\u00f3n \u2192 recibe datos en JSON \u2192 muestra las coordenadas al usuario.</li> </ul>"},{"location":"ud06/ud06.html#amazon-api-gateway_1","title":"Amazon API Gateway","text":"<p>Amazon API Gateway es un servicio gestionado que permite crear y publicar y mantener APIs a gran escala. Act\u00faa como punto de entrada para que las aplicaciones accedan a datos o l\u00f3gica del backend y permite crear APIs REST y WebSocket. </p> <p>No tiene coste inicial: se paga solo por las llamadas y los datos transferidos, con precios que bajan al aumentar el uso.</p> <p>Se puede utilizar API\u00a0Gateway con otros servicios administrados de AWS para crear backends sin servidor para las aplicaciones. Por ejemplo, API\u00a0Gateway puede enviar solicitudes a funciones de Lambda que ejecutan nuestro c\u00f3digo y generan respuestas. Incluso se pueden crear APIs que env\u00eden solicitudes a otros servicios de AWS, como Amazon\u00a0S3, sin tener que escribir c\u00f3digo.</p>"},{"location":"ud06/ud06.html#tipos-de-api-en-aws","title":"Tipos de API en AWS","text":"<p>AWS ofrece tres tipos de APIs seg\u00fan la forma en que necesitemos comunicar clientes y servicios. Cada una est\u00e1 dise\u00f1ada para un uso diferente.</p> <p>REST APIs</p> <ul> <li>APIs basadas en la arquitectura RESTful.</li> <li>Funcionan con m\u00e9todos HTTP est\u00e1ndar: GET, POST, PUT, DELETE.</li> <li>Dise\u00f1adas para recursos: /usuarios, /productos, /pedidos.</li> </ul> <p>HTTP APIs</p> <p>Son APIs m\u00e1s simples y m\u00e1s baratas que REST APIs, pero no tiene todas las funcionalidades avanzadas de REST API.</p> <p>Est\u00e1n pensadas para:</p> <ul> <li>Apps modernas basadas en Lambda o ECS/Fargate.</li> <li>Casos donde solo necesitamos endpoints HTTP r\u00e1pidos, sin reglas complejas.</li> </ul> <p>WebSocket APIs</p> <p>Son APIs dise\u00f1adas para comunicaci\u00f3n bidireccional en tiempo real.</p> <p>A diferencia de HTTP:</p> <ul> <li>La conexi\u00f3n permanece abierta.</li> <li>El servidor puede enviar mensajes al cliente cuando quiera.</li> <li>Ejemplos de uso: Chats, Notificaciones en tiempo real, juegos online...</li> </ul> <p>Funcionamiento:</p> <ul> <li>El cliente se conecta a la URL WebSocket.</li> <li>Mantiene la conexi\u00f3n abierta.</li> <li>Mensajes pueden ir cliente \u2192 servidor y servidor \u2192 cliente.</li> <li>Lambda suele procesar los mensajes entrantes y salientes.</li> </ul>"},{"location":"ud06/ud06.html#ejemplo-microservicio-con-restful","title":"Ejemplo: Microservicio con RESTful","text":"<p>Supongamos una arquitectura en la que los clientes pueden utilizar nuestro microservicio realizando llamadas HTTP API para, por ejemplo, guardar datos meteorol\u00f3gicos. </p> <p></p> <p>El siguiente ejemplo ser\u00eda una llamada t\u00edpica a una API (cuyo endpoint ser\u00eda <code>https://api.midominio.com/lecturas</code>) que desencadenar\u00eda una funci\u00f3n lambda para escribir los datos recibidos (sensor, timestamp, temperatura y humedad) en una base de datos (por ejemplo en DynamoDB).</p> <pre><code>curl -X POST \"https://api.midominio.com/lecturas\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"sensor\": \"sensor-01\",\n        \"timestamp\": \"2025-12-04T10:23:00Z\",\n        \"temperatura\": 22.5,\n        \"humedad\": 48\n      }'\n</code></pre>"},{"location":"ud07/practica1.html","title":"Practica1","text":"<p>Perfecto \ud83d\udd25 \u2014 te preparo una pr\u00e1ctica completa de laboratorio de AWS centrada en IAM, pol\u00edticas y roles, ideal para un entorno educativo (como el m\u00f3dulo de Implantaci\u00f3n de Sistemas Operativos del ciclo de ASIR).</p>"},{"location":"ud07/practica1.html#practica-creacion-y-aplicacion-de-politicas-y-roles-en-aws","title":"\ud83e\uddea Pr\u00e1ctica: Creaci\u00f3n y aplicaci\u00f3n de pol\u00edticas y roles en AWS","text":""},{"location":"ud07/practica1.html#objetivos","title":"\ud83c\udfaf Objetivos","text":"<ul> <li>Comprender c\u00f3mo funcionan las pol\u00edticas y los roles en AWS IAM.</li> <li>Crear y aplicar una pol\u00edtica personalizada.</li> <li>Asociar un rol a una instancia EC2 para controlar el acceso a S3 sin usar credenciales.</li> </ul>"},{"location":"ud07/practica1.html#1-preparacion-del-entorno","title":"\ud83e\udded 1\ufe0f\u20e3. Preparaci\u00f3n del entorno","text":"<ol> <li>Accede a la Consola de AWS.</li> <li>En el buscador superior, escribe IAM y entra al servicio.</li> <li>Verifica que est\u00e1s en la regi\u00f3n donde crear\u00e1s los recursos (por ejemplo, <code>eu-west-1</code>).</li> </ol>"},{"location":"ud07/practica1.html#2-creacion-de-una-politica-personalizada","title":"\ud83e\udde9 2\ufe0f\u20e3. Creaci\u00f3n de una pol\u00edtica personalizada","text":""},{"location":"ud07/practica1.html#objetivo","title":"\ud83d\udd38 Objetivo:","text":"<p>Permitir solo lectura de objetos dentro de un bucket S3 concreto.</p>"},{"location":"ud07/practica1.html#pasos","title":"\ud83d\udd38 Pasos:","text":"<ol> <li>En el panel lateral, selecciona Policies \u2192 Create policy.</li> <li>Elige la pesta\u00f1a JSON y pega lo siguiente:</li> </ol> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::asir-lab-bucket\",\n        \"arn:aws:s3:::asir-lab-bucket/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <ol> <li>Pulsa Next, asigna el nombre:    \ud83d\udc49 <code>LecturaS3Personalizada</code>    y una descripci\u00f3n breve.</li> <li>Crea la pol\u00edtica.</li> </ol> <p>\ud83d\udcd8 Consejo: sustituye <code>asir-lab-bucket</code> por el nombre real del bucket que usar\u00e1s.</p>"},{"location":"ud07/practica1.html#3-creacion-de-un-rol-con-permisos-controlados","title":"\ud83e\uddd1\u200d\ud83d\udcbb 3\ufe0f\u20e3. Creaci\u00f3n de un rol con permisos controlados","text":""},{"location":"ud07/practica1.html#objetivo_1","title":"\ud83d\udd38 Objetivo:","text":"<p>Permitir que una instancia EC2 lea objetos del bucket S3 usando el rol (sin claves de acceso).</p>"},{"location":"ud07/practica1.html#pasos_1","title":"\ud83d\udd38 Pasos:","text":"<ol> <li>En IAM \u2192 Roles \u2192 Create role.</li> <li>Selecciona AWS service \u2192 EC2, y haz clic en Next.</li> <li>Adjunta la pol\u00edtica reci\u00e9n creada LecturaS3Personalizada.</li> <li>Asigna nombre al rol:    \ud83d\udc49 <code>rol-ec2-lectura-s3</code>.</li> <li>Crea el rol.</li> </ol>"},{"location":"ud07/practica1.html#4-creacion-de-la-instancia-ec2","title":"\ud83d\udcbb 4\ufe0f\u20e3. Creaci\u00f3n de la instancia EC2","text":"<ol> <li>Ve al servicio EC2 \u2192 Instances \u2192 Launch instance.</li> <li> <p>Elige:</p> </li> <li> <p>AMI: Amazon Linux 2 o Ubuntu.</p> </li> <li>Tipo de instancia: <code>t2.micro</code>.</li> <li>En el apartado IAM role, selecciona rol-ec2-lectura-s3.</li> <li>Lanza la instancia.</li> </ol> <p>\ud83d\udca1 Este paso vincula la instancia con el rol IAM, otorg\u00e1ndole permisos temporales sin claves.</p>"},{"location":"ud07/practica1.html#5-verificacion-desde-la-instancia","title":"\ud83e\uddf0 5\ufe0f\u20e3. Verificaci\u00f3n desde la instancia","text":"<ol> <li>Con\u00e9ctate a la instancia mediante SSH.</li> </ol> <p><pre><code>ssh -i \"clave.pem\" ec2-user@&lt;IP-P\u00daBLICA&gt;\n</code></pre> 2. Instala la CLI de AWS (si no est\u00e1 instalada):</p> <p><pre><code>sudo yum install -y awscli\n</code></pre> 3. Comprueba el acceso al bucket:</p> <pre><code>aws s3 ls s3://asir-lab-bucket\n</code></pre> <p>\ud83d\udcd8 Si la pol\u00edtica est\u00e1 bien configurada, ver\u00e1s el listado de objetos. Si intentas subir un archivo, fallar\u00e1:</p> <pre><code>aws s3 cp test.txt s3://asir-lab-bucket/\n</code></pre> <p>\u2192 AccessDenied (porque la pol\u00edtica solo permite lectura).</p>"},{"location":"ud07/practica1.html#6-prueba-con-otro-rol-ampliacion-opcional","title":"\ud83d\udd10 6\ufe0f\u20e3. Prueba con otro rol (ampliaci\u00f3n opcional)","text":"<ol> <li>Crea una nueva pol\u00edtica llamada <code>EscrituraS3Personalizada</code>:</li> </ol> <p><pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:PutObject\"],\n      \"Resource\": [\"arn:aws:s3:::asir-lab-bucket/*\"]\n    }\n  ]\n}\n</code></pre> 2. Crea un nuevo rol rol-ec2-escritura-s3 y as\u00edgnale esa pol\u00edtica. 3. Cambia el rol de la instancia EC2:</p> <ul> <li>EC2 \u2192 Instancia \u2192 pesta\u00f1a Security \u2192 Modify IAM role.</li> <li>Selecciona <code>rol-ec2-escritura-s3</code>.</li> <li>Vuelve a probar el comando <code>aws s3 cp</code>.    \u2192 Esta vez deber\u00eda funcionar.</li> </ul>"},{"location":"ud07/practica1.html#7-limpieza-del-laboratorio","title":"\ud83d\udccb 7\ufe0f\u20e3. Limpieza del laboratorio","text":"<p>Para evitar costes:</p> <ol> <li>Det\u00e9n o elimina la instancia EC2.</li> <li>Elimina los roles creados.</li> <li>Elimina las pol\u00edticas personalizadas.</li> <li>Si creaste buckets, b\u00f3rralos si ya no los necesitas.</li> </ol>"},{"location":"ud07/practica1.html#conclusiones","title":"\ud83e\udde0 Conclusiones","text":"<ul> <li>Las pol\u00edticas IAM definen qu\u00e9 acciones se pueden realizar sobre qu\u00e9 recursos.</li> <li>Los roles permiten asignar permisos a servicios o identidades temporales sin usar credenciales.</li> <li>Las pol\u00edticas pueden ser muy espec\u00edficas, limitando el acceso a buckets, prefijos o acciones concretas.</li> <li>El modelo se basa siempre en el principio de m\u00ednimos privilegios.</li> </ul>"},{"location":"ud07/practica1_IAM.html","title":"Pr\u00e1ctica 1 \u2013 Control de Acceso con IAM y Pol\u00edticas","text":""},{"location":"ud07/practica1_IAM.html#objetivo","title":"Objetivo","text":"<p>Comprender usuarios, grupos, roles, pol\u00edticas y el principio de m\u00ednimos privilegios mediante un escenario realista.</p>"},{"location":"ud07/practica1_IAM.html#escenario","title":"Escenario","text":"<p>La empresa \"TechEdu\" quiere gestionar el acceso a materiales en un bucket S3:</p> <ul> <li>Profesores: lectura, subida y borrado.</li> <li>Alumnos: solo lectura.</li> <li>Invitados: sin acceso.</li> </ul> <p></p>"},{"location":"ud07/practica1_IAM.html#tareas","title":"Tareas","text":""},{"location":"ud07/practica1_IAM.html#1-crear-bucket-s3","title":"1. Crear bucket S3","text":"<ul> <li>Nombre: <code>techedu-material</code>.</li> <li>Bloquear acceso p\u00fablico.</li> </ul>"},{"location":"ud07/practica1_IAM.html#2-crear-grupos-iam","title":"2. Crear grupos IAM","text":"<ul> <li><code>Profesores</code></li> <li><code>Alumnos</code></li> </ul>"},{"location":"ud07/practica1_IAM.html#3-crear-usuarios","title":"3. Crear usuarios","text":"<ul> <li><code>profesor1</code> \u2192 Profesores</li> <li><code>alumno1</code> \u2192 Alumnos</li> <li><code>invitado1</code> \u2192 sin grupo</li> </ul>"},{"location":"ud07/practica1_IAM.html#4-crear-politicas-personalizadas","title":"4. Crear pol\u00edticas personalizadas","text":""},{"location":"ud07/practica1_IAM.html#profesores-acceso-completo-al-bucket","title":"Profesores (acceso completo al bucket):","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:*\"],\n      \"Resource\": [\n        \"arn:aws:s3:::techedu-material\",\n        \"arn:aws:s3:::techedu-material/*\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"ud07/practica1_IAM.html#alumnos-solo-lectura","title":"Alumnos (solo lectura):","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::techedu-material\",\n        \"arn:aws:s3:::techedu-material/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>Captura las pantallas</p> <p>Captura la pantalla donde se vea que <code>alumno1</code> puede leer pero no subir ni borrar. Captura la pantalla donde se vea que<code>profesor1</code> puede leer, subir y borrar. Captura la pantalla donde se vea que <code>invitado1</code> recibe Access Denied en todo.  </p>"},{"location":"ud07/practica2_seguridad.html","title":"Pr\u00e1ctica 2 \u2013 Seguridad en Red, Roles IAM y Auditor\u00eda","text":""},{"location":"ud07/practica2_seguridad.html#objetivo","title":"Objetivo","text":"<p>Crear una arquitectura segura con VPC, EC2, roles IAM y auditor\u00eda con CloudTrail.</p>"},{"location":"ud07/practica2_seguridad.html#escenario","title":"Escenario","text":"<p>La empresa \"NetSecure\" necesita:</p> <ul> <li>Una EC2 accesible solo por SSH desde la IP del estudiante.</li> <li>EC2 debe leer un bucket S3 usando IAM Roles.</li> <li>Registrar todas las acciones con CloudTrail.</li> </ul> <p></p>"},{"location":"ud07/practica2_seguridad.html#tareas","title":"Tareas","text":""},{"location":"ud07/practica2_seguridad.html#1-crear-vpc","title":"1. Crear VPC","text":"<ul> <li>Nombre: <code>netsecure-vpc</code></li> <li>CIDR: <code>10.0.0.0/16</code></li> </ul>"},{"location":"ud07/practica2_seguridad.html#2-crear-subnet-publica","title":"2. Crear subnet p\u00fablica","text":"<ul> <li>Nombre: <code>public-subnet-1</code></li> <li>CIDR: <code>10.0.1.0/24</code></li> </ul>"},{"location":"ud07/practica2_seguridad.html#3-crear-internet-gateway","title":"3. Crear Internet Gateway","text":"<ul> <li>Asociarlo a <code>netsecure-vpc</code>.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#4-crear-route-table-publica","title":"4. Crear Route Table p\u00fablica","text":"<ul> <li>Asociar a <code>public-subnet-1</code>.</li> <li>A\u00f1adir ruta a <code>0.0.0.0/0</code> \u2192 IGW.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#5-crear-security-group","title":"5. Crear Security Group","text":"<ul> <li>Nombre: <code>sg-ec2-netsecure</code>.</li> <li>Inbound: SSH desde \u201cMy IP\u201d.</li> <li>Outbound: permitir todo.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#6-crear-bucket-s3","title":"6. Crear bucket S3","text":"<ul> <li>Nombre: <code>netsecure-app-storage</code>.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#7-crear-rol-iam-para-ec2","title":"7. Crear rol IAM para EC2","text":"<ul> <li>Trusted entity: EC2.</li> <li>Pol\u00edtica: <code>AmazonS3ReadOnlyAccess</code>.</li> <li>Nombre: <code>EC2-S3-Role</code>.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#8-lanzar-ec2","title":"8. Lanzar EC2","text":"<ul> <li>Amazon Linux 2.</li> <li>Subnet: <code>public-subnet-1</code>.</li> <li>SG: <code>sg-ec2-netsecure</code>.</li> <li>Rol IAM: <code>EC2-S3-Role</code>.</li> </ul>"},{"location":"ud07/practica2_seguridad.html#9-acceder-por-ssh","title":"9. Acceder por SSH","text":"<pre><code>ssh -i clave.pem ec2-user@IP_PUBLICA\n</code></pre>"},{"location":"ud07/practica2_seguridad.html#10-verificar-acceso-a-s3-sin-claves","title":"10. Verificar acceso a S3 sin claves","text":"<p>En la EC2:</p> <pre><code>aws s3 ls s3://netsecure-app-storage\n</code></pre>"},{"location":"ud07/practica2_seguridad.html#11-activar-cloudtrail","title":"11. Activar CloudTrail","text":"<ul> <li>Crear trail <code>netsecure-trail</code>.</li> <li>Grabar logs en un nuevo bucket.</li> </ul> <p>Captura las pantallas</p> <p>Acceso por ssh a la EC2 Acceso a S3 sin claves Resultado de realizar acciones en IAM/EC2\" y observar eventos en CloudTrail \u2192 Event History  </p>"},{"location":"ud07/ud07.html","title":"Tema 7. Modelo de Seguridad de AWS","text":""},{"location":"ud07/ud07.html#modelo-de-seguridad-de-aws","title":"Modelo de Seguridad de AWS","text":"<p>El modelo de seguridad de AWS se basa en el principio de responsabilidad compartida: AWS asegura la infraestructura, y el cliente asegura los datos y la configuraci\u00f3n de sus servicios.</p>"},{"location":"ud07/ud07.html#responsabilidad-compartida","title":"Responsabilidad compartida","text":"Parte Qu\u00e9 asegura AWS Seguridad de la infraestructura f\u00edsica, hardware, redes, centros de datos y servicios gestionados. Cliente Configuraci\u00f3n de los servicios, control de acceso, cifrado de datos, seguridad de aplicaciones y sistemas operativos. <p>Ejemplo</p> <p>En EC2, AWS asegura el hardware y la red, pero nosotros debemos proteger nuestro sistema operativo, usuarios y aplicaciones.</p>"},{"location":"ud07/ud07.html#identidad-y-acceso-iam","title":"Identidad y acceso (IAM)","text":"<p>AWS gestiona la autenticaci\u00f3n y autorizaci\u00f3n mediante IAM (Identity and Access Management):</p> <ul> <li>Usuarios y grupos: cuentas dentro de la organizaci\u00f3n.</li> <li>Roles: permisos temporales para servicios o usuarios externos.</li> <li>Pol\u00edticas: reglas que definen qu\u00e9 acciones puede realizar un usuario o servicio sobre un recurso.</li> </ul>"},{"location":"ud07/ud07.html#cifrado-de-datos","title":"Cifrado de datos","text":"<p>AWS permite cifrar datos en reposo y en tr\u00e1nsito:</p> <ul> <li> <p>En reposo:</p> <ul> <li>S3, EBS, RDS y DynamoDB soportan cifrado con claves gestionadas por AWS ** o propias**.</li> </ul> </li> <li> <p>En tr\u00e1nsito:</p> <ul> <li>TLS/SSL para proteger la comunicaci\u00f3n entre servicios y clientes.</li> </ul> </li> </ul>"},{"location":"ud07/ud07.html#red-y-perimetro","title":"Red y per\u00edmetro","text":"<p>AWS protege la red mediante servicios y configuraciones:</p> <ul> <li>VPC (Virtual Private Cloud): redes privadas aisladas en la nube.</li> <li>Subredes, ACLs y Security Groups: control granular de tr\u00e1fico entrante y saliente.</li> <li>AWS Shield y WAF: protecci\u00f3n frente a ataques DDoS y filtrado de tr\u00e1fico web malicioso.</li> </ul>"},{"location":"ud07/ud07.html#monitorizacion-y-auditoria","title":"Monitorizaci\u00f3n y auditor\u00eda","text":"<ul> <li>CloudTrail: registro de todas las acciones de API realizadas en la cuenta.</li> <li>CloudWatch: monitorizaci\u00f3n de m\u00e9tricas y eventos de los recursos.</li> <li>GuardDuty: detecci\u00f3n de amenazas mediante an\u00e1lisis de logs y patrones sospechosos.</li> </ul>"},{"location":"ud07/ud07.html#cumplimiento-y-certificaciones","title":"Cumplimiento y certificaciones","text":"<p>AWS cumple con normas de seguridad y privacidad reconocidas internacionalmente.</p> <p>Esto permite que las empresas conf\u00eden en la infraestructura para aplicaciones cr\u00edticas y reguladas.</p>"},{"location":"ud07/ud07.html#aws-iam-identity-and-access-management","title":"AWS IAM (Identity and Access Management)","text":"<p>AWS Identity and Access Management (IAM) es el servicio de gesti\u00f3n de identidades y control de acceso de Amazon Web Services.</p> <p>Permite administrar de forma segura qui\u00e9n puede acceder a los recursos de AWS y qu\u00e9 acciones puede realizar.</p> <p>IAM es gratuito (no tiene coste adicional) y se integra en todos los servicios de AWS.</p> <p>Info</p> <p>Es un componente central del modelo de seguridad de AWS y se basa en el principio de m\u00ednimos privilegios: cada usuario o servicio solo debe tener los permisos estrictamente necesarios para realizar su tarea.</p>"},{"location":"ud07/ud07.html#usuario-grupos-roles-y-politicas","title":"Usuario, Grupos, Roles y Pol\u00edticas","text":"<p>IAM se organiza alrededor de identidades, pol\u00edticas y permisos.</p> <p>Usuarios</p> <p>Representan personas o aplicaciones que necesitan acceder a AWS.</p> <ul> <li>Tienen credenciales: nombre de usuario y contrase\u00f1a (para la consola web) o claves de acceso (para la CLI o APIs).</li> <li>Pueden a\u00f1adirse a grupos o recibir permisos directamente.</li> <li>Ejemplo: <code>usuario_admin</code>, <code>usuario_lectura</code>, <code>aplicacion_api</code>.</li> </ul> <p>Grupos</p> <p>Conjuntos l\u00f3gicos de usuarios con permisos comunes.</p> <ul> <li>Sirven para gestionar permisos de forma masiva.</li> <li>Ejemplo: grupo <code>Desarrolladores</code> con permisos sobre instancias EC2 y buckets S3.</li> </ul> <p>Roles</p> <p>Identidades sin credenciales propias, dise\u00f1adas para ser asumidas temporalmente por usuarios, servicios o recursos.</p> <ul> <li>Muy usados para otorgar permisos a servicios de AWS (como EC2 o Lambda) sin exponer claves.</li> <li>Ejemplo: una instancia EC2 que necesita leer un bucket S3 utiliza un rol IAM con ese permiso.</li> </ul> <p>Pol\u00edticas (Policies)</p> <p>Son documentos en formato JSON que definen los permisos.</p> <p>Las vemos con dentenimiento en el siguiente apratado.</p>"},{"location":"ud07/ud07.html#autorizacion-como-aws-decide-si-algo-esta-permitido","title":"Autorizaci\u00f3n: c\u00f3mo AWS decide si algo est\u00e1 permitido","text":"<p>Cada vez que un usuario o servicio hace una petici\u00f3n a AWS, IAM eval\u00faa todas las pol\u00edticas asociadas y aplica una l\u00f3gica de decisi\u00f3n:</p> <ol> <li>Por defecto todo est\u00e1 denegado.</li> <li>Si una pol\u00edtica permite la acci\u00f3n, pasa a estado permitido provisionalmente.</li> <li>Si alguna pol\u00edtica deniega expl\u00edcitamente una acci\u00f3n, la petici\u00f3n se bloquea siempre.</li> </ol> <p>Esto se conoce como el modelo Deny by default.</p>"},{"location":"ud07/ud07.html#roles-y-delegacion-de-permisos","title":"Roles y delegaci\u00f3n de permisos","text":"<p>Los roles IAM permiten delegar permisos de forma temporal y controlada. Se usan, por ejemplo, para:</p> <ul> <li>Permitir que una instancia EC2 acceda a un bucket S3 sin usar claves.</li> <li>Conceder permisos temporales a usuarios externos o cuentas de otra organizaci\u00f3n (cross-account roles).</li> <li>Autorizar a servicios de AWS (como Lambda o ECS) para actuar en nombre del usuario.</li> </ul> <p>Nota</p> <p>IAM es el coraz\u00f3n de la seguridad en AWS: controla qui\u00e9n entra, qu\u00e9 puede hacer y con qu\u00e9 recursos, garantizando una gesti\u00f3n centralizada, segura y flexible del acceso a la nube.</p>"},{"location":"ud07/ud07.html#politicas-de-iam-en-aws","title":"Pol\u00edticas de IAM en AWS","text":"<p>Las pol\u00edticas son documentos en formato JSON que definen los permisos que se conceden o deniegan a un usuario, grupo o rol en AWS.</p> <p>Es decir...</p> <p>Una pol\u00edtica indica qu\u00e9 acciones puede realizar un sujeto (usuario, grupo o rol) sobre qu\u00e9 recursos y bajo qu\u00e9 condiciones.</p> <p>Son el n\u00facleo del modelo de control de acceso en AWS: sin una pol\u00edtica asociada, ning\u00fan usuario o servicio tiene permisos.</p> <ul> <li> <p>Especifican:</p> <ul> <li>Acciones (<code>Action</code>): qu\u00e9 operaciones se permiten o deniegan.</li> <li>Recursos (<code>Resource</code>): sobre qu\u00e9 objetos se aplican.</li> <li>Efecto (<code>Effect</code>): <code>Allow</code> o <code>Deny</code>.</li> </ul> </li> </ul> <p>Cuando un usuario intenta realizar una acci\u00f3n, AWS eval\u00faa las pol\u00edticas siguiendo este orden:</p> <ol> <li>Denegaci\u00f3n expl\u00edcita (Deny) \u2192 siempre prevalece.</li> <li>Permiso expl\u00edcito (Allow) \u2192 concede acceso si no hay una denegaci\u00f3n previa.</li> <li>Por defecto, todo est\u00e1 denegado hasta que una pol\u00edtica lo permita.</li> </ol> <p>Regla de oro</p> <p>Si no hay una pol\u00edtica <code>Allow</code>, la acci\u00f3n no se ejecutar\u00e1.</p> <ul> <li>Ejemplo de pol\u00edtica simple:</li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:ListBucket\", \"s3:GetObject\"],\n      \"Resource\": [\"arn:aws:s3:::mi-bucket\", \"arn:aws:s3:::mi-bucket/*\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"ud07/ud07.html#tipos-de-politicas","title":"Tipos de pol\u00edticas","text":"<p>AWS ofrece varios tipos de pol\u00edticas, clasificadas seg\u00fan c\u00f3mo y d\u00f3nde se aplican:</p> Tipo de pol\u00edtica Descripci\u00f3n Ejemplo Administradas por AWS Pol\u00edticas predefinidas creadas y mantenidas por AWS. Simplifican la gesti\u00f3n y se actualizan autom\u00e1ticamente. <code>AmazonS3ReadOnlyAccess</code>, <code>AdministratorAccess</code> Administradas por el cliente Pol\u00edticas personalizadas creadas por el usuario para definir permisos espec\u00edficos. Pol\u00edtica que permite acceso de lectura a un bucket concreto. Inline (insertadas) Pol\u00edticas directamente incrustadas en un usuario, grupo o rol concreto. No son reutilizables. Pol\u00edtica personalizada dentro de un rol de EC2."},{"location":"ud07/ud07.html#estructura-y-sintaxis-de-una-politica-json","title":"Estructura y sintaxis de una pol\u00edtica (JSON)","text":"<p>Las pol\u00edticas de IAM siguen una estructura JSON con campos obligatorios y opcionales:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::mi-bucket\",\n        \"arn:aws:s3:::mi-bucket/*\"\n      ],\n      \"Condition\": {\n        \"IpAddress\": {\n          \"aws:SourceIp\": \"203.0.113.0/24\"\n        }\n      }\n    }\n  ]\n}\n</code></pre> <p>Desglose de los campos:</p> Campo Descripci\u00f3n Obligatorio Version Indica la versi\u00f3n del lenguaje de pol\u00edticas. Actualmente se usa <code>\"2012-10-17\"</code>. \u2705 Statement Lista de reglas que definen permisos. Puede contener una o varias. \u2705 Effect Determina si la acci\u00f3n se permite (<code>Allow</code>) o deniega (<code>Deny</code>). \u2705 Action Especifica las acciones de AWS que se permiten o deniegan (por ejemplo, <code>s3:PutObject</code>, <code>ec2:StartInstances</code>). \u2705 Resource Indica los recursos espec\u00edficos sobre los que se aplican los permisos, usando su ARN. \u2705 Condition Define condiciones opcionales (por IP, usuario, hora, MFA, etc.) que deben cumplirse para que se concedan los permisos. \u274c"},{"location":"ud07/ud07.html#ejemplo-practico-politica-personalizada","title":"Ejemplo pr\u00e1ctico: pol\u00edtica personalizada","text":"<p>Objetivo: Permitir a un usuario listar y leer objetos del bucket <code>iescamp-datos</code>, pero no borrarlos.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"LeerBucketIESCAMP\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:ListBucket\",\n        \"s3:GetObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::iescamp-datos\",\n        \"arn:aws:s3:::iescamp-datos/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>Sid (Statement ID): campo opcional para identificar el bloque de permisos.</p> <p>Los ARN (Amazon Resource Names) identifican de forma \u00fanica los recursos en AWS.</p> <p>Ejemplo de estructura:</p> <pre><code>arn:aws:servicio:regi\u00f3n:cuenta:recurso\n</code></pre> <p>Ejemplo para un bucket S3:</p> <pre><code>arn:aws:s3:::mi-bucket\narn:aws:s3:::mi-bucket/mis-archivos/*\n</code></pre>"},{"location":"ud08/practica1.html","title":"Pr\u00e1ctica 1. M\u00e9tricas EC2","text":"<p>An\u00e1lisis m\u00e9tricas EC2</p>"},{"location":"ud08/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Identificar las m\u00e9tricas b\u00e1sicas de una instancia EC2.</li> <li>Consultar m\u00e9tricas desde:<ul> <li>La pesta\u00f1a Monitoreo de EC2.</li> <li>El servicio Amazon CloudWatch.</li> </ul> </li> <li>Comprender la relaci\u00f3n entre EC2 y CloudWatch.</li> <li>Diferenciar entre monitorizaci\u00f3n b\u00e1sica y monitorizaci\u00f3n detallada.</li> </ul>"},{"location":"ud08/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud08/practica1.html#creacion-de-una-instancia-ec2","title":"Creaci\u00f3n de una instancia EC2","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio EC2. Lanza una nueva instancia:</p> <ul> <li>Ll\u00e1mala Servidor-Web</li> <li>La imagen ser\u00e1 la AMI de Ubuntu.</li> <li>El tama\u00f1o ser\u00e1 un tipo de instancia t3.micro.</li> <li>El par de claves utilizaremos el del laboratorio (vockey).</li> <li>Nos aseguramos que se asigna una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Nos aseguramos que se crea una regla de firewall para permitir las conexiones por el puerto SSH (22) y HTTP(80).</li> <li>Para hacer que durante el primer lanzamiento de la instancia se instale el servidor HTTP y se copie el repositorio hello-cloud ponemos las siguientes l\u00edneas en el apartado de Datos de usuario:</li> </ul> <pre><code>#!/bin/bash\napt update\napt install -y apache2\ngit clone https://github.com/IES-CAMP-DE-MORVEDRE/hello-cloud.git\ncp hello-cloud/* /var/www/html -R\n</code></pre> <p></p>"},{"location":"ud08/practica1.html#monitorizacion-desde-ec2-pestana-monitoreo","title":"Monitorizaci\u00f3n desde EC2 (pesta\u00f1a Monitoreo)","text":"<p>2.- Selecciona la instancia creada. Accede a la pesta\u00f1a Monitoreo y observa las m\u00e9tricas que vienen por defecto. Nos interesan:</p> <ul> <li>CPU Utilization</li> <li>Network In </li> <li>Network Out</li> </ul> <p>Pulsa sobre Administrar el monitoreo detallado para habilitar que los datos se muestreen cada minuto.</p> <p>Atenci\u00f3n</p> <p>Las m\u00e9tricas b\u00e1sicas son gratuitas, pero al habilitar el monitoreo detallado se nos incrementar\u00e1 el costo del servicio CloudWacth.</p> <p>Podemos personalizar tambi\u00e9n la unidad de tiempo que deseamos mostrar y el tiempo de refresco del panel (por defecto el refresco debe ser manual).</p> <p>Nota</p> <p>Observa que los gr\u00e1ficos ya existen sin haber configurado nada.</p> <p>Explicaci\u00f3n</p> <p>EC2 env\u00eda autom\u00e1ticamente m\u00e9tricas b\u00e1sicas a CloudWatch. Los gr\u00e1ficos que estamos viendo se alimentan de las m\u00e9tricas de Cloudwatch</p>"},{"location":"ud08/practica1.html#monitorizacion-desde-cloudwatch","title":"Monitorizaci\u00f3n desde Cloudwatch","text":"<p>3.- Accede al servicio CloudWatch:</p> <ul> <li>En el panel lateral accede al men\u00fa M\u00e9tricas --&gt; Todas las M\u00e9tricas</li> <li>Dentro de la pesta\u00f1a Examinar nos aparecen cajas con acceso a las m\u00e9tricas y a los paneles autom\u00e1ticos por servicio.</li> <li>Accede a Ver el panel autom\u00e1tico de EC2.</li> <li>Observa que nos aparecen pr\u00e1cticamente los mismos gr\u00e1ficos que en la pesta\u00f1a de Monitoreo de EC2, pero en este caso para todas las instancias que hay en ejecuci\u00f3n. En uno de los paneles selecciona la instancia Servidor-Web y comprueba que los datos coinciden con los vistos anteriormente.</li> </ul> <p></p> <p>4.- Vamos a crear un nuevo panel:</p> <ul> <li>En el panel lateral de CloudWatch accede a Paneles.</li> <li>Pulsa sobre Crear un panel</li> <li>Dale un nombre: Servidor-Web</li> <li>Comienza a\u00f1adiendo un widget de m\u00e9trica de tipo L\u00ednea</li> <li>De las m\u00e9tricas disponibles selecciona las de EC2.</li> <li>Pulsa sobre M\u00e9tricas por instancia.</li> <li>Selcciona una m\u00e9trica asociada a la instancia Servidor-Web (se puede filtar por InstanceId).</li> <li>Una vez a\u00f1adido el widget, pulsa sobre el bot\u00f3n + y a\u00f1ade varios m\u00e1s. Puedes probar varios tipos de widget.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea el panel creado con varios widgets .</p> <p>No borres ning\u00fan recurso</p> <p>Puesto que vamos a utilizar la instancia EC2 en la siguiente pr\u00e1ctica, no borres ning\u00fan recurso creado en esta pr\u00e1ctica.</p>"},{"location":"ud08/practica2.html","title":"Pr\u00e1ctica 2. Alarmas en CloudWatch","text":"<p>Creaci\u00f3n de alarmas asociadas a EC2</p>"},{"location":"ud08/practica2.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Crear una alarma b\u00e1sica en CloudWatch.</li> <li>Entender los estados de una alarma (OK / ALARM / INSUFFICIENT_DATA).</li> <li>Ver c\u00f3mo una alarma reacciona ante un cambio de carga.</li> </ul>"},{"location":"ud08/practica2.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud08/practica2.html#creacion-de-una-instancia-ec2","title":"Creaci\u00f3n de una instancia EC2","text":"<p>1.- Vamos a utilizar la instancia Servidor-Web utilizada en la pr\u00e1ctica anterior.</p>"},{"location":"ud08/practica2.html#creacion-de-una-alarma-en-cloudwatch","title":"Creaci\u00f3n de una alarma en CloudWatch","text":"<p>2.- Accede al servicio CloudWatch:</p> <ul> <li>En el panel lateral accede al men\u00fa Alarmas --&gt; Todas las Alarmas</li> <li>Pulsa sobre Crear Alarma</li> <li>Selecciona una m\u00e9trica.<ul> <li>De las m\u00e9tricas disponibles selecciona las de EC2.</li> <li>Pulsa sobre M\u00e9tricas por instancia.</li> <li>Selecciona la m\u00e9trica CPUUtilization asociada a la instancia Servidor-Web (se puede filtar por InstanceId).</li> </ul> </li> <li>Una vez aparezca el gr\u00e1fico, vamos a configurar las siguientes condiciones:<ul> <li>Estad\u00edstica: Media</li> <li>Periodo: 1 minuto</li> <li>Tipo de l\u00edmite: Est\u00e1tico</li> <li>Cuando la CPUUtilization sea...: Mayor que 70</li> <li>En la Configuraci\u00f3n adicional selecionamos que la alarma se disparar\u00e1 cuando haya 2 puntos por encima del l\u00edmite en 2 muestras consecutivas (2 de 2).</li> </ul> </li> <li>La siguiente pantalla nos pide configurar la acci\u00f3n a realizar cuando se dispare la alarma:<ul> <li>Cofiguramos una notificaci\u00f3n por el servicio SNS:<ul> <li>El activador: En modo alarma</li> <li>Enviar una notificaci\u00f3n al tema de SNS: Crear un tema nuevo</li> <li>Introducimos un nombre de tema (o dejamos el por defecto)</li> <li>A\u00f1adimos nuestra direcci\u00f3n de correo.</li> <li>Agregamos la notificaci\u00f3n.</li> <li>Nos debe llegar un correo electr\u00f3nico a la direcci\u00f3n especificada para confirmar la suscripci\u00f3n al tema.</li> </ul> </li> </ul> </li> <li>Por \u00faltimo damos un nombre a la alarma y opcionalmente un texto en formato Markdown con la descripci\u00f3n.</li> </ul> <p></p>"},{"location":"ud08/practica2.html#estres-de-la-maquina","title":"Estr\u00e9s de la m\u00e1quina","text":"<p>3.- Vamos a estresar la m\u00e1quina para que si dispare una alarma:</p> <ul> <li>Accede por SSH a la m\u00e1quina EC2</li> <li>Instala el paquete stress-ng: <code>sudo apt install -y stress-ng</code></li> <li>Ejecuta el siguiente comando para estresar la CPU durante 3 minutos: <code>stress-ng --cpu 4 --timeout 3m</code></li> <li>Accede al panel de la alarma reci\u00e9n creada y comprueba la informaci\u00f3n que va mostrando la m\u00e9trica.</li> <li>Si todo ha ido bien, pasados unos minutos debes haber recibido un correo electr\u00f3nico notificando la alarma.</li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea el panel de la alarma, con la zona roja en el momento del estr\u00e9s, y otra captura con el correo recibido.</p> <p>Interpretaci\u00f3n de la gr\u00e1fica</p> <p>Es posible que veamos en la gr\u00e1fica que el % de utilizaci\u00f3n de la CPU no ha alcanzado la l\u00ednea roja (70%) y en cambio s\u00ed que se ha disparado la alarma. Esto es debido a que el gr\u00e1fico saca medias cada 5 minutos, y en cambio la alarma est\u00e1 muestreando cada minuto, lo que puede dar lugar a situaciones de que durante 2 minutos la m\u00e1quina est\u00e1 al 100% y por tanto se dispara la alarma, pero en el conjunto de los 5 minutos la utilizaci\u00f3n no ha llegado al 70% en total.</p> <p></p>"},{"location":"ud08/practica3.html","title":"Pr\u00e1ctica 3. Logs en CloudWacth","text":"<p>Visualizaci\u00f3n de logs en CloudWacth</p>"},{"location":"ud08/practica3.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Visualizar logs generados autom\u00e1ticamente por las funciones Lambda.</li> <li>Identificar Log Groups (Grupos de Registro) y Log Streams (Flujos de Registro) asociados a una funci\u00f3n Lambda.</li> <li>Interpretar la informaci\u00f3n b\u00e1sica de los logs (START, END, REPORT).</li> <li>Consultar logs usando CloudWatch Logs Insights.</li> </ul> <p>Atenci\u00f3n</p> <p>CloudWatch puede recibir logs de muchos servicios de AWS, pero no todos lo hacen autom\u00e1ticamente. Servicios como AWS Lambda, API Gateway o Step Functions env\u00edan sus logs a CloudWatch de forma autom\u00e1tica, sin necesidad de instalar agentes ni realizar configuraciones adicionales. En estos casos, AWS crea por s\u00ed mismo los Log Groups y Log Streams, y los logs aparecen en CloudWatch en cuanto el servicio se ejecuta.</p> <p>Otros servicios, como EC2, contenedores o aplicaciones propias, requieren una configuraci\u00f3n expl\u00edcita para enviar logs. Esto implica asignar permisos IAM adecuados y, normalmente, instalar y configurar el CloudWatch Agent o usar el SDK de AWS. En todos los casos, para que existan logs es imprescindible que haya un origen que los genere, permisos para enviarlos y un destino en CloudWatch donde almacenarlos.</p>"},{"location":"ud08/practica3.html#requisitos-previos","title":"Requisitos previos","text":"<p>Es necesario haber realizado alguna pr\u00e1ctica de la Unidad 6: Microservicios y arquitecturas sin servidor y no haber borrado los logs de la ejecuci\u00f3n de las funciones Lambda.</p>"},{"location":"ud08/practica3.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud08/practica3.html#acceso-a-los-grupos-de-registro","title":"Acceso a los Grupos de Registro","text":"<p>1.- Accede al servicio CloudWatch:</p> <ul> <li>En el panel lateral accede al men\u00fa Registros --&gt; Log Management</li> <li>Nos aparecen los Grupos de Registro (Log Groups)</li> <li>Busca un Log Group con el formato: <code>/aws/lambda/nombre-de-la-funcion</code></li> <li>Este Log Group:<ul> <li>Se crea autom\u00e1ticamente</li> <li>Tiene el mismo nombre que la funci\u00f3n</li> </ul> </li> <li>Haz clic sobre \u00e9l.</li> </ul> <p></p>"},{"location":"ud08/practica3.html#explorar-los-flujos-de-registro","title":"Explorar los Flujos de Registro","text":"<p>Dentro del Grupo de Registros pueden aparecer varios Flujos de Registro (Log Streams). Cada uno corresponde a:</p> <ul> <li>Una ejecuci\u00f3n</li> <li>O a un contenedor reutilizado por Lambda</li> </ul> <p>El nombre suele incluir:</p> <ul> <li>Fecha</li> <li>Identificador \u00fanico</li> </ul> <p>2.- Selecciona uno de ellos.</p> <p></p>"},{"location":"ud08/practica3.html#interpretar-los-logs-de-una-ejecucion","title":"Interpretar los logs de una ejecuci\u00f3n","text":"<p>Al abrir un Log Stream t\u00edpico veremos los Eventos de Registro, algo parecido a esto:</p> <p><pre><code>START RequestId: xxx Version: $LATEST\n</code></pre> <pre><code>Mensaje generado por la funci\u00f3n\n</code></pre> <pre><code>END RequestId: xxx\n</code></pre> <pre><code>REPORT RequestId: xxx Duration: 3.45 ms Billed Duration: 4 ms Memory Size: 128 MB Max Memory Used: 57 MB\n</code></pre></p> <p>Cada uno de estos eventos tiene una informaci\u00f3n relacionada con distintos eventos de la funci\u00f3n que se ha ejecutado.</p> <ul> <li>START<ul> <li>Inicio de la ejecuci\u00f3n de la funci\u00f3n.</li> </ul> </li> <li>Mensajes intermedios<ul> <li>Salidas del c\u00f3digo (por ejemplo <code>console.log</code>, <code>print</code>, etc.).</li> </ul> </li> <li>END<ul> <li>Fin de la ejecuci\u00f3n.</li> </ul> </li> <li>REPORT<ul> <li>Informaci\u00f3n de rendimiento (esta l\u00ednea es clave para optimizaci\u00f3n y costes):<ul> <li>Tiempo de ejecuci\u00f3n</li> <li>Memoria asignada</li> <li>Memoria utilizada</li> </ul> </li> </ul> </li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea los eventos de registro de un flujo de registro en concreto.</p> <p></p>"},{"location":"ud08/practica3.html#consultas-con-logs-insights","title":"Consultas con Logs Insights","text":"<p>CloudWatch Logs Insights es una herramienta de AWS que permite buscar, filtrar y analizar de forma r\u00e1pida los logs almacenados en CloudWatch, usando un lenguaje de consultas sencillo. Facilita encontrar errores, analizar ejecuciones y obtener estad\u00edsticas sin necesidad de descargar los logs.</p> <p>Utiliza un lenguaje de consultas propio de AWS, espec\u00edfico para el an\u00e1lisis de logs. Es un lenguaje declarativo y orientado a b\u00fasquedas, inspirado en SQL pero no es SQL est\u00e1ndar, dise\u00f1ado para filtrar, ordenar y obtener estad\u00edsticas a partir de registros de texto de forma eficiente.</p> <p>3.- En el panel lateral del servicio CloudWatch accede al men\u00fa Registros --&gt; Logs Insights:</p> <ul> <li>Selecciona un grupo de registro de los asociados a la ejecuci\u00f3n de las funciones lambda que ten\u00edas.</li> <li>Especifica un rango de tiempo (por defecto aparece seleccionado una hora) que incluya la fecha de la ejecuci\u00f3n de la funci\u00f3n lambda.</li> <li>Deja el query que viene por defecto: <pre><code>fields @timestamp, @message\n| sort @timestamp desc\n| limit 10000\n</code></pre></li> <li>Ejecuta la consulta.</li> </ul> <p>Deben aparecer los eventos de registro asociados al grupo de registros seleccionados ordenados por fecha m\u00e1s reciente.</p> <p>Prueba a cambiar la consulta:</p> <ul> <li>Logs en los que aparece la palabra \"error\": <pre><code>fields @timestamp, @message\n| filter @message =~ /error/\n| sort @timestamp desc\n</code></pre></li> <li>Ver duraci\u00f3n de las ejecuciones de la funci\u00f3n lambda: <pre><code>filter @type = \"REPORT\"\n| stats avg(@duration), max(@duration)\n</code></pre></li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea la ejcuci\u00f3n satisfactoria de alguna consulta.</p>"},{"location":"ud08/practica4.html","title":"Pr\u00e1ctica 4. M\u00e9tricas RDS en CloudWatch","text":"<p>An\u00e1lisis m\u00e9tricas RDS</p>"},{"location":"ud08/practica4.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Identificar las m\u00e9tricas b\u00e1sicas de una instancia RDS.</li> <li>Crear un panel.</li> <li>Estresar una base de datos y analizar sus m\u00e9tricas.</li> </ul>"},{"location":"ud08/practica4.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud08/practica4.html#creacion-de-una-base-datos-rds","title":"Creaci\u00f3n de una Base Datos RDS","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio RDS. Crea una nueva base de datos p\u00fablica:</p> <ul> <li>Seleccionamos el m\u00e9todo de creaci\u00f3n est\u00e1ndar.</li> <li>Como motor de base de datos elegimos MySQL.</li> <li>La plantilla sobre la que se va a basar ser\u00e1 Entorno de pruebas (las dem\u00e1s no son aptas para el laboratorio).</li> <li>Disponibilidad Implementaci\u00f3n de una instanciade base de datos de zona de disponibilidad \u00fanica (1 instancia)</li> <li>Ponemos un nombre de servidor que debe ser \u00fanico en nuestra cuenta de AWS. Introduce uno que lleve tu nombre o iniciales.</li> <li>Asignamos nombre de usuario administrador y su contrase\u00f1a.</li> <li>Dejamos las opciones por defecto del tama\u00f1o de la instancia y el almacenamiento.</li> <li>No vamos a conectar nuestra BBDD a ninguna instancia EC2, y dejamos la BBDD en la VPC por defecto (Default VPC).</li> <li>Importante: Permitimos el Acceso P\u00fablico a nuestra BBDD. Esto generar\u00e1 una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Creamos un nuevo grupo de seguridad, por ejemplo bbdd-sg</li> <li>Los dem\u00e1s campos los dejamos por defecto. </li> </ul>"},{"location":"ud08/practica4.html#conexion-a-la-bbdd","title":"Conexi\u00f3n a la BBDD","text":"<p>2.- En nuestra m\u00e1quina local establacemos una conexi\u00f3n mediante un cliente de MySQL de l\u00ednea de comandos, indicando la cadena de conexi\u00f3n y el usuario que hemos definido como administrador. En el par\u00e1metro host <code>-h</code> ponemos el nombre del servidor (endpoint que hemos copiado en el portapapeles) y en el par\u00e1metro de usuario <code>-u</code> el nombre del usuario. Para que nos solicite el password indicamos el par\u00e1metro <code>-p</code>.</p> <p><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p</code></p> <p>Una vez comprobada la conexi\u00f3n, cerramos la sesi\u00f3n:</p> <p><code>exit;</code></p> <p>Atenci\u00f3n</p> <p>Si hemos dejado la opci\u00f3n de Permitir Acceso P\u00fablico como NO o no aparece la regla de seguridad del firewall (grupo de seguridad) no podremos conectarnos.</p> <p>3.- Vamos a crear una base de datos con una tabla. Lo vamos a hacer mediante un script de sentencias sql. Para ello comenzamos con la descarga del fichero de creaci\u00f3n de la base de datos.</p> <p>Descarga fichero sql</p> <p>4.- Ejecutamos las instrucciones SQL que hay en el contenido del fichero descargado. Basta con redireccionar la entrada del comando <code>mysql</code> con el fichero descargado de nombre <code>asir.sql</code>.</p> <pre><code>mysql -h database-jrpm.cruqs8qiedha.us-east-1.rds.amazonaws.com -u admin -p &lt; asir.sql\n</code></pre> <p></p>"},{"location":"ud08/practica4.html#estresando-la-bbdd","title":"Estresando la BBDD","text":"<p>5.- Vamos a simular varias conexiones simult\u00e1neas a nuestra base de datos mediante el programa <code>mysqlslap</code> que es una herramienta que viene instalada con el cliente de MySQL. Para ello ejecutamos el siguiente comando:</p> <pre><code>mysqlslap -h &lt;endpoint&gt;&gt; -u admin -p \\\n--concurrency=50 --iterations=10 \\\n--number-of-queries=1000 \\\n--create-schema=webasir --query=\"SELECT * FROM clientes;\"\n</code></pre> <p>El comando simula 50 conexiones simult\u00e1neas que ejecutan 1000 veces el query indicado.</p> <p></p>"},{"location":"ud08/practica4.html#monitorizacion-desde-cloudwatch","title":"Monitorizaci\u00f3n desde Cloudwatch","text":"<p>6.- Accede al servicio CloudWatch:</p> <ul> <li>En el panel lateral accede al men\u00fa Paneles --&gt; Crear Panel</li> <li>Dale un nombre: BasedeDatos</li> <li>Comienza a\u00f1adiendo un widget de m\u00e9trica de tipo L\u00ednea</li> <li>De las m\u00e9tricas disponibles selecciona las de RDS.</li> <li>Pulsa sobre DBinstanceIdentifier.</li> <li>Selcciona la m\u00e9trica DataBaseConnections.</li> <li>Una vez a\u00f1adido el widget, pulsa sobre el bot\u00f3n + y a\u00f1ade varios m\u00e1s:<ul> <li>ReadIOPS</li> <li>WriteIOPS</li> <li>ReadLatency</li> <li>CPUUtilization</li> <li>FreeStorageSpace (widget tipo N\u00famero)</li> </ul> </li> </ul> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea el panel creado con varios widgets. Interpreta el significado de cada m\u00e9trica mostrada.</p> <p></p>"},{"location":"ud08/practica4.html#eliminacion-de-los-recursos-creados","title":"Eliminaci\u00f3n de los recursos creados","text":"<p>7.- Desde la consola de AWS, elimina el servidor de BBDD creado para asegurarnos que no dejamos ning\u00fan recurso consumiendo cr\u00e9dito. No crees ninguna instant\u00e1nea final ni conserves las copias de seguridad.</p> <p>Atenci\u00f3n</p> <p>Si detenemos un servidor de BBDD (sin eliminarlo), AWS lo iniciar\u00e1 autom\u00e1ticamente a los 7 d\u00edas (si no lo hemos levantado nosotros de manera manual antes). Esto es peligroso, pues si olvidamos eliminar un recurso de BBDD que no utilizamos, se pondr\u00e1 en marcha autom\u00e1ticamente a los 7 d\u00edas de haberlo detenido, con el consiguiente consumo de cr\u00e9dito.</p> <p></p>"},{"location":"ud08/ud08.html","title":"Tema 8. Monitorizaci\u00f3n en AWS","text":""},{"location":"ud08/ud08.html#monitoreo-en-la-nube","title":"Monitoreo en la Nube","text":"<p>El monitoreo es un componente esencial de cualquier arquitectura moderna y reactiva en la nube. Permite obtener visibilidad sobre el estado de los sistemas, comprender c\u00f3mo se comportan las aplicaciones y tomar decisiones informadas para optimizar tanto el rendimiento como los costos. Implementar una estrategia de monitoreo s\u00f3lida ayuda a abordar cuatro \u00e1reas principales:</p> <ul> <li>Estado operativo: Permite hacer un seguimiento continuo del funcionamiento y el rendimiento de todos los recursos en la nube, asegurando que todo funcione como se espera.</li> <li>Rendimiento de la aplicaci\u00f3n: Ayuda a verificar que la infraestructura est\u00e9 satisfaciendo la demanda de los usuarios, identificando cuellos de botella o degradaciones en el servicio antes de que afecten la experiencia del cliente.</li> <li>Utilizaci\u00f3n de los recursos: Ofrece datos precisos sobre c\u00f3mo se est\u00e1n usando los recursos (como la capacidad de c\u00f3mputo o el almacenamiento), lo que permite optimizar su uso y reducir costos al detener instancias infrautilizadas.</li> <li>Auditor\u00eda de la seguridad: Proporciona un rastro de auditor\u00eda de qui\u00e9n accede a qu\u00e9 recursos, informaci\u00f3n crucial para definir y verificar los permisos de acceso y cumplir con los objetivos de gobernanza.</li> </ul> <p>Para centralizar y gestionar estas actividades, AWS ofrece un servicio principal de monitoreo y observaci\u00f3n conocido como Amazon CloudWatch.</p>"},{"location":"ud08/ud08.html#amazon-cloudwatch","title":"Amazon CloudWatch","text":"<p>Amazon CloudWatch es el servicio central de monitorizaci\u00f3n de AWS. Permite recopilar y visualizar m\u00e9tricas, logs y eventos de los recursos AWS y de aplicaciones personalizadas. Su prop\u00f3sito es proporcionar datos e informaci\u00f3n procesable para monitorear aplicaciones, responder a cambios de rendimiento en todo el sistema, optimizar el uso de recursos y obtener una visi\u00f3n unificada del estado operativo general.</p> <p>El valor fundamental de CloudWatch es su capacidad para recopilar y rastrear variables (m\u00e9tricas), crear alarmas para responder a cambios en esas m\u00e9tricas e incluso automatizar acciones basadas en esas alarmas.</p> <p></p> <p>Los componentes principales de CloudWatch se pueden resumir de la siguiente manera:</p> Componente Funci\u00f3n Principal M\u00e9tricas Recopila puntos de datos a lo largo del tiempo sobre el rendimiento de los sistemas y las aplicaciones. Registros (Logs) Centraliza, monitorea y almacena archivos de registro (logs) de diversas fuentes para su an\u00e1lisis y soluci\u00f3n de problemas. Alarmas Vigila una m\u00e9trica espec\u00edfica y ejecuta acciones autom\u00e1ticas cuando se cruza un umbral predefinido. Eventos (EventBridge) Entrega un flujo de eventos del sistema en tiempo real que describen cambios en los recursos de AWS."},{"location":"ud08/ud08.html#metricas","title":"M\u00e9tricas","text":"<p>Las m\u00e9tricas son el fundamento del monitoreo en CloudWatch. Son esencialmente puntos de datos sobre el rendimiento de nuestros sistemas, recopilados a lo largo del tiempo. Por ejemplo, una m\u00e9trica com\u00fan es el uso de la CPU de una instancia EC2.</p> <p></p> <p>Es importante conocer tres caracter\u00edsticas clave de las m\u00e9tricas de CloudWatch:</p> <ol> <li>M\u00e9tricas por Defecto: Muchos servicios de AWS, como Amazon EC2, Amazon EBS y Amazon RDS, env\u00edan autom\u00e1ticamente m\u00e9tricas de rendimiento a CloudWatch sin necesidad de configuraci\u00f3n adicional.</li> <li>Retenci\u00f3n de Datos: Los datos de las m\u00e9tricas se conservan durante 15 meses. Esto es \u00fatil para analizar tanto las tendencias de rendimiento recientes como los patrones hist\u00f3ricos a largo plazo.</li> <li>M\u00e9tricas Personalizadas: Adem\u00e1s de las m\u00e9tricas que AWS proporciona de forma predeterminada, tenemos la flexibilidad de publicar nuestras propias m\u00e9tricas personalizadas desde nuestras aplicaciones.</li> </ol>"},{"location":"ud08/ud08.html#registros-logs","title":"Registros (Logs)","text":"<p>Amazon CloudWatch Logs es un servicio que nos permite monitorear, almacenar y acceder a nuestros archivos de registro desde una variedad de fuentes. En lugar de tener que conectarnos a cada servidor para ver sus logs, podemos centralizarlos todos en un solo lugar.</p> <p></p> <p>Algunos ejemplos de fuentes de registro incluyen:</p> <ul> <li>Instancias Amazon EC2</li> <li>AWS CloudTrail (registros de llamadas a la API)</li> <li>Amazon Route 53</li> </ul> <p>Un caso de uso pr\u00e1ctico es monitorear los registros de una aplicaci\u00f3n para contar el n\u00famero de errores que ocurren. Si la cantidad de errores supera un l\u00edmite que se ha definido, CloudWatch Logs puede enviar una notificaci\u00f3n para que se investigue el problema.</p> <p>Adicionalmente, el servicio incluye CloudWatch Logs Insights, una potente herramienta que permite ejecutar consultas interactivas para analizar grandes vol\u00famenes de datos de registro en segundos.</p>"},{"location":"ud08/ud08.html#alarmas","title":"Alarmas","text":"<p>Una alarma de CloudWatch es una herramienta que vigila una \u00fanica m\u00e9trica durante un per\u00edodo de tiempo que se puede especificar. Sin embargo, su prop\u00f3sito no es solo notificar; su verdadera capacidad reside en la automatizaci\u00f3n. El objetivo principal de una alarma es iniciar una o m\u00e1s acciones autom\u00e1ticamente cuando una m\u00e9trica cruza un umbral definido.</p> <p></p> <p>Una alarma puede desencadenar principalmente dos tipos de acciones:</p> <ul> <li>Enviar una notificaci\u00f3n a un tema de Amazon Simple Notification Service (SNS).</li> <li>Ejecutar una pol\u00edtica de Amazon Auto Scaling para a\u00f1adir o eliminar recursos.</li> </ul> <p>Esta \u00faltima acci\u00f3n es especialmente interesante para realizar un escalado horizontal de manera autom\u00e1tica. Por ejemplo, podemos configurar una alarma que se active si la m\u00e9trica CPUUtilization de una instancia EC2 es superior al 50% durante 5 minutos. Esta alarma podr\u00eda entonces activar una pol\u00edtica de Auto Scaling para lanzar una instancia EC2 adicional y as\u00ed manejar el aumento de la carga.</p> <p></p>"},{"location":"ud08/ud08.html#eventos-amazon-eventbridge","title":"Eventos (Amazon EventBridge)","text":"<p>Amazon EventBridge (anteriormente conocido como CloudWatch Events) es un servicio que ofrece un flujo de eventos del sistema en tiempo real. Un evento es simplemente una se\u00f1al de que algo ha cambiado en el entorno de AWS.</p> <p></p> <p>Ejemplos de eventos incluyen:</p> <ul> <li>Un cambio en el estado de una instancia EC2 (por ejemplo, de pending a running).</li> <li>Una llamada a la API de AWS registrada por CloudTrail.</li> <li>Un evento programado que se genera a intervalos regulares (por ejemplo, cada hora).</li> </ul> <p>EventBridge funciona con dos conceptos clave:</p> <ul> <li>Reglas: Una regla se encarga de buscar y coincidir con los eventos entrantes seg\u00fan un patr\u00f3n que definamos. Por ejemplo, una regla puede coincidir con cualquier evento que indique la terminaci\u00f3n de una instancia EC2.</li> <li>Objetivos: Un objetivo es el recurso que procesa el evento una vez que una regla lo ha identificado. Los objetivos pueden ser muy variados, como una funci\u00f3n de AWS Lambda, una instancia EC2 o una cola de Amazon SQS.</li> </ul>"},{"location":"ud08/ud08.html#aws-cloudtrail","title":"AWS CloudTrail","text":"<p>AWS CloudTrail es el servicio de AWS encargado de registrar y auditar toda la actividad que ocurre dentro de una cuenta. Su funci\u00f3n principal es dejar constancia de qui\u00e9n realiza una acci\u00f3n, cu\u00e1ndo la realiza, desde d\u00f3nde y con qu\u00e9 resultado.</p> <p>CloudTrail no est\u00e1 pensado para medir rendimiento ni consumo de recursos, sino para seguridad, auditor\u00eda y cumplimiento normativo. Gracias a este servicio es posible reconstruir exactamente qu\u00e9 ha ocurrido en una cuenta AWS ante un incidente o una auditor\u00eda.</p> <p>En la pr\u00e1ctica, CloudTrail registra las llamadas a la API de AWS, independientemente de que se hayan hecho desde la consola web, la AWS CLI, un SDK o desde otro servicio de AWS.</p>"},{"location":"ud08/ud08.html#acciones-registradas-por-cloudtrail","title":"Acciones registradas por CloudTrail","text":"<p>CloudTrail registra pr\u00e1cticamente cualquier acci\u00f3n relevante en AWS. Esto incluye:</p> <ul> <li>Acciones realizadas desde la consola de administraci\u00f3n, como crear una instancia EC2 o modificar un grupo de seguridad.</li> <li>Acciones realizadas mediante AWS CLI o SDKs, muy comunes en entornos automatizados.</li> <li>Acciones realizadas por servicios de AWS entre s\u00ed, por ejemplo cuando Auto Scaling lanza nuevas instancias o una funci\u00f3n Lambda accede a un bucket S3.</li> </ul> <p>La idea clave es que todo lo que sea una llamada a la API queda reflejado en CloudTrail.</p>"},{"location":"ud08/ud08.html#tipos-de-eventos-registrados-por-cloudtrail","title":"Tipos de eventos registrados por CloudTrail","text":""},{"location":"ud08/ud08.html#eventos-de-administracion-management-events","title":"Eventos de administraci\u00f3n (Management Events)","text":"<p>Son los eventos m\u00e1s importantes y est\u00e1n activados por defecto. Registran operaciones relacionadas con la gesti\u00f3n y configuraci\u00f3n de los recursos.</p> <p>Incluyen, entre otros:</p> <ul> <li>Creaci\u00f3n, modificaci\u00f3n y eliminaci\u00f3n de recursos</li> <li>Cambios de configuraci\u00f3n</li> <li>Gesti\u00f3n de usuarios, roles y pol\u00edticas IAM</li> </ul> <p>Ejemplos t\u00edpicos ser\u00edan crear una instancia EC2, borrar un bucket S3 o asignar una pol\u00edtica a un rol.</p>"},{"location":"ud08/ud08.html#eventos-de-datos-data-events","title":"Eventos de datos (Data Events)","text":"<p>Los eventos de datos registran el acceso al contenido de los recursos, no su configuraci\u00f3n. Debido al enorme volumen que pueden generar, no est\u00e1n activados por defecto.</p> <p>Ejemplos claros:</p> <ul> <li>Accesos a objetos en S3 (<code>GetObject</code>, <code>PutObject</code>)</li> <li>Invocaciones de funciones Lambda</li> </ul> <p>Se configuran de forma expl\u00edcita y por recurso, y se usan cuando es necesario un control muy detallado de accesos.</p>"},{"location":"ud08/ud08.html#eventos-de-analisis-insight-events","title":"Eventos de an\u00e1lisis (Insight Events)","text":"<p>Este tipo de eventos permite a CloudTrail detectar comportamientos an\u00f3malos, como un aumento inusual de determinadas acciones.</p> <p>Por ejemplo:</p> <ul> <li>Un n\u00famero anormalmente alto de eliminaciones de recursos</li> <li>Cambios inesperados en el uso de IAM</li> </ul> <p>Son muy \u00fatiles como sistema de alerta temprana ante posibles incidentes de seguridad.</p>"},{"location":"ud08/ud08.html#almacenamiento-y-consulta-de-los-logs","title":"Almacenamiento y consulta de los logs","text":"<p>Los eventos de CloudTrail se almacenan en formato JSON, lo que permite su an\u00e1lisis autom\u00e1tico.</p> <p>Tambi\u00e9n pueden enviarse a CloudWatch Logs, lo que permite crear m\u00e9tricas y alarmas casi en tiempo real, por ejemplo para detectar la eliminaci\u00f3n de recursos cr\u00edticos.</p> <p>De forma predeterminada, AWS ofrece el Event History, que permite consultar los eventos de los \u00faltimos 90 d\u00edas directamente desde la consola. Este historial no es configurable y solo sirve para consultas r\u00e1pidas.</p> <p>Para un uso real y profesional se utilizan los Trails, que permiten enviar los eventos a un bucket S3 y opcionalmente a CloudWatch Logs. Esto posibilita:</p> <ul> <li>Retener los logs durante a\u00f1os</li> <li>Analizarlos con otras herramientas</li> <li>Integrarlos con sistemas de alerta</li> </ul>"},{"location":"ud08/ud08.html#monitoreo-de-costos-y-uso-en-aws","title":"Monitoreo de Costos y Uso en AWS","text":"<p>Adem\u00e1s de monitorear el rendimiento t\u00e9cnico de la infraestructura, es vital monitorear los costos para gestionar eficazmente nuestro gasto en AWS. La plataforma ofrece varias herramientas dise\u00f1adas espec\u00edficamente para este prop\u00f3sito.</p> <ul> <li>AWS Cost Explorer: Es una herramienta que ayuda a visualizar, comprender y administrar los costos y uso de AWS a lo largo del tiempo, con datos de hasta 13 meses que permiten identificar patrones de gasto.</li> <li>AWS Budgets: Permite definir presupuestos personalizados. Si los costos o el uso superan (o se prev\u00e9 que superen) el monto presupuestado, se env\u00eda una alerta.</li> <li>Informe de uso y costo de AWS: Ofrece el conjunto de datos de costos y uso m\u00e1s completo disponible, incluyendo metadatos detallados sobre servicios, precios y reservas.</li> <li>Cost Optimization Monitor: Una soluci\u00f3n que procesa autom\u00e1ticamente los informes de facturaci\u00f3n para ofrecer m\u00e9tricas detalladas que se pueden analizar y visualizar en un panel personalizado.</li> </ul>"},{"location":"ud09/practica1.html","title":"Pr\u00e1ctica 1. Autoescalado de EC2","text":"<p>Dise\u00f1o e implementaci\u00f3n de una infraestructura web altamente disponible y escalable, utilizando balanceo de carga y autoescalado.</p>"},{"location":"ud09/practica1.html#objetivo-de-la-practica","title":"Objetivo de la pr\u00e1ctica","text":"<ul> <li>Desplegar instancias EC2 autom\u00e1ticamente usando un Launch Template y scripts de inicializaci\u00f3n.</li> <li>Configurar un Application Load Balancer (ALB) para distribuir tr\u00e1fico HTTP entre varias instancias.</li> <li>Implementar un Auto Scaling Group, definiendo tama\u00f1os m\u00ednimo, deseado y m\u00e1ximo.</li> <li>Configurar pol\u00edticas de escalado autom\u00e1tico basadas en m\u00e9tricas.</li> <li>Verificar el funcionamiento del balanceo y el autoescalado mediante pruebas de carga.</li> </ul>"},{"location":"ud09/practica1.html#esquema-en-aws","title":"Esquema en AWS","text":""},{"location":"ud09/practica1.html#practica-a-realizar","title":"Pr\u00e1ctica a realizar","text":""},{"location":"ud09/practica1.html#creacion-de-la-red","title":"Creaci\u00f3n de la red","text":"<p>1.- Inicia sesi\u00f3n en la Consola de AWS y entra en el servicio VPC. Procedemos a crear una nueva VPC:</p> <ul> <li>Le decimos que queremos crear la VPC y m\u00e1s.</li> <li>Asignamos un nombre a la VPC, por ejemplo practica01</li> <li>Como direcci\u00f3n de red (Bloque de CIDR IPv4) dejamos la 10.0.0.0/16</li> <li>Seleccionamos dos zonas de disponibilidad (AZ).</li> <li>Le decimos que nos cree dos subredes p\u00fablicas y ninguna subred privada.</li> <li>Personalizamos los bloques de direcciones de modo que las subredes tengan las siguientes direcciones:<ul> <li>Subred p\u00fablica 1: 10.0.1.0/24</li> <li>Subred p\u00fablica 2: 10.0.2.0/24</li> </ul> </li> <li>No necesitamos ning\u00fan Gateway NAT.</li> <li>No vamos a conectar ning\u00fan bucket de S3, por tanto no seleccionamos ning\u00fan Gateway de S3 en el apartado de Puntos de enlace de la VPC.</li> </ul> <p></p>"},{"location":"ud09/practica1.html#creacion-de-los-grupos-de-seguridad","title":"Creaci\u00f3n de los grupos de seguridad","text":"<p>2.- Accede al panel de EC2 y en el men\u00fa lateral pulsa grupos de seguridad y crea 2 grupos de seguridad:</p> <ul> <li>Primer grupo de seguridad: gs-web<ul> <li>Descripci\u00f3n: Permitir trafico entrante HTTP desde Internet</li> <li>VPC: practica01</li> <li>Permitir tr\u00e1fico de entrada por el puerto HTTP(80) desde cualquier lugar de internet: 0.0.0.0/0</li> <li>El tr\u00e1fico de salida lo dejamos con los valores por defecto.</li> </ul> </li> <li>Segundo grupo de seguridad: gs-alb<ul> <li>Descripci\u00f3n: Permitir trafico entrante HTTP desde Balanceador de Carga</li> <li>VPC: practica01</li> <li>Permitir tr\u00e1fico de entrada por el puerto HTTP(80) desde el grupo de seguridad gs-web</li> <li>El tr\u00e1fico de salida lo dejamos con los valores por defecto.</li> </ul> </li> </ul> <p></p>"},{"location":"ud09/practica1.html#creacion-de-una-instancia-ec2","title":"Creaci\u00f3n de una instancia EC2","text":"<p>3.- Accede al servicio EC2. Lanza una nueva instancia:</p> <ul> <li>Ll\u00e1mala Servidor-Web</li> <li>La imagen ser\u00e1 la AMI de Ubuntu.</li> <li>El tama\u00f1o ser\u00e1 un tipo de instancia t3.micro.</li> <li>El par de claves utilizaremos el del laboratorio (vockey).</li> <li>Edita la configuraci\u00f3n de red para utilizar la VPC creada en el apartado anterior y ubica la m\u00e1quina en una de las 2 subredes p\u00fablicas.</li> <li>Nos aseguramos que se asigna una IP P\u00fablica para poder conectarnos desde Internet.</li> <li>Usa el grupo de seguridad llamado gs-web que contiene la regla de firewall para permitir las conexiones por el puerto HTTP(80).</li> <li>Para hacer que durante el primer lanzamiento de la instancia se instale el servidor HTTP y se copie el repositorio hello-cloud ponemos las siguientes l\u00edneas en el apartado de Datos de usuario:</li> </ul> <p><pre><code>#!/bin/bash\napt update\napt install -y apache2\ngit clone https://github.com/IES-CAMP-DE-MORVEDRE/hello-cloud.git\ncp hello-cloud/* /var/www/html -R\n</code></pre> </p> <p>4.- Inicia la m\u00e1quina y comprueba mediante un navegador que la web est\u00e1 disponible. </p>"},{"location":"ud09/practica1.html#creacion-de-una-plantilla-de-lanzamiento-launch-template","title":"Creaci\u00f3n de una Plantilla de Lanzamiento (Launch Template)","text":"<p>El siguiente paso ser\u00e1 crear, a partir de la instancia que tenemos creada, una plantilla de lanzamiento para crear m\u00e1quinas EC2 autom\u00e1ticamente en el grupo de auto escalado.</p> <p>5.- Selecciona la instancia que est\u00e1 corriendo, y en el men\u00fa Acciones pulsa sobre Imagen y Plantillas --&gt; Crear plantilla a partir de una instancia.</p> <ul> <li>Deja unos segundos a que se carguen los datos recuperados de la instancia que est\u00e1 corriendo.</li> <li>Pon un nombre a la plantilla: p. ej ServidorWeb</li> <li>Debe haber recuperado los valores de AMI, tama\u00f1o de la instancia, par de claves, red y datos de usuario que configuramos en el apartado de la creaci\u00f3n de la instancia EC2.</li> <li>Atenci\u00f3n: en grupo de seguridad ponemos el gs-alb, para permitir \u00fanicamente tr\u00e1fico entrante proveniente del balanceador de carga que crearemos m\u00e1s tarde, y eliminamos el que ha recuperado *gs-web. Por seguridad no vamos a querer que se acceda a las nuevas instancias directamente desde Internet, sino \u00fanicamente desde el balanceador de carga.</li> <li>Pulsamos sobre Crear plantilla de lanzamiento.</li> </ul> <p>Atenci\u00f3n</p> <p>En este momento la instancia EC2 que est\u00e1bamos corriendo ya no nos es necesaria y podemos eliminarla, puesto que la hab\u00edamos creado para crear una plantilla a partir de ella.</p> <p></p>"},{"location":"ud09/practica1.html#creacion-del-balanceador-de-carga","title":"Creaci\u00f3n del Balanceador de Carga","text":"<p>Vamos a crear un balanceador de carga (Amazon ELB) que utilizaremos m\u00e1s tarde para balancear el tr\u00e1fico entre todas las instancias del grupo de autoescalado. Puesto que al crear el grupo de autoescalado nos preguntar\u00e1 si tenemos un balanceador de carga, es necesario que lo creemos primero.</p> <p>6.- En el panel lateral de EC2 accede al men\u00fa Equilibrio de carga --&gt; Balanceadores de carga y pulsa sobre Crear balanceador de carga:</p> <ul> <li>Seleccionamos un balanceador de carga de Aplicaciones (ALB). Pulsamos Crear.</li> <li>Le damos un nombre: alb-web</li> <li>Seleccionamos el tipo Expuesto a Internet, pues queremos que se utilice para balancear el tr\u00e1fico de las peticiones de Internet a nuestra web.</li> <li>Seleccionamos la red practica01</li> <li>Marcamos las 2 subredes, pues queremos balancear entre las instancias que se alojen en ambas subredes (AZs).</li> <li>Como grupo de seguridad marcamo gs-web, que permite el tr\u00e1fico de entrada desde Internet por el puerto 80.</li> <li>El puerto por el que escuchar\u00e1 el balanceador ser\u00e1 el 80 (http).</li> <li>Pulsamos sobre Crear un grupo de destino. Nos abrir\u00e1 una nueva ventana para crear el Target Group:<ul> <li>Tipo de destino: Instancias</li> <li>Nombre: tgt-web</li> <li>Todos los dem\u00e1s valores por defecto.</li> <li>Pulsamos Siguiente y Crear sin tocar m\u00e1s valores. No hay que a\u00f1adir instancias de destino, las instancias ser\u00e1n las del grupo de auto escalado que a\u00fan no hemos creado.</li> </ul> </li> <li>Una vez creado el grupo de destino, lo seleccionamos y dejamos el resto de valores por defecto y le damos a crear el balanceador de carga.</li> </ul> <p></p>"},{"location":"ud09/practica1.html#creacion-del-grupo-de-auto-escalado","title":"Creaci\u00f3n del Grupo de Auto Escalado.","text":"<p>Hemos creado un balanceador de carga que de momento no balancea entre ninguna instancia porque en el Grupo de destino no hemos seleccionado nada. Vamos a crear un grupo de auto escalado que contendr\u00e1 instancias (entre 1 y 4) que se van a crear autom\u00e1ticamente a partir de la plantilla.</p> <p>7.- En el panel lateral de EC2 accedemos a Grupos de Auto Scaling y pulsamos sobre Crear grupo de Auto Scaling:</p> <ul> <li>Nombre: asc-web</li> <li>Plantilla de lanzamiento: ServidorWeb</li> <li>Red: practica01</li> <li>Seleccionamos las 2 zonas de disponiblidad, para que las instancias EC2 se creen repartidas entre ambas.</li> <li>Asociamos a un balanceador de carga existente: tgt-web</li> <li>En el tama\u00f1o de grupo configuramos:<ul> <li>Capacidad deseada: 2</li> <li>Capacidad m\u00ednima: 1</li> <li>Capacidad m\u00e1xima: 4</li> </ul> </li> <li>En Escaldo configuramos:<ul> <li>Pol\u00edtica de escalado de seguimiento de destino.</li> <li>M\u00e9trica: Utilizaci\u00f3n promedio de la CPU</li> <li>Valor 50 (es el %de utilizaci\u00f3n)</li> <li>Dejamos los 300 segundos como tiempo necesario para que se arranquen las nuevas instancias y empiece la m\u00e9trica a estabilizarse.</li> </ul> </li> </ul> <p></p>"},{"location":"ud09/practica1.html#comprobacion","title":"Comprobaci\u00f3n","text":"<p>8.- Accede al grupo de autoescalado, y en la pesta\u00f1a administraci\u00f3n de instancias comprueba que se han lanzado 2 instancias autom\u00e1ticamente (capacidad deseada). Cada una de ellas debe estar corriendo en una AZ distinta.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea las 2 instancias corriendo dentro del Grupo de autoescalado.</p> <p>9.- Accede al panel del Balanceador de Carga y en la pesta\u00f1a de Detalles copia el nombre DNS. Pega ese nombre de DNS en un navegador y comprueba que devuelve la p\u00e1gina web que est\u00e1 corriendo en una de las 2 instancias del grupo de autoescalado.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea el navegador con la direcci\u00f3n web DNS y que devuelve la p\u00e1gina.</p>"},{"location":"ud09/practica1.html#desescalado","title":"Desescalado","text":"<p>10.- Deja pasar entre 5 y 10 minutos y vuelve a comprobar la pesta\u00f1a de administraci\u00f3n de instancias del grupo de autoescalado y ver\u00e1s como debido a la nula actividad, el grupo se ha desescalado a una instancia que es el n\u00famero m\u00ednimo que le hemos puesto. De esta forma conseguimos un ahorro de costes ajustando nuestra capacidad a la demanda del momento.</p> <p>Captura la pantalla</p> <p>Captura la pantalla en la que se vea la \u00fanica instancia corriendo dentro del Grupo de autoescalado.</p> <p></p>"},{"location":"ud09/practica1.html#eliminacion-de-recursos","title":"Eliminaci\u00f3n de recursos","text":"<p>11.- Elimina los recursos creados: Balanceador de carga, Grupo de autoescalado e instancias. Son recursos que consumen mucho cr\u00e9dito.</p> <p>Atenci\u00f3n</p> <p>Aunqqe terminemos las instancias, si no eliminamos el grupo de autoescalado, este volver\u00e1 a crear instancias autom\u00e1ticamente.</p>"},{"location":"ud09/ud09.html","title":"Tema 9. Escalabilidad y Alta Disponibilidad en AWS","text":""},{"location":"ud09/ud09.html#introduccion-a-las-arquitecturas-reactivas-en-la-nube","title":"Introducci\u00f3n a las Arquitecturas Reactivas en la Nube","text":"<p>Las aplicaciones modernas deben ser capaces de gestionar cantidades masivas de datos y picos de tr\u00e1fico sin experimentar tiempos de inactividad y manteniendo tiempos de respuesta inferiores al segundo. </p> <p>Caso pr\u00e1ctico</p> <p>Tomemos el ejemplo de una empresa cuyo sitio web est\u00e1 a punto de aparecer en un famoso programa de televisi\u00f3n. Anticipan un aumento masivo de tr\u00e1fico, con decenas de miles de nuevos usuarios. Su arquitectura actual, basada en un \u00fanico servidor en una sola Zona de Disponibilidad, no est\u00e1 preparada para gestionar este pico. Para garantizar una experiencia de cliente excelente, sin retrasos ni ca\u00eddas, necesitan una arquitectura avanzada que pueda reaccionar din\u00e1micamente a la demanda.</p> <p>Para cumplir con estos exigentes requisitos, los arquitectos de la nube implementan sistemas basados en los principios de las arquitecturas reactivas. Los conceptos clave de un sistema reactivo son:</p> <ul> <li>Elasticidad: La capacidad de la infraestructura para ampliarse o contraerse din\u00e1micamente seg\u00fan cambien las necesidades de capacidad.</li> <li>Resiliencia: La habilidad de una carga de trabajo para recuperarse de errores de componentes o picos de estr\u00e9s, garantizando la continuidad del servicio.</li> <li>Capacidad de respuesta: El sistema responde de manera oportuna bajo cualquier condici\u00f3n de carga, asegurando una interacci\u00f3n fluida para el usuario.</li> <li>Basado en mensajes: Los componentes se comunican de forma as\u00edncrona, lo que promueve un bajo acoplamiento y mejora la escalabilidad y la resiliencia.</li> </ul> <p>En este tema nos centraremos en tres conceptos fundamentales para construir arquitecturas reactivas en AWS:</p> <ul> <li>Alta Disponibilidad: La capacidad de un sistema para resistir fallos y permanecer operativo.</li> <li>Tolerancia a Errores (Resiliencia): La habilidad de una carga de trabajo para recuperarse de errores de componentes o picos de estr\u00e9s.</li> <li>Autoescalado (Elasticidad): La capacidad de la infraestructura para ampliar o contraer autom\u00e1ticamente los recursos seg\u00fan la demanda.</li> </ul>"},{"location":"ud09/ud09.html#elasticidad-y-estrategias-de-escalado","title":"Elasticidad y Estrategias de Escalado","text":"<p>En el contexto de la nube, la elasticidad es una ventaja estrat\u00e9gica fundamental. Se define como la capacidad de una infraestructura para adquirir recursos cuando son necesarios y liberarlos cuando ya no lo son. Esto permite a las aplicaciones manejar fluctuaciones en la demanda \u2014desde picos inesperados hasta patrones diarios predecibles\u2014, garantizando tanto el rendimiento como la optimizaci\u00f3n de costos, ya que solo se paga por los recursos que se utilizan.</p> <p>Para lograr esta elasticidad, la t\u00e9cnica principal que empleamos es el escalado. El escalado consiste en ajustar (aumentando o disminuyendo) la capacidad de los recursos de nuestra arquitectura para satisfacer la carga de trabajo en un momento dado.</p>"},{"location":"ud09/ud09.html#tipos-de-escalado","title":"Tipos de escalado","text":"<p>Existen dos estrategias principales para escalar los recursos de una aplicaci\u00f3n, cada una con sus propias caracter\u00edsticas y casos de uso.</p> Escalado Horizontal (Scale-out/Scale-in) Escalado Vertical (Scale-up/Scale-down) Consiste en agregar m\u00e1s instancias (escalado ascendente) para distribuir la carga o eliminar instancias (escalado descendente) cuando la demanda disminuye. Es el m\u00e9todo preferido para lograr una alta elasticidad y tolerancia a fallos en la nube. Consiste en aumentar la potencia de una \u00fanica instancia, como cambiar a un tipo de instancia con m\u00e1s CPU o memoria (escalado ascendente), o disminuirla (escalado descendente). Puede implicar un breve tiempo de inactividad. <p></p> <p>Vamos a ver c\u00f3mo AWS nos permite automatizar el escalado horizontal de nuestros recursos de c\u00f3mputo para construir sistemas el\u00e1sticos.</p>"},{"location":"ud09/ud09.html#autoescalado-de-computo-amazon-ec2-auto-scaling","title":"Autoescalado de c\u00f3mputo: Amazon EC2 Auto Scaling","text":"<p>Amazon EC2 Auto Scaling es el servicio clave en AWS para implementar la elasticidad de manera automatizada en las instancias de c\u00f3mputo. Su funci\u00f3n principal es asegurar que se ejecute el n\u00famero correcto de instancias EC2 para manejar la carga de la aplicaci\u00f3n de forma eficiente, lanzando nuevas instancias cuando la demanda aumenta y termin\u00e1ndolas cuando la demanda disminuye para ahorrar costos.</p> <p>Este servicio opera a trav\u00e9s de un grupo de Auto Scaling, que se configura con tres par\u00e1metros principales que definen su comportamiento:</p> <ul> <li>Capacidad M\u00ednima: El n\u00famero m\u00ednimo de instancias que el grupo debe mantener en ejecuci\u00f3n en todo momento, garantizando una capacidad base para la aplicaci\u00f3n.</li> <li>Capacidad M\u00e1xima: El n\u00famero m\u00e1ximo de instancias al que el grupo puede escalar. Esto act\u00faa como un l\u00edmite de seguridad para controlar los costos.</li> <li>Capacidad Deseada: El n\u00famero de instancias que el grupo intenta mantener en un momento dado. Este valor es din\u00e1mico y fluct\u00faa entre el m\u00ednimo y el m\u00e1ximo en respuesta a las pol\u00edticas de escalado.</li> </ul> <p></p> <p>El ajuste de la capacidad deseada se gestiona a trav\u00e9s de pol\u00edticas de escalado. Una de las m\u00e1s comunes y efectivas es la pol\u00edtica de escalado de seguimiento de valores objetivo. Esta pol\u00edtica ajusta el n\u00famero de instancias para mantener una m\u00e9trica espec\u00edfica, como el uso promedio de la CPU del grupo, en un valor objetivo que nosotros definimos. Por ejemplo, podemos configurar el grupo para que mantenga la utilizaci\u00f3n promedio de la CPU en un 50%, y EC2 Auto Scaling se encargar\u00e1 de agregar o eliminar instancias para mantenerse cerca de ese valor. Adicionalmente, EC2 Auto Scaling ofrece estrategias avanzadas como el escalado predictivo, que utiliza modelos de aprendizaje autom\u00e1tico para predecir el tr\u00e1fico futuro bas\u00e1ndose en patrones hist\u00f3ricos diarios y semanales, permitiendo aprovisionar la capacidad antes de que sea necesaria.</p> <p></p>"},{"location":"ud09/ud09.html#escalado-en-bases-de-datos-relacionales-aws","title":"Escalado en Bases de Datos Relacionales AWS","text":"<p>El escalado de la capa de datos es tan crucial como el de la capa de c\u00f3mputo para el rendimiento y la disponibilidad de una aplicaci\u00f3n. Una base de datos sobrecargada puede convertirse en un cuello de botella que afecte a todo el sistema. AWS ofrece diferentes estrategias y servicios para escalar tanto bases de datos relacionales como no relacionales, permitiendo que la arquitectura completa sea el\u00e1stica.</p> <p>En el tema de Bases de Datos ya vimos que pod\u00edamos dividir los servicios de Bases de Datos Relacionales que ofrece AWS en 2 grupos:</p> <ul> <li>RDS: (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server)</li> <li>Aurora RDS</li> </ul> <p>Vamos a ver qu\u00e9 mecanismos de escalado ofrecen estos servicios de bases de datos.</p>"},{"location":"ud09/ud09.html#amazon-rds","title":"Amazon RDS","text":"<p>Escalado Vertical en Amazon RDS</p> <p>La forma m\u00e1s directa de escalar una base de datos RDS es cambiar su clase de instancia a una m\u00e1s potente (escalado ascendente) o menos potente (escalado descendente). Es importante tener en cuenta que este proceso requiere que la base de datos no est\u00e9 disponible temporalmente, generalmente por unos pocos minutos, mientras se aplica el cambio.</p> <p>Escalado Horizontal con R\u00e9plicas de Lectura</p> <p>Para cargas de trabajo con un alto volumen de lecturas, Amazon RDS permite crear r\u00e9plicas de lectura. Estas son copias de la base de datos principal que reciben el tr\u00e1fico de lectura, liberando a la instancia principal para que se concentre en las operaciones de escritura. Amazon RDS est\u00e1ndar permite crear hasta cinco r\u00e9plicas de lectura. Esta replicaci\u00f3n es as\u00edncrona, lo que significa que puede haber una peque\u00f1a demora entre la escritura en la instancia principal y su reflejo en las r\u00e9plicas.</p> <p>Replicaci\u00f3n s\u00edncrona y as\u00edncrona</p> <p>Replicaci\u00f3n s\u00edncrona:</p> <ul> <li>La escritura se confirma solo cuando los datos se guardan en todas las zonas.</li> <li>Garantiza que todas las r\u00e9plicas est\u00e9n actualizadas al instante.</li> <li>Ventaja: m\u00e1xima consistencia de datos.</li> <li>Inconveniente: puede tener m\u00e1s latencia porque espera la confirmaci\u00f3n de la r\u00e9plica.</li> </ul> <p>Replicaci\u00f3n as\u00edncrona: </p> <ul> <li>La escritura se confirma solo en la zona principal, y las r\u00e9plicas se actualizan despu\u00e9s.</li> <li>Ventaja: mejor rendimiento y menor latencia.</li> <li>Inconveniente: si falla la zona principal, las r\u00e9plicas pueden quedar ligeramente desactualizadas.</li> </ul> <p>En este esquema, la instancia principal act\u00faa como writer endpoint, siendo la \u00fanica responsable de aceptar operaciones de escritura (INSERT, UPDATE, DELETE), mientras que cada r\u00e9plica dispone de su propio reader endpoint para atender consultas de solo lectura (SELECT). Las aplicaciones pueden configurarse para dirigir las escrituras siempre al endpoint de la instancia principal y balancear las lecturas entre los endpoints de las r\u00e9plicas, ya sea de forma manual o mediante mecanismos de balanceo a nivel de aplicaci\u00f3n. </p> <p>Dado que la replicaci\u00f3n es as\u00edncrona, es importante tener en cuenta la consistencia eventual: una lectura realizada inmediatamente despu\u00e9s de una escritura puede no reflejar a\u00fan los cambios si se consulta una r\u00e9plica. Por este motivo, las operaciones que requieran datos totalmente actualizados deben seguir consultando la instancia principal, mientras que las r\u00e9plicas resultan ideales para informes, consultas intensivas o aplicaciones donde una ligera latencia en la actualizaci\u00f3n de los datos sea aceptable.</p> <p></p>"},{"location":"ud09/ud09.html#amazon-aurora","title":"Amazon Aurora","text":"<p>Este motor de base de datos, compatible con MySQL y PostgreSQL, est\u00e1 optimizado para la nube y mejora las capacidades de RDS. Un cl\u00faster de Aurora puede tener hasta 15 r\u00e9plicas de Aurora, lo que aumenta significativamente la capacidad de escalado de lectura en comparaci\u00f3n con RDS est\u00e1ndar.</p> <p>Al estar desarrollado de forma nativa por Amazon, est\u00e1 dise\u00f1ado espec\u00edficamente para la nube y se adapta mejor en coste, rendimiento y alta disponibilidad. Est\u00e1 pensado como un subsistema de almacenamiento distribuido de alto rendimiento y tolerante a fallos.</p> <p>En Amazon Aurora, los endpoints del cl\u00faster son uno de sus elementos clave, ya que abstraen la complejidad de trabajar con m\u00faltiples instancias y facilitan tanto el balanceo de carga como la alta disponibilidad. A diferencia de RDS tradicional, Aurora gestiona estos endpoints de forma autom\u00e1tica.</p> <p>Tipos de endpoints en un cl\u00faster Aurora:</p> <p>1. Cluster Endpoint (Writer Endpoint) Es el endpoint principal del cl\u00faster y siempre apunta a la instancia escritora activa. Todas las operaciones de escritura (INSERT, UPDATE, DELETE, DDL) deben dirigirse a este endpoint. En caso de failover, el endpoint se actualiza autom\u00e1ticamente para apuntar a la nueva instancia escritora, sin necesidad de cambiar la configuraci\u00f3n de la aplicaci\u00f3n.</p> <p>2. Reader Endpoint Este endpoint agrupa todas las r\u00e9plicas de lectura del cl\u00faster y balancea autom\u00e1ticamente las consultas de solo lectura entre ellas. Es ideal para aplicaciones con alta carga de lecturas, ya que permite escalar horizontalmente sin que la aplicaci\u00f3n tenga que conocer las instancias individuales. Si se a\u00f1ade o elimina una r\u00e9plica, el endpoint se actualiza de forma transparente.</p> <p>3. Instance Endpoints Cada instancia del cl\u00faster (tanto la escritora como las lectoras) dispone de su endpoint individual. Estos endpoints se usan en escenarios espec\u00edficos, como tareas administrativas, diagn\u00f3sticos o cuando una aplicaci\u00f3n necesita conectarse siempre a una instancia concreta, evitando el balanceo autom\u00e1tico.</p> <p></p> <p>Aurora Serverless</p> <p>Es una configuraci\u00f3n de escalado autom\u00e1tico bajo demanda para Amazon Aurora. Resulta ideal para cargas de trabajo intermitentes, poco frecuentes o impredecibles. Con Aurora Serverless, la base de datos se inicia, se apaga y escala su capacidad de c\u00f3mputo autom\u00e1ticamente seg\u00fan las necesidades de la aplicaci\u00f3n, sin necesidad de administrar instancias. El almacenamiento de la base de datos tambi\u00e9n escala autom\u00e1ticamente desde 10 Gibibytes (GiB) hasta 64 Tebibytes (TiB). El pago se basa en las Unidades de Capacidad de Aurora (ACU) utilizadas por segundo, lo que optimiza los costos para patrones de uso variables.</p> <p>Autoescalado</p> <p>En Amazon RDS tradicional (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server) no existe autoescalado nativo del n\u00famero de r\u00e9plicas de lectura, por lo que su creaci\u00f3n y eliminaci\u00f3n debe hacerse manualmente o mediante automatizaciones personalizadas usando CloudWatch, Lambda y la API de AWS; sin embargo, Amazon Aurora s\u00ed incorpora autoescalado autom\u00e1tico de r\u00e9plicas de lectura, permitiendo a\u00f1adir o quitar instancias en funci\u00f3n de la carga y utilizando endpoints de lectura que distribuyen el tr\u00e1fico de forma transparente, lo que supone una diferencia clave entre ambos servicios.</p> <p>Balanceo</p> <p>En Amazon RDS tradicional el balanceo de carga de las lecturas no se realiza autom\u00e1ticamente: cada r\u00e9plica de lectura tiene su propio endpoint, y es la aplicaci\u00f3n la que debe decidir a qu\u00e9 endpoint conectarse para las consultas de lectura. Esto implica que el reparto de carga debe hacerse de forma manual, ya sea implementando l\u00f3gica en la aplicaci\u00f3n, utilizando un proxy o apoy\u00e1ndose en un balanceador externo. A diferencia de esto, Amazon Aurora s\u00ed ofrece endpoints de lectura gestionados, que distribuyen autom\u00e1ticamente las consultas entre las r\u00e9plicas disponibles.</p>"},{"location":"ud09/ud09.html#diseno-de-arquitecturas-de-alta-disponibilidad","title":"Dise\u00f1o de Arquitecturas de Alta Disponibilidad","text":"<p>Un sistema de alta disponibilidad es aquel que est\u00e1 dise\u00f1ado para resistir fallos y minimizar el tiempo de inactividad, operando sin requerir intervenci\u00f3n humana. El principio fundamental para lograrlo es evitar los puntos \u00fanicos de fallo (single points of failure), es decir, componentes cuyo fallo provocar\u00eda la ca\u00edda de todo el sistema.</p>"},{"location":"ud09/ud09.html#alta-disponibilidad-a-nivel-de-aplicacion","title":"Alta Disponibilidad a nivel de Aplicaci\u00f3n","text":"<p>Un servicio fundamental para construir estas arquitecturas en AWS es Elastic Load Balancing (ELB). ELB es un servicio administrado que distribuye autom\u00e1ticamente el tr\u00e1fico de las aplicaciones entrantes entre m\u00faltiples destinos, como instancias EC2, contenedores o direcciones IP.</p> <p>Las funciones clave de Elastic Load Balancing incluyen:</p> <ul> <li>Distribuci\u00f3n de Tr\u00e1fico: Reparte las solicitudes entrantes entre m\u00faltiples destinos para evitar que un \u00fanico servidor se sobrecargue.</li> <li>Tolerancia a Fallos Multi-AZ: Opera en m\u00faltiples Zonas de Disponibilidad (AZ) dentro de una regi\u00f3n. Si una AZ falla, el balanceador de carga redirige el tr\u00e1fico a los destinos en las AZ operativas.</li> <li>Comprobaciones de Estado: Realiza peri\u00f3dicamente comprobaciones de estado (health checks) a sus destinos registrados. Solo env\u00eda tr\u00e1fico a los destinos que responden correctamente, consider\u00e1ndose \"en buen estado\".</li> </ul> <p>El servicio ELB de AWS ofrece tres tipos principales de balanceadores de carga:</p> <ul> <li>Application Load Balancer (ALB): Opera en la capa 7 (HTTP/HTTPS) y es ideal para el balanceo de carga avanzado basado en el contenido de la solicitud (como la URL o las cabeceras). Es perfecto para arquitecturas modernas como microservicios.</li> <li>Network Load Balancer (NLB): Opera en la capa 4 (TCP/UDP/TLS). Est\u00e1 optimizado para manejar millones de solicitudes por segundo y mantener latencias muy bajas, y es ideal para gestionar patrones de tr\u00e1fico de red repentinos y vol\u00e1tiles.</li> <li>Classic Load Balancer (CLB): Es la generaci\u00f3n anterior de balanceadores de carga. Aunque opera tanto en la capa 4 como en la 7, AWS recomienda utilizar ALB o NLB para nuevas aplicaciones.</li> </ul> <p>El patr\u00f3n de arquitectura b\u00e1sico para lograr alta disponibilidad combina estos servicios. La pr\u00e1ctica recomendada consiste en colocar las instancias EC2 dentro de un grupo de Auto Scaling configurado para operar en m\u00faltiples Zonas de Disponibilidad. Al frente de este grupo, se despliega un Elastic Load Balancer. El ELB distribuye el tr\u00e1fico entre las instancias saludables repartidas en las diferentes AZ. Si una instancia falla, el ELB la detecta a trav\u00e9s de las comprobaciones de estado y deja de enviarle tr\u00e1fico. Simult\u00e1neamente, el grupo de Auto Scaling reemplazar\u00e1 la instancia defectuosa. Si una Zona de Disponibilidad completa falla, el ELB simplemente redirigir\u00e1 todo el tr\u00e1fico a las instancias en la(s) AZ restante(s), permitiendo que la aplicaci\u00f3n contin\u00fae funcionando sin interrupciones.</p> <p></p>"},{"location":"ud09/ud09.html#alta-disponibilidad-de-bases-de-datos","title":"Alta Disponibilidad de Bases de Datos","text":"<p>Una de las funciones m\u00e1s potentes de Amazon RDS es la posibilidad de configurar la instancia de base de datos para una alta disponibilidad con un despliegue Multi-AZ. Amazon RDS genera autom\u00e1ticamente una copia en espera de la instancia de base de datos en otra zona de disponibilidad de la misma VPC. Tras propagar la copia de la base de datos, las transacciones se replican de forma s\u00edncrona en la copia en espera.</p> <p>Esta configuraci\u00f3n protege las bases de datos contra errores de la instancia de base de datos e interrupciones de la zona de disponibilidad. </p> <p></p> <p>Si la instancia de base de datos principal falla en un despliegue Multi-AZ, Amazon RDS pone en l\u00ednea autom\u00e1ticamente la instancia de base de datos en espera como nueva instancia principal. Dado que las aplicaciones hacen referencia a la base de datos por su nombre mediante el punto de enlace del sistema de nombres de dominio (DNS), no es necesario cambiar nada en el c\u00f3digo de la aplicaci\u00f3n para utilizar la copia en espera para la conmutaci\u00f3n por error.</p> <p>Nota</p> <p>Para que todas estas arquitecturas funcionen de manera \u00f3ptima, es fundamental observar su estado y rendimiento, lo que nos lleva a la importancia del monitoreo que estudiamos en el tema anterior.</p>"}]}